{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAP97oaA0ADX"
   },
   "source": [
    "# Text Classification\n",
    "\n",
    "## Environment\n",
    "You will use Python 3.10 and PyTorch 2.0, which is already available on Colab and some other libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRL3KX0wnNYL"
   },
   "source": [
    "## 실습 Part 0. Checking GPU\n",
    "In this section, you will make sure you are using the GPU of google colab and download the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtPPFmuK0cdG",
    "outputId": "4b73ea19-46f4-42db-ab59-564c387bc9af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.8.10\n",
      "torch 1.14.0a0+44dac51\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "\n",
    "print(\"python\", python_version())\n",
    "print(\"torch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWgcYCZ-czSX",
    "outputId": "dc5dc755-74bf-4b88-be2a-fb36d26f32bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "#check GPU\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eH1EyvPM0ibJ"
   },
   "source": [
    "## 실습 Part 1. Downloading Dataset\n",
    "In this section, you will download Stanford Sentiment Treebank (SST), a popular dataset for sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TbvWWWn601An"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.14.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.22.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZK_eWLF1Ahj"
   },
   "source": [
    "Download SST and print the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1HA3fo_u0-9K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 0.6944400072097778,\n",
      " 'sentence': \"The Rock is destined to be the 21st Century 's new `` Conan '' \"\n",
      "             \"and that he 's going to make a splash even greater than Arnold \"\n",
      "             'Schwarzenegger , Jean-Claud Van Damme or Steven Segal .',\n",
      " 'tokens': \"The|Rock|is|destined|to|be|the|21st|Century|'s|new|``|Conan|''|and|that|he|'s|going|to|make|a|splash|even|greater|than|Arnold|Schwarzenegger|,|Jean-Claud|Van|Damme|or|Steven|Segal|.\",\n",
      " 'tree': '70|70|68|67|63|62|61|60|58|58|57|56|56|64|65|55|54|53|52|51|49|47|47|46|46|45|40|40|41|39|38|38|43|37|37|69|44|39|42|41|42|43|44|45|50|48|48|49|50|51|52|53|54|55|66|57|59|59|60|61|62|63|64|65|66|67|68|69|71|71|0'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "sst_dataset = load_dataset('sst') #download sst dataset\n",
    "pprint(sst_dataset['train'][0]) #printing the first (sentence,label) example in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1GWHC761ceH"
   },
   "source": [
    "You will only use **'sentence'** and **'label'** of the data. Please ignore the other values. Note that the label is between 0 and 1. You will round it to either 0 or 1 for binary classification (1 means it is a positive review and 0 means it is a negative review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-ALFLUbB5ig"
   },
   "source": [
    "## 실습 Part 2. Word Embedding\n",
    "In this section, you will download a pretrained word embedding called Glove and use it to convert words in to a vector representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rGTgBin1CRpg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:41, 5.33MB/s]                                                           \n",
      "100%|█████████████████████████████████████████████████████████████▉| 399999/400000 [00:31<00:00, 12553.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "#word embedding 종류 주변에 있는 단어와 전체 문장의 유사성 즉 단어 간의 유사성을 잘 포착하며, 단어의 의미를 저차원의 벡터로 효과적으로 표현\n",
    "\n",
    "glove = GloVe(name='6B',dim = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "f9yK2s2UDqnD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2084, -0.0197,  0.0640, -0.7140, -0.2118, -0.5928, -0.1532,  0.0442,\n",
      "         0.6329, -0.8482, -0.2113, -0.1976,  0.1903, -0.5623,  0.2713,  0.2378,\n",
      "        -0.5189, -0.2452,  0.0352,  0.0968,  0.2490,  0.7128,  0.0383, -0.1051,\n",
      "        -0.4779, -0.3952, -0.2719, -0.4443,  0.0611, -0.2318, -0.3590, -0.1824,\n",
      "         0.0355, -0.0877, -1.0816, -0.4252,  0.0032, -0.4599, -0.0435, -0.3903,\n",
      "         0.5190,  0.2114, -0.2553,  1.1805, -0.1904, -0.1216,  0.0342, -0.0623,\n",
      "         0.1442, -0.5337,  0.4742, -0.4471,  0.5805,  0.4358,  0.1321, -0.0957,\n",
      "        -0.3718, -0.0138,  0.2060, -0.1010,  0.1068, -0.3372,  0.1099,  0.3480,\n",
      "        -0.0998,  0.3694, -0.5292,  0.1241, -0.4613, -0.3848, -0.1011, -0.1763,\n",
      "         0.3757,  0.1638, -0.2198, -0.2684,  0.8471, -0.3562, -0.0840, -0.2028,\n",
      "        -0.5654,  0.1911, -0.1413, -0.7812,  0.6919, -0.0836, -0.5429,  0.1644,\n",
      "         0.0376, -0.6890, -0.6871, -0.1337, -0.4779,  0.2013,  0.0851, -0.0639,\n",
      "        -0.1710, -0.3243, -0.1762, -0.5140, -0.5029,  0.2320, -0.1132, -1.0640,\n",
      "        -0.0354, -0.5068, -0.2712, -0.1662, -0.6302,  0.0543, -0.0482,  0.2928,\n",
      "        -0.0307, -0.2465, -0.2708, -0.4256, -0.3917,  0.1843, -0.0178, -0.3533,\n",
      "        -0.4908, -0.9078,  0.1387, -0.7652, -0.4632, -0.3212, -0.0862,  1.0448,\n",
      "        -0.3992,  0.6948, -0.1038,  0.8672,  0.2274,  0.4384,  0.0858, -0.2285,\n",
      "         0.4309,  0.0642, -0.0279, -0.0931,  0.6519,  0.5914, -0.3376, -0.3773,\n",
      "         0.0052,  1.1193, -0.2385, -0.1603,  0.4288, -0.1623, -0.1220, -0.1061,\n",
      "         0.0158,  0.0227, -0.1773, -0.0917, -0.2916,  0.1903, -0.3517,  0.2756,\n",
      "        -0.2058,  0.1147, -0.3413, -0.0066,  0.1490, -0.0268,  0.0019,  0.5328,\n",
      "        -0.7609,  0.0631, -0.7209, -0.0413, -0.9616,  0.0208,  0.1612, -0.3434,\n",
      "         0.6971, -0.1602, -0.1170, -0.0702, -0.3077,  0.3974,  0.3999, -0.6780,\n",
      "         0.5768, -0.4810,  0.5932, -0.4226,  0.2861, -0.2620,  0.0527,  0.6166,\n",
      "        -0.3680, -0.2843, -0.4005, -0.3006, -0.2744, -0.0457, -0.5610,  0.2418,\n",
      "         0.8663, -0.8371,  0.1356,  0.2620, -0.4306,  0.3456,  0.0594,  0.6184,\n",
      "         0.1184, -0.0192,  0.4770, -0.3246, -0.1546, -0.2356, -0.6426, -0.0922,\n",
      "        -0.1962,  0.4067,  0.1801,  0.0943,  0.0469,  0.2637, -0.5073,  0.3749,\n",
      "        -0.6677,  0.3510, -0.0338,  0.3053,  0.2317,  0.0235, -0.6837,  0.2608,\n",
      "        -0.2253, -0.2656,  0.5997,  0.2598,  0.3625,  0.1556, -0.4555,  0.1115,\n",
      "        -0.3329,  0.0814, -0.3699, -0.2554, -1.1628, -0.1462, -0.0330, -0.5562,\n",
      "         0.4772, -0.2902,  0.4269,  1.2397, -0.8139,  0.2108, -0.2543, -0.0868,\n",
      "        -0.0784,  0.2603,  0.3281, -0.2378,  0.0514, -0.0302, -0.1567,  0.0571,\n",
      "         0.3390,  0.1279, -0.2147, -0.7521,  0.4142,  0.0063, -0.5290,  0.9219,\n",
      "        -0.4218, -0.6964,  0.0741,  0.1907, -1.2031, -0.0813, -0.4914, -0.2216,\n",
      "        -0.2988,  0.3009,  0.0186,  0.1879, -0.4543, -0.2930,  0.3695, -0.2422,\n",
      "        -0.1180,  0.0718,  0.4403, -0.5998,  0.4535,  0.1785, -0.1716,  0.0188,\n",
      "        -0.6235, -0.0142,  0.1680, -0.0644])\n"
     ]
    }
   ],
   "source": [
    "print(glove['apple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "F9N-bE0YHVf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(glove['notaword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tzCC32BWHXMo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(glove['Apple'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8c7kwZOJAz8"
   },
   "source": [
    "Now you will convert every word in every training sentence with its corresponding word embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZA_UWegMKh0j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8544, 16, 300])\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "training_data = []\n",
    "length = 16\n",
    "\n",
    "for idx_, sentence in enumerate(sst_dataset['train']['sentence']):\n",
    "  #tokenize word\n",
    "  words = nltk.word_tokenize(sentence)\n",
    "\n",
    "  #padding or truncating based on the length\n",
    "  if len(words) > 16:\n",
    "    words = words[:16]\n",
    "  else:\n",
    "    for i in range(0,16-len(words)):\n",
    "      words.append('PAD')\n",
    "\n",
    "  #convert words to their embeddings\n",
    "  ret = glove.get_vecs_by_tokens(words, lower_case_backup = True)\n",
    "  #print(ret.size())\n",
    "  training_data.append(ret)\n",
    "\n",
    "training_data = torch.stack(training_data) #convert list of tensors to tensors\n",
    "print(training_data.size()) #note that now the training data is now of shape (#training data, length of the sentence, dimension of word vector representation) =  (8544, 16, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qCF848JiGWJ"
   },
   "source": [
    "Do the same for testing data (except for padding and truncating because we will be inputting test sentence one by one during inference, so they don't have to be of equal length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "m2Jqgt0FiTOZ"
   },
   "outputs": [],
   "source": [
    "testing_data = []\n",
    "for idx_, sentence in enumerate(sst_dataset['test']['sentence']):\n",
    "  #tokenize word\n",
    "  words = nltk.word_tokenize(sentence)\n",
    "\n",
    "  #convert words to their embeddings\n",
    "  ret = glove.get_vecs_by_tokens(words, lower_case_backup = True)\n",
    "  testing_data.append(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYaM0MoPoT9n"
   },
   "source": [
    "## Utility Functions\n",
    "<br> <font color='red' > **Utility functions and code for 실습 3~4. Please run this before doing 실습 3 and 실습 4. You do not need to change anything here**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y9bcUMHTWqRh"
   },
   "outputs": [],
   "source": [
    "#utilities\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import nn\n",
    "\n",
    "#function for creating dataloaders\n",
    "def create_dataloader(data,label,train):\n",
    "    #create DataLoader\n",
    "    if (train == 0):\n",
    "        print(data.size())\n",
    "        print(label)\n",
    "        print(torch.round(torch.Tensor(label)).to(torch.long))\n",
    "        train = torch.utils.data.TensorDataset(data, torch.round(torch.Tensor(label)).to(torch.long))\n",
    "        #train_data, val_data = torch.utils.data.random_split(train,[int(0.80*len(train)),len(train)-int(0.80*len(train))], generator= torch.Generator().manual_seed(42) )\n",
    "        return DataLoader(train, batch_size = 16, shuffle=True, drop_last = True) #DataLoader(val_data, batch_size = 16, shuffle=True, drop_last = True)\n",
    "    else:\n",
    "        test = torch.utils.data.TensorDataset(torch.Tensor(input).to(torch.int32), (torch.round(torch.Tensor(data['label']))).to(torch.long))\n",
    "        return DataLoader(test, batch_size = 16, shuffle=True)\n",
    "\n",
    "def train(num_epoch, model, train_loader):\n",
    "  for epoch in range(0,num_epoch):\n",
    "      train_loss = 0\n",
    "      model.train()\n",
    "      for batch_id, (data,label) in enumerate(train_loader):\n",
    "          data = data.to(device)\n",
    "          label = label.to(device)\n",
    "          optimizer.zero_grad()\n",
    "          logits = model(data)\n",
    "          loss = cel(logits,label)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          train_loss += loss.item()\n",
    "      average_loss = train_loss / len(train_loader.dataset)\n",
    "      print('====> Epoch: {} Average training loss: {:.4f}'.format(\n",
    "            epoch, average_loss))\n",
    "\n",
    "\n",
    "def accuracy(pred,target):\n",
    "    correct = 0\n",
    "    for i in range(0,pred.size()[0]):\n",
    "        if pred[i] == target[i]:\n",
    "            correct += 1\n",
    "    return correct\n",
    "\n",
    "def test(model,test_data, test_label):\n",
    "  test_label = torch.round(torch.Tensor(test_label)).to(torch.long).to(device)\n",
    "  total_correct = 0\n",
    "  total = 0\n",
    "  model.eval()\n",
    "  for idx in range(0,len(test_data)):\n",
    "    data = test_data[idx].to(device).view(-1, test_data[idx].size()[0], test_data[idx].size()[1])\n",
    "    label = test_label[idx].to(device).view(1)\n",
    "    logits = model(data)\n",
    "    pred = m(logits)\n",
    "    pred = torch.argmax(pred,dim=1)\n",
    "    total_correct += accuracy(pred,label)\n",
    "    total += label.size()[0]\n",
    "\n",
    "  print('Accuracy on the test data is: ' + str(total_correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTt9ESVzXPOv"
   },
   "source": [
    "## 실습 Part 3. Vanilla RNN\n",
    "In this section, you implement a vanilla RNN and perform text classification with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.input_dim = d\n",
    "        self.hidden_dim = d\n",
    "        self.output_dim = 2\n",
    "\n",
    "        # x -> h layer\n",
    "        self.U = nn.Linear(self.input_dim, self.hidden_dim)\n",
    "\n",
    "        # h -> h layer\n",
    "        self.W = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "        # h -> output layer\n",
    "        self.V = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "    def forward(self, x):  # x: size [BatchSize, Length, Word Vector Length]\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # length of sequence\n",
    "        self.length = x.size()[1]\n",
    "\n",
    "        # Iterate through sentence and input to RNN sequentially\n",
    "        for t in range(0, self.length):\n",
    "            xt = x[:, t, :]  # shape [BatchSize, Length of word embedding vector]\n",
    "            hidden = torch.tanh(self.U(xt) + self.W(hidden))  # Update hidden state\n",
    "\n",
    "        # output logit using last sequence\n",
    "        return self.V(hidden)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(batch_size, self.hidden_dim).to(device)\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfZ4bfzmqFJk"
   },
   "source": [
    "Now perform text classification with your vanilla RNN. You will see your model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "V3aG2G_JqEeG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8544, 16, 300])\n",
      "[0.6944400072097778, 0.833329975605011, 0.625, 0.5, 0.7222200036048889, 0.833329975605011, 0.875, 0.7222200036048889, 0.833329975605011, 0.7361099720001221, 0.9027799963951111, 0.44444000720977783, 0.8055599927902222, 0.44444000720977783, 0.8194400072097778, 0.75, 0.6111099720001221, 0.44444000720977783, 0.8194400072097778, 0.7777799963951111, 0.8194400072097778, 0.6388900279998779, 0.5555599927902222, 0.875, 0.5555599927902222, 0.5138900279998779, 0.9444400072097778, 0.7222200036048889, 0.9305599927902222, 0.3333300054073334, 0.8194400072097778, 0.7777799963951111, 0.5694400072097778, 0.7361099720001221, 0.8611099720001221, 0.6805599927902222, 0.7361099720001221, 0.7222200036048889, 0.541670024394989, 0.6805599927902222, 0.7638900279998779, 0.833329975605011, 0.4027799963951111, 0.6527799963951111, 0.5277799963951111, 0.16666999459266663, 0.7777799963951111, 0.6111099720001221, 0.375, 0.9444400072097778, 0.75, 0.8611099720001221, 0.6388900279998779, 0.8888900279998779, 0.8055599927902222, 0.833329975605011, 0.8194400072097778, 0.666670024394989, 0.7777799963951111, 0.6527799963951111, 0.4583300054073334, 0.75, 0.7777799963951111, 0.666670024394989, 0.38888999819755554, 0.36111000180244446, 1.0, 0.708329975605011, 0.875, 0.9027799963951111, 0.708329975605011, 0.541670024394989, 0.36111000180244446, 0.6388900279998779, 0.5555599927902222, 0.44444000720977783, 0.666670024394989, 0.875, 0.8055599927902222, 0.8194400072097778, 0.8194400072097778, 0.625, 0.4583300054073334, 0.833329975605011, 0.7222200036048889, 0.6805599927902222, 0.8472200036048889, 0.9861099720001221, 0.7361099720001221, 0.8055599927902222, 0.7638900279998779, 0.791670024394989, 0.23611000180244446, 0.875, 0.6944400072097778, 0.6111099720001221, 0.916670024394989, 0.625, 0.7222200036048889, 0.8055599927902222, 0.75, 0.8611099720001221, 0.6111099720001221, 0.6111099720001221, 0.7222200036048889, 0.8888900279998779, 0.7777799963951111, 0.7222200036048889, 0.6805599927902222, 0.6388900279998779, 0.7638900279998779, 0.6944400072097778, 0.7777799963951111, 0.916670024394989, 0.708329975605011, 0.791670024394989, 0.8888900279998779, 1.0, 0.666670024394989, 0.7361099720001221, 0.666670024394989, 0.5138900279998779, 0.666670024394989, 0.5555599927902222, 0.7638900279998779, 0.6111099720001221, 0.7638900279998779, 0.916670024394989, 0.23611000180244446, 0.4722200036048889, 0.5, 0.583329975605011, 0.833329975605011, 0.708329975605011, 0.6944400072097778, 0.708329975605011, 0.75, 0.5972200036048889, 0.8055599927902222, 0.833329975605011, 0.6944400072097778, 0.8888900279998779, 0.75, 0.6944400072097778, 0.916670024394989, 0.6388900279998779, 0.791670024394989, 0.791670024394989, 0.8055599927902222, 0.7777799963951111, 0.6388900279998779, 0.6527799963951111, 0.75, 0.7361099720001221, 0.6944400072097778, 0.8194400072097778, 0.833329975605011, 0.8194400072097778, 0.75, 0.8194400072097778, 0.8194400072097778, 0.6111099720001221, 0.666670024394989, 0.8611099720001221, 0.5, 0.833329975605011, 0.7777799963951111, 0.4166699945926666, 0.30555999279022217, 0.7777799963951111, 0.541670024394989, 0.7638900279998779, 0.6388900279998779, 0.30555999279022217, 0.9027799963951111, 0.833329975605011, 0.75, 0.6944400072097778, 0.7361099720001221, 0.791670024394989, 0.7361099720001221, 0.7222200036048889, 0.708329975605011, 0.5, 0.791670024394989, 0.791670024394989, 0.5972200036048889, 0.666670024394989, 0.7222200036048889, 0.541670024394989, 0.666670024394989, 0.708329975605011, 0.666670024394989, 0.48611000180244446, 0.8194400072097778, 0.6527799963951111, 0.375, 0.48611000180244446, 0.8194400072097778, 0.7222200036048889, 0.6388900279998779, 0.3333300054073334, 0.708329975605011, 0.8472200036048889, 0.916670024394989, 0.625, 0.625, 0.6111099720001221, 0.7361099720001221, 0.75, 0.30555999279022217, 1.0, 0.8611099720001221, 0.43055999279022217, 0.8888900279998779, 0.791670024394989, 0.75, 0.791670024394989, 0.666670024394989, 0.8611099720001221, 0.6944400072097778, 0.833329975605011, 0.6805599927902222, 0.791670024394989, 0.8055599927902222, 0.8611099720001221, 0.833329975605011, 0.7777799963951111, 0.6944400072097778, 0.6805599927902222, 0.7222200036048889, 0.583329975605011, 0.6944400072097778, 0.6527799963951111, 0.6111099720001221, 0.7222200036048889, 0.2777799963951111, 0.44444000720977783, 0.8888900279998779, 0.5138900279998779, 0.6805599927902222, 0.8472200036048889, 0.5694400072097778, 0.916670024394989, 0.6944400072097778, 0.2916699945926666, 0.541670024394989, 0.75, 0.9027799963951111, 0.625, 0.666670024394989, 0.8472200036048889, 0.666670024394989, 0.7777799963951111, 0.666670024394989, 0.708329975605011, 0.625, 0.6388900279998779, 0.8888900279998779, 0.666670024394989, 0.666670024394989, 0.31944000720977783, 0.7361099720001221, 1.0, 0.7777799963951111, 0.7361099720001221, 0.875, 0.916670024394989, 0.666670024394989, 0.7222200036048889, 0.8055599927902222, 0.7222200036048889, 0.6111099720001221, 0.5972200036048889, 0.9305599927902222, 0.43055999279022217, 0.666670024394989, 0.833329975605011, 0.5972200036048889, 0.5, 0.9861099720001221, 0.7638900279998779, 0.7777799963951111, 0.4722200036048889, 0.6944400072097778, 0.875, 0.791670024394989, 0.7361099720001221, 0.9305599927902222, 0.7361099720001221, 0.9305599927902222, 0.6388900279998779, 0.7222200036048889, 0.43055999279022217, 0.8888900279998779, 0.2916699945926666, 0.8888900279998779, 0.8472200036048889, 0.666670024394989, 0.666670024394989, 0.916670024394989, 0.6388900279998779, 0.7222200036048889, 0.8055599927902222, 0.8055599927902222, 0.666670024394989, 0.6388900279998779, 0.5972200036048889, 0.8055599927902222, 0.875, 0.666670024394989, 0.541670024394989, 0.38888999819755554, 0.8055599927902222, 0.708329975605011, 0.7638900279998779, 0.833329975605011, 0.6388900279998779, 0.6944400072097778, 0.7638900279998779, 0.7222200036048889, 0.6388900279998779, 0.833329975605011, 0.5694400072097778, 0.38888999819755554, 0.6944400072097778, 0.583329975605011, 0.875, 0.833329975605011, 0.666670024394989, 0.8055599927902222, 0.625, 0.6944400072097778, 0.7361099720001221, 0.5, 0.666670024394989, 0.7777799963951111, 0.4166699945926666, 0.8888900279998779, 0.7222200036048889, 0.8888900279998779, 0.7777799963951111, 0.6944400072097778, 0.7777799963951111, 0.875, 0.8472200036048889, 0.75, 0.75, 0.7222200036048889, 0.833329975605011, 0.666670024394989, 0.6111099720001221, 0.8194400072097778, 0.8611099720001221, 0.791670024394989, 0.3472200036048889, 0.7777799963951111, 0.8194400072097778, 0.8888900279998779, 0.791670024394989, 0.6527799963951111, 0.75, 0.7222200036048889, 0.7777799963951111, 0.6805599927902222, 0.9444400072097778, 0.7222200036048889, 1.0, 0.8055599927902222, 0.75, 0.8194400072097778, 0.833329975605011, 0.666670024394989, 0.6805599927902222, 0.8611099720001221, 0.6805599927902222, 0.7222200036048889, 0.9027799963951111, 0.4027799963951111, 0.6388900279998779, 0.9027799963951111, 0.666670024394989, 0.791670024394989, 0.8055599927902222, 0.8194400072097778, 0.7777799963951111, 0.7361099720001221, 0.5277799963951111, 0.8888900279998779, 0.4166699945926666, 0.791670024394989, 0.38888999819755554, 0.833329975605011, 0.8194400072097778, 0.5277799963951111, 0.708329975605011, 0.833329975605011, 0.2777799963951111, 0.7777799963951111, 0.5555599927902222, 0.48611000180244446, 0.6111099720001221, 0.625, 0.666670024394989, 0.8611099720001221, 0.7777799963951111, 0.5555599927902222, 0.916670024394989, 0.666670024394989, 0.5277799963951111, 0.708329975605011, 0.666670024394989, 0.7777799963951111, 0.6388900279998779, 0.875, 0.583329975605011, 0.6805599927902222, 0.875, 0.791670024394989, 0.8194400072097778, 0.8055599927902222, 0.8888900279998779, 0.708329975605011, 0.8055599927902222, 0.6944400072097778, 0.791670024394989, 0.7638900279998779, 0.7638900279998779, 0.625, 0.791670024394989, 0.5555599927902222, 0.833329975605011, 0.38888999819755554, 0.708329975605011, 0.18055999279022217, 0.8472200036048889, 0.6111099720001221, 0.8472200036048889, 0.875, 0.8194400072097778, 0.8055599927902222, 0.708329975605011, 0.44444000720977783, 0.7361099720001221, 0.8055599927902222, 0.7638900279998779, 0.791670024394989, 0.7361099720001221, 1.0, 0.916670024394989, 0.791670024394989, 0.5, 0.9444400072097778, 0.5555599927902222, 0.8055599927902222, 0.16666999459266663, 1.0, 0.625, 0.75, 0.11111000180244446, 0.7222200036048889, 0.875, 0.8611099720001221, 0.5, 0.666670024394989, 0.7638900279998779, 0.9027799963951111, 0.44444000720977783, 0.583329975605011, 0.38888999819755554, 0.8472200036048889, 0.833329975605011, 0.9722200036048889, 0.7222200036048889, 0.875, 0.5972200036048889, 0.8888900279998779, 0.7638900279998779, 0.7222200036048889, 0.6388900279998779, 0.5555599927902222, 0.7638900279998779, 0.666670024394989, 0.666670024394989, 0.6111099720001221, 0.6805599927902222, 0.833329975605011, 0.7638900279998779, 0.6527799963951111, 0.7638900279998779, 0.5972200036048889, 0.875, 0.7361099720001221, 0.3333300054073334, 0.8888900279998779, 0.44444000720977783, 0.7361099720001221, 0.6527799963951111, 0.791670024394989, 0.8888900279998779, 0.6944400072097778, 0.7222200036048889, 0.7638900279998779, 0.7222200036048889, 0.7638900279998779, 0.75, 0.31944000720977783, 0.75, 0.9444400072097778, 0.7361099720001221, 0.6944400072097778, 0.6805599927902222, 0.7222200036048889, 0.8611099720001221, 0.8194400072097778, 0.8055599927902222, 0.833329975605011, 0.5138900279998779, 0.7361099720001221, 0.833329975605011, 0.75, 0.708329975605011, 0.7638900279998779, 0.8472200036048889, 0.2916699945926666, 0.8888900279998779, 0.8055599927902222, 0.875, 0.7222200036048889, 0.8888900279998779, 0.7222200036048889, 0.7777799963951111, 0.9027799963951111, 0.6388900279998779, 0.6944400072097778, 0.6944400072097778, 0.791670024394989, 0.8888900279998779, 0.43055999279022217, 0.791670024394989, 0.48611000180244446, 0.708329975605011, 0.6944400072097778, 0.9861099720001221, 0.6388900279998779, 0.708329975605011, 0.44444000720977783, 0.833329975605011, 0.666670024394989, 0.8194400072097778, 0.5138900279998779, 0.8055599927902222, 0.7222200036048889, 0.791670024394989, 0.7777799963951111, 0.8888900279998779, 0.666670024394989, 0.48611000180244446, 0.9444400072097778, 0.833329975605011, 0.30555999279022217, 0.6527799963951111, 0.30555999279022217, 0.5, 0.5138900279998779, 0.44444000720977783, 0.8055599927902222, 0.8055599927902222, 0.8888900279998779, 0.833329975605011, 0.8888900279998779, 0.6944400072097778, 0.8888900279998779, 0.8472200036048889, 0.8472200036048889, 0.8055599927902222, 0.708329975605011, 0.833329975605011, 0.666670024394989, 0.75, 0.4166699945926666, 0.5694400072097778, 0.7361099720001221, 0.75, 0.791670024394989, 0.791670024394989, 0.875, 0.9305599927902222, 0.5, 0.666670024394989, 0.6944400072097778, 0.6944400072097778, 0.75, 0.5555599927902222, 0.708329975605011, 0.5555599927902222, 0.7361099720001221, 0.30555999279022217, 0.8888900279998779, 0.833329975605011, 0.75, 0.75, 0.708329975605011, 0.666670024394989, 0.7361099720001221, 0.19444000720977783, 0.7777799963951111, 0.7361099720001221, 0.6111099720001221, 0.4583300054073334, 0.8611099720001221, 0.2777799963951111, 0.31944000720977783, 0.875, 0.7777799963951111, 0.8055599927902222, 0.708329975605011, 0.833329975605011, 0.6805599927902222, 0.4722200036048889, 0.6805599927902222, 0.625, 0.7222200036048889, 0.875, 0.791670024394989, 0.7361099720001221, 0.5555599927902222, 0.8888900279998779, 0.23611000180244446, 0.8888900279998779, 0.541670024394989, 0.6111099720001221, 0.7361099720001221, 0.7361099720001221, 0.8055599927902222, 0.666670024394989, 0.43055999279022217, 0.8611099720001221, 0.8888900279998779, 0.6805599927902222, 0.5694400072097778, 0.7777799963951111, 0.6111099720001221, 0.375, 0.9305599927902222, 0.7777799963951111, 0.48611000180244446, 0.7361099720001221, 0.666670024394989, 0.5555599927902222, 0.791670024394989, 0.791670024394989, 0.8055599927902222, 0.8194400072097778, 0.875, 0.583329975605011, 0.125, 0.43055999279022217, 0.708329975605011, 0.958329975605011, 0.8055599927902222, 0.8888900279998779, 0.6805599927902222, 0.8888900279998779, 0.7777799963951111, 0.833329975605011, 0.31944000720977783, 0.7222200036048889, 0.5, 0.8472200036048889, 0.8611099720001221, 0.8472200036048889, 0.708329975605011, 0.5277799963951111, 0.708329975605011, 0.5277799963951111, 0.9027799963951111, 0.8055599927902222, 0.18055999279022217, 0.5, 0.6527799963951111, 0.833329975605011, 0.8194400072097778, 0.7361099720001221, 0.7222200036048889, 0.791670024394989, 0.75, 0.791670024394989, 0.7777799963951111, 0.7222200036048889, 0.6805599927902222, 0.75, 0.7638900279998779, 0.625, 0.9027799963951111, 0.708329975605011, 0.833329975605011, 0.8194400072097778, 0.541670024394989, 0.583329975605011, 0.8472200036048889, 0.833329975605011, 0.8472200036048889, 0.8194400072097778, 0.5972200036048889, 0.5555599927902222, 0.833329975605011, 0.7638900279998779, 0.7361099720001221, 0.8888900279998779, 0.8611099720001221, 0.8194400072097778, 0.6527799963951111, 0.8472200036048889, 0.7777799963951111, 0.9305599927902222, 0.833329975605011, 0.916670024394989, 0.7361099720001221, 0.7638900279998779, 0.7777799963951111, 0.7222200036048889, 0.7638900279998779, 0.5138900279998779, 0.7638900279998779, 0.916670024394989, 0.9027799963951111, 0.44444000720977783, 0.23611000180244446, 0.7777799963951111, 0.6805599927902222, 0.833329975605011, 0.8888900279998779, 0.8611099720001221, 0.8888900279998779, 0.583329975605011, 1.0, 0.6111099720001221, 0.6111099720001221, 0.7222200036048889, 0.5138900279998779, 0.833329975605011, 0.8194400072097778, 0.875, 0.7222200036048889, 0.75, 0.875, 0.5, 0.5, 0.7638900279998779, 0.7222200036048889, 0.8055599927902222, 0.8888900279998779, 0.6111099720001221, 0.541670024394989, 0.708329975605011, 0.666670024394989, 0.791670024394989, 0.7222200036048889, 0.75, 0.625, 0.375, 0.7638900279998779, 0.6388900279998779, 0.25, 0.8888900279998779, 0.8888900279998779, 0.8888900279998779, 0.22222000360488892, 0.6111099720001221, 0.916670024394989, 0.708329975605011, 0.666670024394989, 0.6527799963951111, 0.7777799963951111, 0.75, 0.916670024394989, 0.75, 0.791670024394989, 0.7777799963951111, 0.9305599927902222, 0.8194400072097778, 0.875, 0.7638900279998779, 0.7222200036048889, 0.43055999279022217, 0.916670024394989, 0.9861099720001221, 0.8611099720001221, 0.875, 0.6805599927902222, 0.6111099720001221, 0.875, 0.8611099720001221, 0.708329975605011, 0.708329975605011, 0.833329975605011, 0.8194400072097778, 0.6527799963951111, 0.75, 0.5138900279998779, 0.5138900279998779, 0.7777799963951111, 0.6805599927902222, 0.6944400072097778, 0.5555599927902222, 0.5, 0.7777799963951111, 0.791670024394989, 0.6388900279998779, 0.8055599927902222, 0.7777799963951111, 0.3333300054073334, 0.5555599927902222, 0.4583300054073334, 0.6111099720001221, 0.666670024394989, 0.8194400072097778, 0.7361099720001221, 0.8888900279998779, 0.791670024394989, 0.8611099720001221, 0.4722200036048889, 0.833329975605011, 0.833329975605011, 0.8055599927902222, 0.7222200036048889, 0.44444000720977783, 0.6944400072097778, 0.5555599927902222, 0.75, 0.8888900279998779, 0.75, 0.791670024394989, 0.7222200036048889, 0.7222200036048889, 0.7638900279998779, 0.833329975605011, 0.9444400072097778, 0.708329975605011, 0.708329975605011, 0.8472200036048889, 0.8194400072097778, 0.7777799963951111, 0.8055599927902222, 0.8472200036048889, 0.583329975605011, 0.48611000180244446, 0.5555599927902222, 0.8194400072097778, 0.6805599927902222, 0.666670024394989, 0.9027799963951111, 0.833329975605011, 0.8472200036048889, 0.666670024394989, 0.666670024394989, 0.833329975605011, 0.625, 0.5, 0.8611099720001221, 0.583329975605011, 0.5972200036048889, 0.9722200036048889, 0.666670024394989, 0.875, 0.6805599927902222, 0.6944400072097778, 0.75, 0.7361099720001221, 0.5138900279998779, 0.6805599927902222, 0.833329975605011, 0.6388900279998779, 0.6111099720001221, 0.75, 0.791670024394989, 0.625, 0.38888999819755554, 0.791670024394989, 0.625, 0.9027799963951111, 0.666670024394989, 0.9305599927902222, 0.625, 0.5694400072097778, 0.4166699945926666, 0.8888900279998779, 0.75, 0.8194400072097778, 0.7361099720001221, 0.7638900279998779, 0.8194400072097778, 0.625, 0.75, 1.0, 1.0, 0.2916699945926666, 0.666670024394989, 0.833329975605011, 0.6527799963951111, 0.7638900279998779, 0.7777799963951111, 0.666670024394989, 0.8055599927902222, 0.8888900279998779, 0.5972200036048889, 0.6944400072097778, 0.7638900279998779, 0.8055599927902222, 0.875, 0.43055999279022217, 0.6111099720001221, 0.9027799963951111, 0.7638900279998779, 0.625, 0.8611099720001221, 0.75, 0.5555599927902222, 0.6944400072097778, 0.833329975605011, 0.5694400072097778, 0.7777799963951111, 0.5694400072097778, 0.833329975605011, 0.7361099720001221, 0.7222200036048889, 0.75, 0.75, 0.75, 0.8194400072097778, 0.5555599927902222, 0.625, 0.6388900279998779, 0.4166699945926666, 0.5277799963951111, 0.38888999819755554, 0.5972200036048889, 0.7638900279998779, 0.8472200036048889, 0.6388900279998779, 0.875, 0.6944400072097778, 0.7777799963951111, 0.5555599927902222, 0.833329975605011, 0.9305599927902222, 0.4722200036048889, 0.5555599927902222, 0.5694400072097778, 0.8055599927902222, 0.7222200036048889, 0.833329975605011, 0.9444400072097778, 0.7361099720001221, 0.833329975605011, 0.6944400072097778, 0.833329975605011, 0.8055599927902222, 0.4722200036048889, 0.6111099720001221, 0.833329975605011, 0.4027799963951111, 0.6805599927902222, 0.7361099720001221, 0.833329975605011, 0.833329975605011, 0.8055599927902222, 0.6111099720001221, 0.7777799963951111, 0.583329975605011, 0.7222200036048889, 0.541670024394989, 0.7777799963951111, 0.75, 0.8194400072097778, 0.625, 0.833329975605011, 0.4722200036048889, 0.75, 0.916670024394989, 0.44444000720977783, 0.666670024394989, 0.43055999279022217, 0.9722200036048889, 0.708329975605011, 0.625, 0.6111099720001221, 0.75, 0.19444000720977783, 0.6944400072097778, 0.7777799963951111, 0.7361099720001221, 0.666670024394989, 0.8611099720001221, 0.666670024394989, 0.666670024394989, 0.625, 0.6388900279998779, 0.6805599927902222, 0.7777799963951111, 0.7361099720001221, 0.25, 0.7777799963951111, 0.6805599927902222, 0.4722200036048889, 0.708329975605011, 0.6527799963951111, 0.6944400072097778, 0.7361099720001221, 0.7777799963951111, 0.666670024394989, 0.7638900279998779, 0.6527799963951111, 0.7638900279998779, 0.666670024394989, 0.8055599927902222, 0.8472200036048889, 0.8194400072097778, 0.9444400072097778, 0.7777799963951111, 0.7638900279998779, 0.8611099720001221, 0.6388900279998779, 0.791670024394989, 0.75, 0.5555599927902222, 0.375, 0.7777799963951111, 0.8472200036048889, 0.23611000180244446, 0.666670024394989, 0.5972200036048889, 0.791670024394989, 0.833329975605011, 0.6805599927902222, 0.666670024394989, 0.6527799963951111, 0.5138900279998779, 0.6388900279998779, 0.7361099720001221, 0.9027799963951111, 0.625, 0.75, 0.7638900279998779, 0.6805599927902222, 0.6805599927902222, 0.44444000720977783, 0.75, 0.791670024394989, 0.9444400072097778, 0.13888999819755554, 0.791670024394989, 0.4027799963951111, 0.7777799963951111, 0.875, 0.9722200036048889, 0.75, 0.833329975605011, 0.6388900279998779, 0.6111099720001221, 0.8888900279998779, 0.7638900279998779, 0.6805599927902222, 0.7638900279998779, 0.8194400072097778, 0.2916699945926666, 0.5694400072097778, 0.7638900279998779, 0.708329975605011, 0.875, 0.8888900279998779, 0.8194400072097778, 0.5555599927902222, 0.7777799963951111, 0.9027799963951111, 0.791670024394989, 0.7777799963951111, 0.7222200036048889, 0.48611000180244446, 0.666670024394989, 0.6388900279998779, 0.5, 0.4166699945926666, 0.75, 0.791670024394989, 0.6111099720001221, 0.6388900279998779, 0.833329975605011, 0.44444000720977783, 0.8472200036048889, 0.7638900279998779, 0.6944400072097778, 0.8194400072097778, 0.6111099720001221, 0.7638900279998779, 0.43055999279022217, 0.7638900279998779, 0.6388900279998779, 0.6527799963951111, 0.75, 0.9861099720001221, 0.6388900279998779, 0.7361099720001221, 0.7222200036048889, 0.7361099720001221, 0.7638900279998779, 0.8055599927902222, 0.16666999459266663, 0.583329975605011, 0.7638900279998779, 0.7638900279998779, 0.958329975605011, 0.9305599927902222, 0.5138900279998779, 0.8472200036048889, 0.5138900279998779, 0.5277799963951111, 0.8194400072097778, 0.8472200036048889, 0.5138900279998779, 0.75, 0.8611099720001221, 0.7777799963951111, 0.44444000720977783, 0.48611000180244446, 0.6944400072097778, 0.75, 0.8888900279998779, 0.791670024394989, 0.7638900279998779, 0.6111099720001221, 0.541670024394989, 0.5, 0.7222200036048889, 0.6111099720001221, 0.75, 0.9305599927902222, 0.666670024394989, 0.4722200036048889, 0.6805599927902222, 0.75, 0.666670024394989, 0.7777799963951111, 0.6111099720001221, 0.6111099720001221, 0.9861099720001221, 0.833329975605011, 0.8611099720001221, 0.5277799963951111, 0.7777799963951111, 0.9444400072097778, 0.8472200036048889, 0.875, 0.7777799963951111, 0.666670024394989, 0.8611099720001221, 0.44444000720977783, 0.75, 0.583329975605011, 0.6805599927902222, 0.7777799963951111, 0.666670024394989, 0.7361099720001221, 0.7777799963951111, 0.44444000720977783, 0.48611000180244446, 0.6388900279998779, 0.7222200036048889, 0.8055599927902222, 0.8194400072097778, 0.3333300054073334, 0.5972200036048889, 0.6944400072097778, 0.7222200036048889, 0.31944000720977783, 0.5, 0.8472200036048889, 0.8611099720001221, 0.875, 0.8888900279998779, 0.791670024394989, 0.9027799963951111, 0.625, 0.8194400072097778, 0.7361099720001221, 0.666670024394989, 0.791670024394989, 0.8055599927902222, 0.9722200036048889, 0.6944400072097778, 0.875, 0.6388900279998779, 0.6805599927902222, 0.6944400072097778, 0.6527799963951111, 0.8194400072097778, 0.8888900279998779, 0.8055599927902222, 0.625, 0.375, 0.5277799963951111, 0.75, 0.583329975605011, 0.8888900279998779, 0.791670024394989, 0.9305599927902222, 0.8055599927902222, 0.75, 0.8888900279998779, 0.7638900279998779, 0.833329975605011, 0.5694400072097778, 0.75, 0.6111099720001221, 0.7777799963951111, 0.8055599927902222, 0.3333300054073334, 0.583329975605011, 0.6388900279998779, 0.7222200036048889, 0.8888900279998779, 0.44444000720977783, 0.7638900279998779, 0.7222200036048889, 0.7638900279998779, 0.7361099720001221, 0.75, 0.7638900279998779, 0.8055599927902222, 0.4583300054073334, 0.8194400072097778, 0.43055999279022217, 0.6388900279998779, 0.75, 0.8472200036048889, 0.5972200036048889, 0.6111099720001221, 0.75, 0.6527799963951111, 0.708329975605011, 0.5555599927902222, 0.875, 0.6944400072097778, 0.7222200036048889, 0.8472200036048889, 0.7777799963951111, 0.6527799963951111, 0.06944400072097778, 0.625, 0.6527799963951111, 0.7361099720001221, 0.583329975605011, 0.7777799963951111, 0.625, 0.44444000720977783, 0.6944400072097778, 0.8611099720001221, 0.708329975605011, 0.8194400072097778, 0.44444000720977783, 0.5972200036048889, 0.875, 0.7777799963951111, 0.666670024394989, 0.26388999819755554, 0.9444400072097778, 0.75, 0.7777799963951111, 0.48611000180244446, 0.38888999819755554, 0.6805599927902222, 0.7777799963951111, 0.7638900279998779, 0.8888900279998779, 0.7361099720001221, 0.791670024394989, 0.5694400072097778, 0.875, 0.7361099720001221, 0.7777799963951111, 0.7361099720001221, 0.833329975605011, 0.75, 0.6944400072097778, 0.6805599927902222, 0.4722200036048889, 0.4583300054073334, 0.5, 0.833329975605011, 0.833329975605011, 0.666670024394989, 0.833329975605011, 0.6388900279998779, 0.31944000720977783, 0.75, 0.2916699945926666, 0.7222200036048889, 0.6388900279998779, 0.833329975605011, 0.8055599927902222, 0.916670024394989, 0.791670024394989, 0.6527799963951111, 0.791670024394989, 0.7361099720001221, 0.5138900279998779, 0.6388900279998779, 0.5, 0.5972200036048889, 0.8611099720001221, 0.9027799963951111, 0.6944400072097778, 0.5138900279998779, 0.8194400072097778, 0.625, 0.4166699945926666, 0.8194400072097778, 0.3333300054073334, 0.8888900279998779, 0.7777799963951111, 0.2777799963951111, 0.583329975605011, 0.6944400072097778, 0.5138900279998779, 0.75, 0.9305599927902222, 0.7361099720001221, 0.8472200036048889, 0.8055599927902222, 0.791670024394989, 0.48611000180244446, 0.75, 0.8888900279998779, 0.5694400072097778, 0.791670024394989, 0.30555999279022217, 0.8194400072097778, 0.8194400072097778, 0.875, 0.833329975605011, 0.44444000720977783, 0.833329975605011, 0.7777799963951111, 0.666670024394989, 0.7638900279998779, 0.9027799963951111, 0.5694400072097778, 0.6527799963951111, 0.6111099720001221, 0.7638900279998779, 0.541670024394989, 0.7222200036048889, 0.625, 0.9305599927902222, 0.9027799963951111, 0.833329975605011, 0.5, 0.791670024394989, 0.6111099720001221, 0.8055599927902222, 0.8472200036048889, 0.8194400072097778, 0.25, 0.48611000180244446, 0.791670024394989, 0.6805599927902222, 0.583329975605011, 0.958329975605011, 0.6944400072097778, 0.8055599927902222, 0.6944400072097778, 0.8194400072097778, 0.6944400072097778, 1.0, 0.583329975605011, 0.875, 0.7777799963951111, 0.75, 0.5555599927902222, 0.7361099720001221, 0.75, 0.3472200036048889, 0.48611000180244446, 0.25, 0.7777799963951111, 0.4722200036048889, 0.6388900279998779, 0.5138900279998779, 0.708329975605011, 0.791670024394989, 0.7777799963951111, 0.916670024394989, 0.8055599927902222, 0.7777799963951111, 0.6944400072097778, 0.6805599927902222, 0.6805599927902222, 0.833329975605011, 0.8194400072097778, 0.791670024394989, 0.9305599927902222, 0.7777799963951111, 0.75, 0.31944000720977783, 0.7777799963951111, 0.6805599927902222, 0.7222200036048889, 0.9027799963951111, 0.7777799963951111, 0.7777799963951111, 0.5555599927902222, 0.75, 0.5555599927902222, 0.625, 0.708329975605011, 0.583329975605011, 0.2916699945926666, 0.7222200036048889, 0.75, 0.6111099720001221, 0.8194400072097778, 0.6527799963951111, 0.625, 0.5555599927902222, 1.0, 0.6944400072097778, 0.666670024394989, 0.5555599927902222, 0.5277799963951111, 0.2916699945926666, 0.125, 0.8888900279998779, 0.6111099720001221, 0.958329975605011, 0.666670024394989, 0.5555599927902222, 0.75, 0.9444400072097778, 0.7777799963951111, 0.7777799963951111, 0.7777799963951111, 0.7361099720001221, 0.8888900279998779, 0.5694400072097778, 0.833329975605011, 0.6527799963951111, 0.791670024394989, 0.4166699945926666, 0.666670024394989, 0.6111099720001221, 0.541670024394989, 0.625, 0.791670024394989, 0.8055599927902222, 0.8472200036048889, 0.916670024394989, 0.5972200036048889, 0.916670024394989, 0.8194400072097778, 0.8888900279998779, 0.666670024394989, 0.31944000720977783, 0.5277799963951111, 0.7222200036048889, 0.5, 0.8611099720001221, 0.6111099720001221, 0.7777799963951111, 0.6388900279998779, 0.791670024394989, 0.7777799963951111, 0.8888900279998779, 0.625, 0.9027799963951111, 0.9305599927902222, 0.833329975605011, 0.708329975605011, 0.5, 0.7777799963951111, 0.9305599927902222, 0.31944000720977783, 0.5, 0.5, 0.8472200036048889, 0.6944400072097778, 0.7777799963951111, 0.8055599927902222, 0.666670024394989, 0.7361099720001221, 0.8888900279998779, 0.4166699945926666, 0.7361099720001221, 0.30555999279022217, 0.3333300054073334, 0.44444000720977783, 0.791670024394989, 0.4722200036048889, 0.8194400072097778, 0.6805599927902222, 0.833329975605011, 0.6805599927902222, 0.7777799963951111, 0.791670024394989, 0.8194400072097778, 0.6111099720001221, 0.9861099720001221, 0.8472200036048889, 0.8194400072097778, 0.30555999279022217, 0.5, 0.8194400072097778, 0.791670024394989, 0.8611099720001221, 0.583329975605011, 0.916670024394989, 0.6944400072097778, 0.8472200036048889, 0.833329975605011, 0.666670024394989, 0.8194400072097778, 0.5138900279998779, 0.6805599927902222, 0.625, 0.7777799963951111, 0.666670024394989, 0.5972200036048889, 0.30555999279022217, 0.8055599927902222, 0.7222200036048889, 0.5972200036048889, 0.6111099720001221, 0.7638900279998779, 0.5694400072097778, 0.7222200036048889, 0.8055599927902222, 0.666670024394989, 0.9722200036048889, 0.8472200036048889, 0.6527799963951111, 0.833329975605011, 0.23611000180244446, 0.3472200036048889, 0.5277799963951111, 0.4027799963951111, 0.791670024394989, 0.75, 0.7222200036048889, 0.6805599927902222, 0.6527799963951111, 0.666670024394989, 0.9305599927902222, 0.7222200036048889, 0.6527799963951111, 0.5555599927902222, 0.7222200036048889, 0.7638900279998779, 0.5972200036048889, 0.5972200036048889, 0.666670024394989, 0.875, 0.6111099720001221, 0.875, 0.6111099720001221, 0.75, 0.5277799963951111, 0.6944400072097778, 0.6111099720001221, 0.6388900279998779, 0.7361099720001221, 0.8472200036048889, 0.541670024394989, 0.6944400072097778, 0.916670024394989, 0.8055599927902222, 0.791670024394989, 0.9722200036048889, 0.8055599927902222, 0.583329975605011, 0.6805599927902222, 0.7638900279998779, 0.75, 0.7638900279998779, 0.7638900279998779, 0.708329975605011, 0.8472200036048889, 0.7361099720001221, 0.8194400072097778, 0.6944400072097778, 0.666670024394989, 0.791670024394989, 0.6805599927902222, 0.5555599927902222, 0.708329975605011, 0.9444400072097778, 0.708329975605011, 0.5, 0.7222200036048889, 0.43055999279022217, 0.6527799963951111, 0.8055599927902222, 0.9722200036048889, 0.8055599927902222, 0.7638900279998779, 0.833329975605011, 0.7361099720001221, 0.8888900279998779, 0.8888900279998779, 0.875, 0.666670024394989, 0.6527799963951111, 0.22222000360488892, 0.75, 0.75, 0.708329975605011, 0.9861099720001221, 0.791670024394989, 0.6388900279998779, 0.7777799963951111, 0.8888900279998779, 0.8888900279998779, 0.7222200036048889, 0.5555599927902222, 0.7777799963951111, 0.625, 0.8888900279998779, 0.6944400072097778, 0.583329975605011, 0.7638900279998779, 0.7638900279998779, 0.8194400072097778, 0.8472200036048889, 0.7222200036048889, 0.791670024394989, 0.8055599927902222, 0.8888900279998779, 0.583329975605011, 0.7638900279998779, 0.9305599927902222, 0.75, 0.5, 0.4722200036048889, 0.7361099720001221, 0.5, 0.8194400072097778, 0.7777799963951111, 0.583329975605011, 0.9027799963951111, 0.666670024394989, 0.38888999819755554, 0.8055599927902222, 0.6805599927902222, 0.8055599927902222, 0.7361099720001221, 0.5555599927902222, 0.7638900279998779, 0.7361099720001221, 0.833329975605011, 0.8888900279998779, 0.5277799963951111, 0.7638900279998779, 0.7638900279998779, 0.6388900279998779, 0.625, 0.7222200036048889, 0.916670024394989, 0.708329975605011, 0.8611099720001221, 0.8194400072097778, 0.8472200036048889, 0.8888900279998779, 0.36111000180244446, 0.8055599927902222, 0.8611099720001221, 0.791670024394989, 0.708329975605011, 0.7222200036048889, 0.625, 0.708329975605011, 0.625, 0.958329975605011, 0.8055599927902222, 1.0, 0.7361099720001221, 0.541670024394989, 0.5694400072097778, 0.6527799963951111, 0.9027799963951111, 0.48611000180244446, 0.5138900279998779, 0.7638900279998779, 0.7222200036048889, 0.7361099720001221, 0.6111099720001221, 0.8055599927902222, 0.7777799963951111, 0.75, 0.75, 0.6944400072097778, 0.7222200036048889, 0.5138900279998779, 0.875, 0.7777799963951111, 0.7222200036048889, 0.6527799963951111, 0.7638900279998779, 0.75, 0.7222200036048889, 0.666670024394989, 0.7222200036048889, 0.6805599927902222, 0.5555599927902222, 0.875, 0.7361099720001221, 0.5555599927902222, 0.666670024394989, 0.6111099720001221, 0.6805599927902222, 0.7361099720001221, 0.7361099720001221, 0.708329975605011, 0.8888900279998779, 0.7638900279998779, 0.9305599927902222, 0.666670024394989, 0.9444400072097778, 0.9027799963951111, 0.3333300054073334, 0.8055599927902222, 0.7638900279998779, 0.9861099720001221, 0.583329975605011, 0.541670024394989, 0.5138900279998779, 0.8888900279998779, 0.708329975605011, 0.666670024394989, 0.7222200036048889, 0.48611000180244446, 0.833329975605011, 0.8194400072097778, 0.7777799963951111, 0.7222200036048889, 0.9444400072097778, 0.6805599927902222, 0.8888900279998779, 0.8888900279998779, 0.5555599927902222, 0.7222200036048889, 0.7777799963951111, 0.8472200036048889, 0.791670024394989, 0.8888900279998779, 0.875, 0.6388900279998779, 0.5277799963951111, 0.8888900279998779, 0.8194400072097778, 0.8194400072097778, 0.7222200036048889, 0.5555599927902222, 0.31944000720977783, 0.5555599927902222, 0.6805599927902222, 0.6388900279998779, 0.875, 0.6944400072097778, 0.75, 0.791670024394989, 0.5138900279998779, 0.7222200036048889, 0.791670024394989, 0.9444400072097778, 0.7777799963951111, 0.7361099720001221, 0.6805599927902222, 0.833329975605011, 0.4027799963951111, 0.5555599927902222, 0.708329975605011, 0.7638900279998779, 0.541670024394989, 0.6111099720001221, 0.7361099720001221, 0.5, 0.8055599927902222, 0.6944400072097778, 0.5, 0.7638900279998779, 0.833329975605011, 0.5277799963951111, 0.5555599927902222, 0.6805599927902222, 0.666670024394989, 0.666670024394989, 0.833329975605011, 0.583329975605011, 0.8472200036048889, 0.5, 0.8611099720001221, 0.8194400072097778, 0.8194400072097778, 0.833329975605011, 0.875, 0.4166699945926666, 0.9444400072097778, 0.8055599927902222, 0.31944000720977783, 0.8888900279998779, 0.7222200036048889, 0.8055599927902222, 0.8055599927902222, 0.833329975605011, 0.666670024394989, 0.916670024394989, 0.708329975605011, 0.6111099720001221, 0.833329975605011, 0.541670024394989, 0.6111099720001221, 0.958329975605011, 0.708329975605011, 0.7777799963951111, 0.7777799963951111, 0.8194400072097778, 0.6527799963951111, 0.833329975605011, 0.8055599927902222, 0.833329975605011, 0.5972200036048889, 0.6805599927902222, 0.7361099720001221, 0.541670024394989, 0.8888900279998779, 0.48611000180244446, 0.708329975605011, 0.708329975605011, 0.4722200036048889, 0.22222000360488892, 0.75, 0.6111099720001221, 0.666670024394989, 0.7361099720001221, 0.708329975605011, 0.48611000180244446, 0.8055599927902222, 0.8055599927902222, 0.75, 0.8055599927902222, 0.22222000360488892, 0.8055599927902222, 0.8194400072097778, 0.5972200036048889, 0.5, 0.7777799963951111, 0.9027799963951111, 0.6944400072097778, 0.7777799963951111, 0.666670024394989, 0.6111099720001221, 0.6527799963951111, 0.791670024394989, 0.8055599927902222, 0.833329975605011, 0.75, 0.875, 0.7222200036048889, 0.7638900279998779, 0.9444400072097778, 0.958329975605011, 0.7777799963951111, 0.8055599927902222, 0.7777799963951111, 0.8611099720001221, 0.791670024394989, 0.6944400072097778, 0.3472200036048889, 0.708329975605011, 0.6944400072097778, 0.7361099720001221, 0.48611000180244446, 0.5138900279998779, 0.15277999639511108, 0.7222200036048889, 0.6805599927902222, 0.5277799963951111, 0.833329975605011, 0.6527799963951111, 0.6805599927902222, 0.916670024394989, 0.6805599927902222, 0.7638900279998779, 0.5555599927902222, 0.8194400072097778, 0.833329975605011, 0.833329975605011, 0.5138900279998779, 0.7222200036048889, 0.4583300054073334, 0.6111099720001221, 0.75, 0.6527799963951111, 0.7777799963951111, 0.7222200036048889, 0.708329975605011, 0.9305599927902222, 0.8055599927902222, 0.5972200036048889, 0.7777799963951111, 0.4583300054073334, 0.8472200036048889, 0.8194400072097778, 0.5555599927902222, 0.2777799963951111, 0.6805599927902222, 0.3472200036048889, 0.5694400072097778, 0.875, 0.583329975605011, 0.625, 0.8472200036048889, 0.6805599927902222, 0.9305599927902222, 0.8611099720001221, 0.666670024394989, 0.8194400072097778, 0.6527799963951111, 0.30555999279022217, 0.791670024394989, 0.666670024394989, 0.8194400072097778, 0.9027799963951111, 0.4722200036048889, 0.4027799963951111, 0.7777799963951111, 0.9305599927902222, 0.9027799963951111, 0.708329975605011, 0.3333300054073334, 0.833329975605011, 0.666670024394989, 0.6944400072097778, 0.625, 0.7361099720001221, 0.6111099720001221, 0.9027799963951111, 0.7638900279998779, 0.708329975605011, 0.7361099720001221, 0.916670024394989, 0.833329975605011, 0.8611099720001221, 0.7222200036048889, 0.6388900279998779, 0.708329975605011, 0.6944400072097778, 0.8055599927902222, 0.8888900279998779, 0.6388900279998779, 0.8472200036048889, 0.791670024394989, 0.4583300054073334, 0.5138900279998779, 0.8888900279998779, 0.8194400072097778, 0.8611099720001221, 0.38888999819755554, 0.375, 0.9027799963951111, 0.38888999819755554, 0.75, 0.7222200036048889, 0.916670024394989, 0.48611000180244446, 0.8055599927902222, 0.8055599927902222, 0.625, 0.8888900279998779, 0.3472200036048889, 0.4583300054073334, 0.5972200036048889, 0.875, 0.625, 0.6388900279998779, 0.5, 0.7361099720001221, 0.44444000720977783, 0.7361099720001221, 0.5694400072097778, 0.791670024394989, 0.75, 0.6111099720001221, 0.6527799963951111, 0.791670024394989, 0.7361099720001221, 0.8888900279998779, 0.7222200036048889, 0.8055599927902222, 0.8888900279998779, 0.5972200036048889, 0.75, 0.7777799963951111, 0.5277799963951111, 0.5972200036048889, 0.75, 0.75, 0.9027799963951111, 0.9027799963951111, 0.833329975605011, 0.7777799963951111, 0.833329975605011, 0.125, 0.708329975605011, 0.8888900279998779, 0.7777799963951111, 0.8055599927902222, 0.833329975605011, 0.708329975605011, 0.8888900279998779, 0.7638900279998779, 0.75, 0.9027799963951111, 0.75, 0.666670024394989, 0.7777799963951111, 0.5555599927902222, 0.8194400072097778, 0.6388900279998779, 0.4722200036048889, 0.833329975605011, 0.916670024394989, 0.8055599927902222, 0.6111099720001221, 0.5, 0.7638900279998779, 0.708329975605011, 0.7638900279998779, 0.541670024394989, 0.5, 0.541670024394989, 0.7777799963951111, 0.875, 0.8055599927902222, 0.75, 0.7777799963951111, 0.7361099720001221, 0.7361099720001221, 0.791670024394989, 0.791670024394989, 0.6111099720001221, 0.6388900279998779, 0.791670024394989, 0.8194400072097778, 0.6944400072097778, 0.7777799963951111, 0.791670024394989, 0.6527799963951111, 0.7777799963951111, 0.9305599927902222, 0.7222200036048889, 0.7638900279998779, 0.8055599927902222, 0.5972200036048889, 0.666670024394989, 0.6944400072097778, 0.875, 0.875, 0.8055599927902222, 0.22222000360488892, 0.5, 0.4166699945926666, 0.791670024394989, 0.7777799963951111, 0.8055599927902222, 0.708329975605011, 0.6111099720001221, 0.666670024394989, 0.75, 0.8055599927902222, 0.666670024394989, 0.31944000720977783, 0.7222200036048889, 0.6111099720001221, 0.4027799963951111, 0.7777799963951111, 0.833329975605011, 0.8888900279998779, 0.22222000360488892, 0.6111099720001221, 0.5, 0.9027799963951111, 0.7222200036048889, 0.8194400072097778, 0.708329975605011, 0.791670024394989, 0.916670024394989, 0.7361099720001221, 0.5138900279998779, 0.8611099720001221, 0.7777799963951111, 0.541670024394989, 0.6527799963951111, 0.8055599927902222, 0.6944400072097778, 0.22222000360488892, 0.8055599927902222, 0.6944400072097778, 0.75, 0.38888999819755554, 0.7222200036048889, 0.8055599927902222, 0.48611000180244446, 0.7222200036048889, 0.7222200036048889, 0.8472200036048889, 0.7222200036048889, 0.6527799963951111, 0.4166699945926666, 0.7222200036048889, 0.5277799963951111, 0.666670024394989, 0.916670024394989, 0.5555599927902222, 0.6527799963951111, 0.791670024394989, 0.31944000720977783, 0.7638900279998779, 0.583329975605011, 0.875, 0.7777799963951111, 0.833329975605011, 0.6805599927902222, 0.7777799963951111, 0.7777799963951111, 0.38888999819755554, 0.5, 0.3472200036048889, 0.4583300054073334, 0.958329975605011, 0.7361099720001221, 0.75, 0.5972200036048889, 0.8611099720001221, 0.7222200036048889, 0.16666999459266663, 0.7777799963951111, 0.958329975605011, 0.3472200036048889, 0.5277799963951111, 0.7222200036048889, 0.7222200036048889, 0.666670024394989, 0.7361099720001221, 0.7638900279998779, 0.791670024394989, 0.8888900279998779, 0.791670024394989, 0.9444400072097778, 0.8888900279998779, 0.833329975605011, 0.5972200036048889, 0.9444400072097778, 0.875, 0.8472200036048889, 0.3333300054073334, 0.541670024394989, 0.8472200036048889, 0.7777799963951111, 0.7222200036048889, 0.7777799963951111, 0.7361099720001221, 0.75, 0.6527799963951111, 0.75, 0.9444400072097778, 0.6805599927902222, 0.708329975605011, 0.31944000720977783, 0.5277799963951111, 0.5555599927902222, 0.43055999279022217, 0.2916699945926666, 0.7777799963951111, 0.6944400072097778, 0.875, 0.5, 0.583329975605011, 0.7222200036048889, 0.833329975605011, 0.833329975605011, 0.833329975605011, 0.8611099720001221, 0.5972200036048889, 0.7777799963951111, 0.7777799963951111, 0.7222200036048889, 0.43055999279022217, 0.875, 0.3472200036048889, 0.2916699945926666, 0.8194400072097778, 0.583329975605011, 0.5555599927902222, 0.9027799963951111, 0.8055599927902222, 0.8194400072097778, 0.8611099720001221, 0.6805599927902222, 0.8888900279998779, 0.7638900279998779, 0.75, 0.8888900279998779, 0.9444400072097778, 0.625, 0.791670024394989, 0.8055599927902222, 0.666670024394989, 0.5, 0.8611099720001221, 1.0, 0.6944400072097778, 0.7777799963951111, 0.9444400072097778, 0.8055599927902222, 0.666670024394989, 0.7638900279998779, 0.5555599927902222, 0.791670024394989, 0.8472200036048889, 0.666670024394989, 0.7777799963951111, 0.7777799963951111, 0.7638900279998779, 0.8888900279998779, 0.666670024394989, 0.7361099720001221, 0.8888900279998779, 0.2916699945926666, 0.8472200036048889, 0.7638900279998779, 0.7638900279998779, 0.625, 0.7222200036048889, 0.8055599927902222, 0.791670024394989, 0.6111099720001221, 0.5, 0.666670024394989, 0.7777799963951111, 0.7361099720001221, 0.9444400072097778, 0.7361099720001221, 0.833329975605011, 0.6944400072097778, 0.7777799963951111, 0.5, 0.75, 0.791670024394989, 0.8194400072097778, 0.9444400072097778, 0.75, 0.541670024394989, 0.791670024394989, 0.8472200036048889, 0.8611099720001221, 0.8055599927902222, 0.75, 0.7222200036048889, 0.7777799963951111, 0.583329975605011, 0.36111000180244446, 0.5138900279998779, 0.7222200036048889, 0.5694400072097778, 0.8888900279998779, 0.875, 0.7777799963951111, 0.7777799963951111, 0.6388900279998779, 0.625, 0.6944400072097778, 0.7638900279998779, 0.6805599927902222, 0.833329975605011, 0.7777799963951111, 0.7777799963951111, 0.5694400072097778, 0.875, 0.19444000720977783, 0.75, 0.3472200036048889, 0.6527799963951111, 0.8055599927902222, 0.583329975605011, 0.7638900279998779, 0.8888900279998779, 0.5555599927902222, 0.8888900279998779, 0.7361099720001221, 0.7222200036048889, 0.8472200036048889, 0.8611099720001221, 0.6944400072097778, 0.708329975605011, 0.791670024394989, 0.791670024394989, 0.875, 0.7222200036048889, 0.8055599927902222, 0.7222200036048889, 0.7777799963951111, 0.7361099720001221, 0.7638900279998779, 0.31944000720977783, 0.8611099720001221, 0.9444400072097778, 0.7222200036048889, 0.75, 0.8888900279998779, 0.48611000180244446, 0.7361099720001221, 0.8055599927902222, 0.916670024394989, 0.6805599927902222, 0.6944400072097778, 0.8611099720001221, 0.625, 0.5, 0.666670024394989, 0.8611099720001221, 0.5555599927902222, 0.7777799963951111, 0.22222000360488892, 0.22222000360488892, 0.791670024394989, 0.6111099720001221, 0.5972200036048889, 0.6111099720001221, 0.583329975605011, 0.7777799963951111, 0.666670024394989, 0.6805599927902222, 0.4722200036048889, 0.7638900279998779, 0.75, 0.833329975605011, 0.6527799963951111, 0.7638900279998779, 0.7361099720001221, 0.7777799963951111, 0.7222200036048889, 0.6527799963951111, 0.7361099720001221, 0.7777799963951111, 0.75, 0.9722200036048889, 0.7777799963951111, 0.7361099720001221, 0.8472200036048889, 0.9027799963951111, 0.7361099720001221, 0.7777799963951111, 0.7777799963951111, 0.8055599927902222, 0.8611099720001221, 0.9027799963951111, 0.8194400072097778, 0.5555599927902222, 0.4722200036048889, 0.8194400072097778, 0.625, 0.7638900279998779, 0.6527799963951111, 0.8472200036048889, 0.7638900279998779, 0.30555999279022217, 0.583329975605011, 0.6944400072097778, 0.833329975605011, 0.75, 0.833329975605011, 0.833329975605011, 0.833329975605011, 0.583329975605011, 0.7222200036048889, 0.833329975605011, 0.7222200036048889, 1.0, 0.6527799963951111, 0.8888900279998779, 0.6944400072097778, 0.75, 0.7222200036048889, 0.7777799963951111, 0.7222200036048889, 0.8055599927902222, 0.9444400072097778, 0.6111099720001221, 0.8611099720001221, 0.22222000360488892, 0.7777799963951111, 0.7361099720001221, 0.4166699945926666, 0.6944400072097778, 0.916670024394989, 0.875, 0.7222200036048889, 0.7222200036048889, 0.7777799963951111, 0.8611099720001221, 0.6527799963951111, 0.875, 0.875, 0.6388900279998779, 0.7638900279998779, 0.75, 0.6527799963951111, 0.8194400072097778, 0.916670024394989, 0.8194400072097778, 0.8888900279998779, 0.6944400072097778, 0.875, 0.7361099720001221, 0.5138900279998779, 0.7777799963951111, 0.9444400072097778, 0.791670024394989, 0.625, 0.8055599927902222, 0.6527799963951111, 0.8055599927902222, 0.6388900279998779, 0.666670024394989, 0.7777799963951111, 0.7222200036048889, 0.7222200036048889, 0.833329975605011, 0.7222200036048889, 0.7222200036048889, 0.5694400072097778, 0.583329975605011, 0.7222200036048889, 0.666670024394989, 0.708329975605011, 0.6388900279998779, 0.7638900279998779, 0.75, 0.8194400072097778, 0.833329975605011, 0.8611099720001221, 0.666670024394989, 0.7638900279998779, 0.875, 0.8611099720001221, 0.31944000720977783, 0.6111099720001221, 0.75, 0.916670024394989, 0.43055999279022217, 0.75, 0.8194400072097778, 0.7222200036048889, 0.5555599927902222, 0.7638900279998779, 0.625, 0.5555599927902222, 0.6805599927902222, 0.5972200036048889, 0.7777799963951111, 0.6805599927902222, 0.6111099720001221, 0.833329975605011, 0.6805599927902222, 0.6944400072097778, 0.5694400072097778, 0.7222200036048889, 0.7777799963951111, 0.666670024394989, 0.7638900279998779, 0.7222200036048889, 0.791670024394989, 0.7222200036048889, 0.8472200036048889, 0.7361099720001221, 0.5277799963951111, 0.833329975605011, 0.75, 0.7777799963951111, 0.916670024394989, 0.583329975605011, 0.5, 0.8055599927902222, 0.75, 0.5972200036048889, 0.7222200036048889, 0.75, 0.7638900279998779, 0.6388900279998779, 0.875, 0.875, 0.8611099720001221, 0.6111099720001221, 0.916670024394989, 0.708329975605011, 0.8472200036048889, 0.5, 0.5555599927902222, 0.9027799963951111, 0.75, 0.666670024394989, 0.8888900279998779, 0.5555599927902222, 0.7222200036048889, 0.7222200036048889, 0.791670024394989, 0.833329975605011, 0.6527799963951111, 0.5, 0.3333300054073334, 0.7777799963951111, 0.6388900279998779, 0.875, 0.916670024394989, 0.9444400072097778, 0.8888900279998779, 0.791670024394989, 0.75, 0.7222200036048889, 0.48611000180244446, 0.8611099720001221, 0.8472200036048889, 0.875, 0.666670024394989, 0.5138900279998779, 0.7222200036048889, 0.3333300054073334, 0.9444400072097778, 0.7222200036048889, 0.833329975605011, 0.8055599927902222, 0.7638900279998779, 0.7638900279998779, 0.6805599927902222, 0.833329975605011, 0.6805599927902222, 0.833329975605011, 0.8611099720001221, 0.75, 0.6944400072097778, 0.6388900279998779, 0.7361099720001221, 0.833329975605011, 0.8611099720001221, 0.5, 0.6388900279998779, 0.6944400072097778, 0.5, 0.5, 0.8194400072097778, 0.8055599927902222, 0.7361099720001221, 0.8194400072097778, 0.7361099720001221, 0.8194400072097778, 0.8888900279998779, 0.9027799963951111, 0.6805599927902222, 0.8194400072097778, 0.6805599927902222, 0.7777799963951111, 0.8055599927902222, 0.7222200036048889, 0.7777799963951111, 0.666670024394989, 0.7777799963951111, 0.6527799963951111, 0.916670024394989, 0.8194400072097778, 0.833329975605011, 0.791670024394989, 0.8472200036048889, 0.7638900279998779, 0.791670024394989, 0.7638900279998779, 0.833329975605011, 0.6805599927902222, 0.7222200036048889, 0.875, 0.666670024394989, 0.6111099720001221, 0.7777799963951111, 0.5277799963951111, 0.8194400072097778, 0.791670024394989, 0.6944400072097778, 0.11111000180244446, 1.0, 0.9444400072097778, 0.2777799963951111, 0.8888900279998779, 0.833329975605011, 0.7638900279998779, 0.8888900279998779, 0.75, 0.833329975605011, 0.7777799963951111, 0.7361099720001221, 0.5138900279998779, 0.666670024394989, 0.7222200036048889, 0.875, 0.8055599927902222, 0.6527799963951111, 0.7777799963951111, 0.6944400072097778, 0.8194400072097778, 0.9027799963951111, 0.4166699945926666, 0.666670024394989, 0.708329975605011, 0.7222200036048889, 0.43055999279022217, 0.75, 0.75, 0.38888999819755554, 0.6111099720001221, 0.7222200036048889, 0.6111099720001221, 0.7777799963951111, 0.75, 0.8055599927902222, 0.5555599927902222, 0.6944400072097778, 0.708329975605011, 0.541670024394989, 0.6111099720001221, 0.8472200036048889, 0.7777799963951111, 0.6527799963951111, 0.6388900279998779, 0.8888900279998779, 0.38888999819755554, 0.9305599927902222, 0.7361099720001221, 0.8611099720001221, 0.7222200036048889, 0.583329975605011, 0.6527799963951111, 0.5, 0.6111099720001221, 0.791670024394989, 0.625, 0.7777799963951111, 0.8611099720001221, 0.7222200036048889, 0.6805599927902222, 0.791670024394989, 0.5555599927902222, 0.8194400072097778, 0.6388900279998779, 0.541670024394989, 0.875, 0.8055599927902222, 0.6388900279998779, 0.7222200036048889, 0.8194400072097778, 0.7777799963951111, 0.8888900279998779, 0.6805599927902222, 0.7361099720001221, 0.16666999459266663, 0.7638900279998779, 0.7361099720001221, 0.7638900279998779, 0.833329975605011, 0.8611099720001221, 0.833329975605011, 0.958329975605011, 0.7777799963951111, 0.666670024394989, 0.6388900279998779, 0.6527799963951111, 0.5138900279998779, 0.7777799963951111, 0.8055599927902222, 0.8472200036048889, 0.75, 0.7222200036048889, 0.8888900279998779, 0.7638900279998779, 0.75, 0.6388900279998779, 0.5972200036048889, 0.6388900279998779, 0.4583300054073334, 0.7638900279998779, 0.7638900279998779, 0.625, 0.5694400072097778, 0.9444400072097778, 0.8472200036048889, 0.666670024394989, 0.833329975605011, 0.75, 0.8888900279998779, 0.791670024394989, 0.833329975605011, 0.541670024394989, 0.833329975605011, 0.8611099720001221, 0.833329975605011, 0.8472200036048889, 0.833329975605011, 0.8611099720001221, 0.958329975605011, 0.7361099720001221, 0.8055599927902222, 0.7777799963951111, 0.6944400072097778, 0.8888900279998779, 0.5138900279998779, 0.8194400072097778, 0.5555599927902222, 0.791670024394989, 0.7638900279998779, 0.875, 0.75, 0.833329975605011, 0.8194400072097778, 0.75, 0.7777799963951111, 0.5972200036048889, 0.4722200036048889, 0.7777799963951111, 0.833329975605011, 0.8472200036048889, 0.75, 0.7361099720001221, 0.9027799963951111, 0.6527799963951111, 0.5694400072097778, 0.8194400072097778, 0.708329975605011, 0.8888900279998779, 0.6111099720001221, 0.5694400072097778, 0.8888900279998779, 0.5972200036048889, 0.708329975605011, 0.833329975605011, 0.708329975605011, 0.583329975605011, 0.8472200036048889, 0.5555599927902222, 0.22222000360488892, 0.48611000180244446, 0.7222200036048889, 0.833329975605011, 0.44444000720977783, 0.6388900279998779, 0.7638900279998779, 0.7222200036048889, 0.6388900279998779, 0.43055999279022217, 0.7777799963951111, 0.7361099720001221, 0.8611099720001221, 0.625, 0.7777799963951111, 0.7777799963951111, 0.666670024394989, 0.5555599927902222, 0.8194400072097778, 0.708329975605011, 0.8888900279998779, 0.25, 0.666670024394989, 0.44444000720977783, 0.6111099720001221, 0.8055599927902222, 0.8472200036048889, 0.09722200036048889, 0.583329975605011, 0.75, 0.875, 0.8611099720001221, 0.791670024394989, 0.9444400072097778, 0.5555599927902222, 0.6527799963951111, 0.7361099720001221, 0.875, 0.833329975605011, 0.7222200036048889, 0.7777799963951111, 0.7777799963951111, 0.7638900279998779, 0.7777799963951111, 0.833329975605011, 0.708329975605011, 0.8611099720001221, 0.6111099720001221, 0.791670024394989, 0.75, 0.7638900279998779, 0.7361099720001221, 0.8472200036048889, 0.8194400072097778, 0.5972200036048889, 0.8888900279998779, 0.44444000720977783, 0.6805599927902222, 0.7638900279998779, 0.4166699945926666, 0.6805599927902222, 0.6527799963951111, 0.44444000720977783, 0.6944400072097778, 0.7222200036048889, 0.708329975605011, 0.708329975605011, 0.833329975605011, 0.8888900279998779, 0.15277999639511108, 0.7222200036048889, 0.9444400072097778, 0.4583300054073334, 0.583329975605011, 0.708329975605011, 0.6944400072097778, 0.8055599927902222, 0.6527799963951111, 0.8055599927902222, 0.583329975605011, 0.8472200036048889, 0.8194400072097778, 0.8472200036048889, 0.7777799963951111, 0.7361099720001221, 0.5277799963951111, 0.7638900279998779, 0.9861099720001221, 0.6944400072097778, 0.8055599927902222, 0.8611099720001221, 0.9305599927902222, 0.791670024394989, 0.625, 0.7777799963951111, 0.6805599927902222, 0.8194400072097778, 0.8055599927902222, 0.8611099720001221, 0.8055599927902222, 0.5694400072097778, 0.6527799963951111, 0.8194400072097778, 0.708329975605011, 0.6388900279998779, 0.9305599927902222, 0.7361099720001221, 0.7222200036048889, 0.833329975605011, 0.708329975605011, 0.791670024394989, 0.8472200036048889, 0.6388900279998779, 0.6388900279998779, 0.48611000180244446, 0.5138900279998779, 0.6388900279998779, 0.8055599927902222, 0.6111099720001221, 0.8888900279998779, 0.7222200036048889, 0.833329975605011, 0.583329975605011, 0.875, 0.7638900279998779, 0.7777799963951111, 0.6944400072097778, 0.875, 0.6805599927902222, 0.875, 0.7638900279998779, 0.791670024394989, 0.8194400072097778, 0.8472200036048889, 0.5694400072097778, 0.791670024394989, 0.5555599927902222, 0.625, 0.666670024394989, 0.7638900279998779, 0.666670024394989, 0.8611099720001221, 0.8611099720001221, 0.541670024394989, 0.75, 0.9861099720001221, 0.75, 0.666670024394989, 0.31944000720977783, 0.833329975605011, 0.7638900279998779, 0.8472200036048889, 0.6388900279998779, 0.5138900279998779, 0.8472200036048889, 0.541670024394989, 0.7222200036048889, 0.5555599927902222, 0.6805599927902222, 0.75, 0.75, 0.5, 0.708329975605011, 0.7777799963951111, 0.7222200036048889, 0.7361099720001221, 0.48611000180244446, 0.6527799963951111, 0.833329975605011, 0.6944400072097778, 0.6111099720001221, 0.7777799963951111, 0.9444400072097778, 0.8611099720001221, 0.7638900279998779, 0.708329975605011, 0.7222200036048889, 0.666670024394989, 0.7361099720001221, 0.7777799963951111, 0.8194400072097778, 0.666670024394989, 0.8055599927902222, 0.43055999279022217, 0.18055999279022217, 0.5, 0.708329975605011, 0.8055599927902222, 0.791670024394989, 0.8472200036048889, 0.8472200036048889, 0.833329975605011, 0.6111099720001221, 0.666670024394989, 0.4166699945926666, 0.7777799963951111, 0.4583300054073334, 0.8194400072097778, 0.6388900279998779, 0.8611099720001221, 0.6944400072097778, 0.8194400072097778, 0.6805599927902222, 0.666670024394989, 0.5972200036048889, 0.6944400072097778, 0.8472200036048889, 0.6944400072097778, 0.4166699945926666, 0.791670024394989, 0.8055599927902222, 0.7361099720001221, 0.6944400072097778, 0.791670024394989, 0.6944400072097778, 0.791670024394989, 0.7777799963951111, 0.6944400072097778, 0.833329975605011, 0.916670024394989, 0.7222200036048889, 0.7361099720001221, 0.833329975605011, 0.38888999819755554, 0.7222200036048889, 0.6944400072097778, 0.6388900279998779, 0.875, 0.791670024394989, 0.5972200036048889, 0.5, 0.875, 0.666670024394989, 0.2916699945926666, 0.8472200036048889, 0.8194400072097778, 0.7361099720001221, 0.6944400072097778, 0.6944400072097778, 0.8194400072097778, 0.8611099720001221, 0.7361099720001221, 0.8055599927902222, 0.6944400072097778, 0.9027799963951111, 0.5694400072097778, 0.875, 0.7638900279998779, 0.2916699945926666, 0.5694400072097778, 0.6944400072097778, 0.708329975605011, 0.5277799963951111, 0.666670024394989, 0.5277799963951111, 0.6805599927902222, 0.8055599927902222, 0.375, 0.6805599927902222, 0.6388900279998779, 0.833329975605011, 0.7361099720001221, 0.6944400072097778, 0.9444400072097778, 0.833329975605011, 0.8888900279998779, 0.5972200036048889, 0.8055599927902222, 0.8055599927902222, 0.875, 0.8194400072097778, 0.708329975605011, 0.6111099720001221, 0.666670024394989, 0.791670024394989, 0.708329975605011, 0.6111099720001221, 0.666670024394989, 0.6944400072097778, 0.9305599927902222, 0.8888900279998779, 0.7638900279998779, 0.875, 0.958329975605011, 0.8472200036048889, 0.7222200036048889, 0.375, 0.875, 0.8472200036048889, 0.36111000180244446, 0.6944400072097778, 0.7638900279998779, 0.8194400072097778, 0.6805599927902222, 0.5972200036048889, 0.541670024394989, 0.625, 0.5138900279998779, 0.5555599927902222, 0.6805599927902222, 0.36111000180244446, 0.5694400072097778, 0.666670024394989, 0.8055599927902222, 0.8055599927902222, 0.8194400072097778, 0.666670024394989, 0.7361099720001221, 0.6527799963951111, 0.5277799963951111, 0.6944400072097778, 0.666670024394989, 0.875, 0.833329975605011, 0.833329975605011, 0.6944400072097778, 0.833329975605011, 0.666670024394989, 0.791670024394989, 0.7222200036048889, 0.833329975605011, 0.8611099720001221, 0.8055599927902222, 0.7361099720001221, 0.8472200036048889, 0.8888900279998779, 0.5972200036048889, 0.708329975605011, 0.7222200036048889, 0.708329975605011, 0.5555599927902222, 0.666670024394989, 0.583329975605011, 0.833329975605011, 0.5694400072097778, 0.8611099720001221, 0.583329975605011, 0.9027799963951111, 0.75, 0.8888900279998779, 0.5, 0.30555999279022217, 0.4722200036048889, 0.8611099720001221, 0.2777799963951111, 0.8472200036048889, 0.9027799963951111, 0.7361099720001221, 0.5, 0.5555599927902222, 0.791670024394989, 0.7361099720001221, 0.8194400072097778, 0.7777799963951111, 0.4583300054073334, 0.6944400072097778, 0.6944400072097778, 0.8055599927902222, 0.7638900279998779, 0.6805599927902222, 1.0, 0.7361099720001221, 0.7361099720001221, 0.7361099720001221, 0.625, 0.5972200036048889, 0.8194400072097778, 0.44444000720977783, 0.541670024394989, 0.583329975605011, 0.75, 0.6111099720001221, 0.8888900279998779, 0.6111099720001221, 0.7222200036048889, 0.6527799963951111, 0.583329975605011, 0.5972200036048889, 0.9444400072097778, 0.708329975605011, 0.7777799963951111, 0.4583300054073334, 0.666670024394989, 0.833329975605011, 0.8194400072097778, 0.6388900279998779, 0.7361099720001221, 0.8055599927902222, 0.708329975605011, 0.6944400072097778, 0.75, 0.916670024394989, 0.7222200036048889, 0.5694400072097778, 0.833329975605011, 0.625, 0.8888900279998779, 0.708329975605011, 0.791670024394989, 0.6111099720001221, 0.5972200036048889, 0.708329975605011, 0.6388900279998779, 0.708329975605011, 0.666670024394989, 0.7777799963951111, 0.5138900279998779, 0.75, 0.7222200036048889, 0.3333300054073334, 0.625, 0.8611099720001221, 0.6944400072097778, 0.666670024394989, 0.6805599927902222, 0.791670024394989, 0.38888999819755554, 0.5694400072097778, 0.44444000720977783, 0.7361099720001221, 0.7777799963951111, 0.8472200036048889, 0.8611099720001221, 0.833329975605011, 0.541670024394989, 0.791670024394989, 0.5555599927902222, 0.5555599927902222, 0.6805599927902222, 0.7777799963951111, 0.666670024394989, 0.6805599927902222, 0.8611099720001221, 0.75, 0.583329975605011, 0.6944400072097778, 0.75, 0.8611099720001221, 0.6111099720001221, 0.8472200036048889, 0.44444000720977783, 0.8472200036048889, 0.2777799963951111, 0.7222200036048889, 0.7777799963951111, 0.7777799963951111, 0.5555599927902222, 0.583329975605011, 0.6527799963951111, 0.7222200036048889, 0.5, 0.666670024394989, 0.666670024394989, 0.7638900279998779, 0.5138900279998779, 0.4027799963951111, 0.6944400072097778, 0.666670024394989, 0.7222200036048889, 0.791670024394989, 0.5555599927902222, 0.8055599927902222, 0.48611000180244446, 0.7638900279998779, 0.666670024394989, 0.958329975605011, 0.6944400072097778, 0.9027799963951111, 0.6527799963951111, 0.708329975605011, 0.5277799963951111, 0.3472200036048889, 0.4722200036048889, 0.8611099720001221, 0.875, 0.9305599927902222, 0.875, 0.6388900279998779, 0.791670024394989, 0.6805599927902222, 0.6527799963951111, 0.5, 0.708329975605011, 0.7638900279998779, 0.583329975605011, 0.6111099720001221, 0.7361099720001221, 0.8055599927902222, 0.833329975605011, 0.708329975605011, 0.36111000180244446, 0.8888900279998779, 0.4166699945926666, 0.7638900279998779, 0.9305599927902222, 0.44444000720977783, 0.666670024394989, 0.5, 0.8472200036048889, 0.31944000720977783, 0.7222200036048889, 0.625, 0.38888999819755554, 0.6111099720001221, 0.8194400072097778, 0.5694400072097778, 0.6805599927902222, 0.7361099720001221, 0.833329975605011, 0.625, 0.5, 0.6111099720001221, 0.7638900279998779, 0.916670024394989, 0.4722200036048889, 0.43055999279022217, 0.583329975605011, 0.6527799963951111, 0.3333300054073334, 0.16666999459266663, 0.8472200036048889, 0.25, 0.75, 0.7777799963951111, 0.8055599927902222, 0.75, 0.5694400072097778, 0.625, 0.708329975605011, 0.7222200036048889, 0.38888999819755554, 0.7777799963951111, 0.666670024394989, 0.7222200036048889, 0.6388900279998779, 0.5277799963951111, 0.666670024394989, 0.7638900279998779, 0.791670024394989, 0.6944400072097778, 0.6388900279998779, 0.8888900279998779, 0.875, 0.8055599927902222, 0.7638900279998779, 0.833329975605011, 0.8194400072097778, 0.9305599927902222, 0.8055599927902222, 0.6944400072097778, 0.791670024394989, 0.7222200036048889, 0.6111099720001221, 0.666670024394989, 0.8472200036048889, 0.8611099720001221, 0.8194400072097778, 0.541670024394989, 0.5972200036048889, 0.44444000720977783, 0.6388900279998779, 0.8055599927902222, 0.8611099720001221, 0.583329975605011, 0.5277799963951111, 1.0, 0.833329975605011, 0.833329975605011, 0.5, 0.5, 0.7222200036048889, 0.625, 0.6805599927902222, 0.7777799963951111, 0.8611099720001221, 0.6805599927902222, 0.833329975605011, 0.625, 0.8888900279998779, 0.7222200036048889, 0.7777799963951111, 0.6805599927902222, 0.5694400072097778, 1.0, 0.5138900279998779, 0.4166699945926666, 0.8194400072097778, 0.8194400072097778, 0.6111099720001221, 0.23611000180244446, 0.7222200036048889, 0.44444000720977783, 0.9444400072097778, 0.6805599927902222, 0.6388900279998779, 0.75, 0.8472200036048889, 0.6944400072097778, 0.708329975605011, 0.8888900279998779, 0.5138900279998779, 0.8472200036048889, 0.30555999279022217, 0.6805599927902222, 0.8472200036048889, 0.6805599927902222, 0.6944400072097778, 0.4027799963951111, 0.7222200036048889, 0.7777799963951111, 0.5972200036048889, 0.75, 0.7777799963951111, 0.8055599927902222, 0.5277799963951111, 0.7222200036048889, 0.583329975605011, 0.7638900279998779, 0.8611099720001221, 0.6527799963951111, 0.625, 0.8888900279998779, 0.4166699945926666, 0.7777799963951111, 0.7638900279998779, 0.5555599927902222, 0.6944400072097778, 0.8194400072097778, 0.833329975605011, 0.7222200036048889, 0.791670024394989, 0.9305599927902222, 0.7222200036048889, 0.7777799963951111, 0.708329975605011, 0.6805599927902222, 0.7361099720001221, 0.791670024394989, 0.708329975605011, 0.8611099720001221, 0.791670024394989, 0.7222200036048889, 0.4166699945926666, 0.9444400072097778, 0.8472200036048889, 0.75, 0.7361099720001221, 0.9305599927902222, 0.8194400072097778, 0.3333300054073334, 0.7361099720001221, 0.666670024394989, 0.875, 0.791670024394989, 0.9444400072097778, 0.5555599927902222, 0.6944400072097778, 0.5138900279998779, 0.7638900279998779, 0.7222200036048889, 0.6944400072097778, 0.6944400072097778, 0.708329975605011, 0.44444000720977783, 0.5277799963951111, 0.9305599927902222, 0.791670024394989, 0.05555599927902222, 0.6111099720001221, 0.708329975605011, 0.6944400072097778, 0.6111099720001221, 0.6527799963951111, 0.5, 0.8055599927902222, 0.7222200036048889, 0.4027799963951111, 0.8888900279998779, 0.8888900279998779, 0.4583300054073334, 0.6944400072097778, 0.8888900279998779, 0.6805599927902222, 0.6944400072097778, 0.9027799963951111, 0.4583300054073334, 0.666670024394989, 0.666670024394989, 0.7222200036048889, 0.30555999279022217, 0.7638900279998779, 0.6805599927902222, 0.7361099720001221, 0.8472200036048889, 0.6805599927902222, 0.916670024394989, 0.8888900279998779, 0.75, 0.833329975605011, 0.38888999819755554, 0.875, 0.708329975605011, 0.5972200036048889, 0.7222200036048889, 0.7777799963951111, 0.625, 0.8055599927902222, 0.5972200036048889, 0.7222200036048889, 0.6944400072097778, 0.791670024394989, 0.666670024394989, 0.5138900279998779, 0.6388900279998779, 0.6319400072097778, 0.666670024394989, 0.666670024394989, 0.75, 0.23611000180244446, 0.833329975605011, 0.5694400072097778, 0.5277799963951111, 0.8888900279998779, 0.8472200036048889, 0.7777799963951111, 0.6944400072097778, 0.958329975605011, 0.6805599927902222, 0.6111099720001221, 0.7638900279998779, 0.5138900279998779, 0.8472200036048889, 0.833329975605011, 0.875, 0.4583300054073334, 0.875, 0.6805599927902222, 0.8055599927902222, 0.625, 0.7777799963951111, 0.7777799963951111, 0.43055999279022217, 0.5138900279998779, 0.6388900279998779, 0.708329975605011, 0.4583300054073334, 0.8611099720001221, 0.6111099720001221, 0.6111099720001221, 0.6388900279998779, 0.6527799963951111, 0.7361099720001221, 0.708329975605011, 0.4027799963951111, 0.75, 0.833329975605011, 0.916670024394989, 0.75, 0.8194400072097778, 0.875, 0.2777799963951111, 0.8194400072097778, 0.7361099720001221, 0.2777799963951111, 0.875, 0.833329975605011, 0.8055599927902222, 0.666670024394989, 0.9027799963951111, 0.6805599927902222, 0.9305599927902222, 0.833329975605011, 0.5138900279998779, 0.7638900279998779, 0.7638900279998779, 0.541670024394989, 0.75, 0.7777799963951111, 0.6388900279998779, 0.6805599927902222, 0.541670024394989, 0.4583300054073334, 0.7222200036048889, 0.583329975605011, 0.5555599927902222, 0.8194400072097778, 0.48611000180244446, 0.6527799963951111, 0.6527799963951111, 0.708329975605011, 0.38888999819755554, 0.3333300054073334, 0.791670024394989, 0.7777799963951111, 0.38888999819755554, 0.833329975605011, 0.4027799963951111, 0.7638900279998779, 0.75, 0.7777799963951111, 0.6388900279998779, 0.625, 0.7638900279998779, 0.8055599927902222, 0.666670024394989, 0.6805599927902222, 0.583329975605011, 0.6527799963951111, 0.8611099720001221, 0.6805599927902222, 0.875, 0.7777799963951111, 0.9027799963951111, 0.9722200036048889, 0.791670024394989, 0.6527799963951111, 0.8194400072097778, 0.583329975605011, 0.8194400072097778, 0.6111099720001221, 0.7638900279998779, 0.75, 0.6944400072097778, 0.9027799963951111, 0.916670024394989, 0.7638900279998779, 0.75, 0.6388900279998779, 0.4722200036048889, 0.5972200036048889, 0.75, 0.833329975605011, 0.9027799963951111, 0.8194400072097778, 0.7638900279998779, 0.7222200036048889, 0.666670024394989, 0.6527799963951111, 0.708329975605011, 0.8888900279998779, 0.8611099720001221, 0.666670024394989, 0.8194400072097778, 0.6111099720001221, 0.875, 0.5972200036048889, 0.833329975605011, 0.958329975605011, 0.8055599927902222, 0.6527799963951111, 0.5, 0.6111099720001221, 0.583329975605011, 0.5694400072097778, 0.3333300054073334, 0.5, 0.3472200036048889, 0.23611000180244446, 0.7222200036048889, 0.2777799963951111, 0.791670024394989, 0.9305599927902222, 0.7638900279998779, 0.791670024394989, 0.7777799963951111, 0.5555599927902222, 0.5694400072097778, 0.75, 0.5694400072097778, 0.75, 0.7777799963951111, 0.22222000360488892, 0.75, 0.833329975605011, 0.833329975605011, 0.75, 0.8888900279998779, 0.708329975605011, 0.8194400072097778, 0.6527799963951111, 0.6111099720001221, 0.708329975605011, 0.6388900279998779, 0.708329975605011, 0.7222200036048889, 0.7638900279998779, 0.6388900279998779, 0.8472200036048889, 0.875, 0.7361099720001221, 0.7222200036048889, 0.6805599927902222, 0.22222000360488892, 0.7361099720001221, 0.9305599927902222, 0.6111099720001221, 0.8611099720001221, 0.8472200036048889, 0.666670024394989, 0.541670024394989, 0.791670024394989, 0.7777799963951111, 0.666670024394989, 0.8611099720001221, 0.833329975605011, 0.6111099720001221, 0.8472200036048889, 0.6111099720001221, 0.8611099720001221, 0.2916699945926666, 0.666670024394989, 0.8472200036048889, 0.5, 0.6944400072097778, 0.6944400072097778, 0.6944400072097778, 0.791670024394989, 0.791670024394989, 0.7777799963951111, 0.7638900279998779, 0.6527799963951111, 0.7777799963951111, 0.8194400072097778, 0.5138900279998779, 0.7222200036048889, 0.791670024394989, 0.8472200036048889, 0.7638900279998779, 0.2777799963951111, 0.708329975605011, 0.791670024394989, 0.6944400072097778, 0.44444000720977783, 0.9305599927902222, 0.6944400072097778, 1.0, 0.8055599927902222, 0.708329975605011, 0.4583300054073334, 0.38888999819755554, 0.4027799963951111, 0.833329975605011, 0.583329975605011, 0.666670024394989, 0.18055999279022217, 0.20833000540733337, 0.8611099720001221, 0.6527799963951111, 0.3333300054073334, 0.6527799963951111, 0.7777799963951111, 0.708329975605011, 0.6805599927902222, 0.5972200036048889, 0.48611000180244446, 0.48611000180244446, 0.875, 0.4027799963951111, 0.7638900279998779, 0.75, 0.38888999819755554, 0.5, 0.2777799963951111, 0.791670024394989, 0.7777799963951111, 0.5138900279998779, 0.875, 0.8472200036048889, 0.6527799963951111, 0.36111000180244446, 0.9722200036048889, 0.625, 0.25, 0.7361099720001221, 0.875, 0.6805599927902222, 0.5277799963951111, 0.6805599927902222, 0.7222200036048889, 0.8888900279998779, 0.833329975605011, 0.5972200036048889, 0.75, 0.625, 0.9027799963951111, 0.625, 0.6527799963951111, 0.7638900279998779, 0.666670024394989, 0.6805599927902222, 0.583329975605011, 0.6527799963951111, 0.7222200036048889, 0.791670024394989, 0.75, 0.5972200036048889, 0.5, 0.708329975605011, 0.8472200036048889, 0.7361099720001221, 0.7222200036048889, 0.6527799963951111, 0.5, 0.3472200036048889, 0.9027799963951111, 0.7361099720001221, 0.5, 0.708329975605011, 0.8611099720001221, 0.6388900279998779, 0.375, 0.7777799963951111, 0.5555599927902222, 0.791670024394989, 0.8472200036048889, 0.8888900279998779, 0.666670024394989, 0.5972200036048889, 0.916670024394989, 0.8472200036048889, 0.7361099720001221, 0.5138900279998779, 0.75, 0.6944400072097778, 0.7222200036048889, 0.7222200036048889, 0.666670024394989, 0.666670024394989, 0.6527799963951111, 0.6527799963951111, 0.44444000720977783, 0.6944400072097778, 0.8194400072097778, 0.4722200036048889, 0.8472200036048889, 0.6944400072097778, 0.44444000720977783, 0.5, 0.625, 0.7777799963951111, 0.5, 0.6527799963951111, 0.7222200036048889, 0.6388900279998779, 0.5138900279998779, 0.666670024394989, 0.7777799963951111, 0.4166699945926666, 0.8611099720001221, 0.666670024394989, 0.3333300054073334, 0.125, 0.8055599927902222, 0.30555999279022217, 0.9444400072097778, 0.44444000720977783, 0.8888900279998779, 0.7777799963951111, 0.6111099720001221, 0.6111099720001221, 0.5555599927902222, 0.6944400072097778, 0.7638900279998779, 0.791670024394989, 0.75, 0.5, 0.2777799963951111, 0.6944400072097778, 0.916670024394989, 0.5, 0.6527799963951111, 0.6527799963951111, 0.666670024394989, 0.625, 0.9027799963951111, 0.666670024394989, 0.791670024394989, 0.7638900279998779, 0.8472200036048889, 0.666670024394989, 0.875, 0.6944400072097778, 0.625, 0.6388900279998779, 0.38888999819755554, 0.666670024394989, 0.5, 0.791670024394989, 0.6388900279998779, 0.8611099720001221, 0.38888999819755554, 0.833329975605011, 0.7638900279998779, 0.48611000180244446, 0.5555599927902222, 0.38888999819755554, 0.6805599927902222, 0.9305599927902222, 0.6388900279998779, 0.833329975605011, 0.44444000720977783, 0.3333300054073334, 0.8055599927902222, 0.7222200036048889, 0.9444400072097778, 0.666670024394989, 0.19444000720977783, 0.708329975605011, 0.6944400072097778, 0.4166699945926666, 0.916670024394989, 0.833329975605011, 0.6944400072097778, 0.8888900279998779, 0.5694400072097778, 0.791670024394989, 0.8194400072097778, 0.875, 0.7777799963951111, 0.8472200036048889, 0.6388900279998779, 0.38888999819755554, 0.916670024394989, 0.75, 0.7222200036048889, 0.7222200036048889, 0.7361099720001221, 0.75, 0.75, 0.7361099720001221, 0.8888900279998779, 0.8055599927902222, 0.8194400072097778, 0.7777799963951111, 0.7222200036048889, 0.833329975605011, 0.8472200036048889, 0.791670024394989, 0.6944400072097778, 0.44444000720977783, 0.4166699945926666, 0.583329975605011, 0.6111099720001221, 0.5555599927902222, 0.6805599927902222, 0.875, 0.7222200036048889, 0.8888900279998779, 0.7222200036048889, 0.833329975605011, 0.31944000720977783, 0.791670024394989, 0.583329975605011, 0.75, 0.4166699945926666, 0.6944400072097778, 0.833329975605011, 0.5555599927902222, 0.8472200036048889, 0.7361099720001221, 0.7222200036048889, 0.6111099720001221, 0.7777799963951111, 0.7638900279998779, 0.833329975605011, 0.5277799963951111, 0.7638900279998779, 0.6527799963951111, 0.8055599927902222, 0.7777799963951111, 0.5972200036048889, 0.8055599927902222, 0.8888900279998779, 0.5138900279998779, 0.6805599927902222, 0.7777799963951111, 0.5138900279998779, 0.7777799963951111, 0.7638900279998779, 0.625, 0.7222200036048889, 0.6944400072097778, 0.6527799963951111, 0.708329975605011, 0.5694400072097778, 0.4166699945926666, 0.6944400072097778, 0.7361099720001221, 0.5972200036048889, 0.6527799963951111, 0.5972200036048889, 0.7222200036048889, 0.666670024394989, 0.8055599927902222, 0.13888999819755554, 0.7638900279998779, 0.583329975605011, 0.791670024394989, 0.666670024394989, 0.916670024394989, 0.9027799963951111, 0.6527799963951111, 0.8194400072097778, 0.708329975605011, 0.833329975605011, 0.25, 0.5138900279998779, 0.6944400072097778, 0.8472200036048889, 0.8055599927902222, 0.666670024394989, 0.7361099720001221, 0.48611000180244446, 0.958329975605011, 0.708329975605011, 0.833329975605011, 0.4722200036048889, 0.8194400072097778, 0.8194400072097778, 0.7777799963951111, 0.44444000720977783, 0.833329975605011, 0.38888999819755554, 0.7361099720001221, 0.583329975605011, 0.666670024394989, 0.8194400072097778, 0.541670024394989, 0.3333300054073334, 0.4166699945926666, 0.833329975605011, 0.958329975605011, 0.36111000180244446, 0.791670024394989, 0.8888900279998779, 0.7638900279998779, 0.8055599927902222, 0.708329975605011, 0.8888900279998779, 0.5555599927902222, 0.8888900279998779, 0.7222200036048889, 0.38888999819755554, 0.666670024394989, 0.9305599927902222, 0.8055599927902222, 0.18055999279022217, 0.6805599927902222, 0.7222200036048889, 0.9305599927902222, 0.833329975605011, 0.8472200036048889, 0.791670024394989, 0.875, 0.3333300054073334, 0.6805599927902222, 0.8888900279998779, 0.875, 0.625, 0.8194400072097778, 0.708329975605011, 0.8194400072097778, 0.5972200036048889, 0.7638900279998779, 0.8194400072097778, 0.7638900279998779, 0.7361099720001221, 0.666670024394989, 0.8055599927902222, 0.6944400072097778, 0.8888900279998779, 0.8055599927902222, 0.8888900279998779, 0.3333300054073334, 0.4027799963951111, 0.7638900279998779, 0.22222000360488892, 0.833329975605011, 0.30555999279022217, 0.7361099720001221, 0.916670024394989, 0.708329975605011, 0.7777799963951111, 0.5972200036048889, 0.8611099720001221, 0.8888900279998779, 0.7222200036048889, 0.5277799963951111, 0.7361099720001221, 0.5138900279998779, 0.6527799963951111, 0.791670024394989, 0.8611099720001221, 0.22222000360488892, 0.7361099720001221, 0.8611099720001221, 0.583329975605011, 0.6944400072097778, 0.6388900279998779, 0.791670024394989, 0.6388900279998779, 0.8472200036048889, 0.8055599927902222, 0.8194400072097778, 0.8611099720001221, 0.791670024394989, 0.791670024394989, 0.7222200036048889, 0.6388900279998779, 0.9305599927902222, 0.833329975605011, 0.875, 0.791670024394989, 0.583329975605011, 0.2916699945926666, 0.5, 0.30555999279022217, 0.4722200036048889, 0.2777799963951111, 0.31944000720977783, 0.18055999279022217, 0.22222000360488892, 0.38888999819755554, 0.31944000720977783, 0.09722200036048889, 0.38888999819755554, 0.5277799963951111, 0.13888999819755554, 0.38888999819755554, 0.2777799963951111, 0.22222000360488892, 0.833329975605011, 0.15277999639511108, 0.23611000180244446, 0.22222000360488892, 0.43055999279022217, 0.31944000720977783, 0.16666999459266663, 0.06944400072097778, 0.5972200036048889, 0.18055999279022217, 0.44444000720977783, 0.125, 0.16666999459266663, 0.2777799963951111, 0.3472200036048889, 0.18055999279022217, 0.583329975605011, 0.3333300054073334, 0.2777799963951111, 0.375, 0.25, 0.08333300054073334, 0.16666999459266663, 0.5277799963951111, 0.4166699945926666, 0.4027799963951111, 0.43055999279022217, 0.19444000720977783, 0.43055999279022217, 0.25, 0.31944000720977783, 0.15277999639511108, 0.2916699945926666, 0.013888999819755554, 0.48611000180244446, 0.5138900279998779, 0.2777799963951111, 0.2916699945926666, 0.375, 0.22222000360488892, 0.30555999279022217, 0.3472200036048889, 0.5, 0.6805599927902222, 0.5, 0.3333300054073334, 0.5972200036048889, 0.31944000720977783, 0.06944400072097778, 0.18055999279022217, 0.125, 0.38888999819755554, 0.5972200036048889, 0.20833000540733337, 0.05555599927902222, 0.19444000720977783, 0.25, 0.19444000720977783, 0.44444000720977783, 0.13888999819755554, 0.4583300054073334, 0.13888999819755554, 0.5972200036048889, 0.22222000360488892, 0.22222000360488892, 0.11111000180244446, 0.5138900279998779, 0.5972200036048889, 0.26388999819755554, 0.125, 0.5138900279998779, 0.08333300054073334, 0.13888999819755554, 0.3472200036048889, 0.5277799963951111, 0.38888999819755554, 0.125, 0.20833000540733337, 0.6388900279998779, 0.26388999819755554, 0.20833000540733337, 0.36111000180244446, 0.11111000180244446, 0.25, 0.3333300054073334, 0.7777799963951111, 0.5972200036048889, 0.3333300054073334, 0.3472200036048889, 0.6944400072097778, 0.6388900279998779, 0.38888999819755554, 0.19444000720977783, 0.22222000360488892, 0.3472200036048889, 0.4722200036048889, 0.23611000180244446, 0.5138900279998779, 0.375, 0.43055999279022217, 0.18055999279022217, 0.3472200036048889, 0.2916699945926666, 0.541670024394989, 0.5972200036048889, 0.125, 0.11111000180244446, 0.3333300054073334, 0.6388900279998779, 0.625, 0.20833000540733337, 0.05555599927902222, 0.6388900279998779, 0.09722200036048889, 0.25, 0.11111000180244446, 0.43055999279022217, 0.16666999459266663, 0.16666999459266663, 0.43055999279022217, 0.25, 0.0, 0.25, 0.36111000180244446, 0.4027799963951111, 0.13888999819755554, 0.22222000360488892, 0.06944400072097778, 0.3472200036048889, 0.2777799963951111, 0.16666999459266663, 0.4722200036048889, 0.5138900279998779, 0.38888999819755554, 0.5138900279998779, 0.4583300054073334, 0.18055999279022217, 0.666670024394989, 0.44444000720977783, 0.25, 0.3333300054073334, 0.18055999279022217, 0.20833000540733337, 0.6805599927902222, 0.5277799963951111, 0.13888999819755554, 0.31944000720977783, 0.6388900279998779, 0.75, 0.43055999279022217, 0.18055999279022217, 0.05555599927902222, 0.30555999279022217, 0.31944000720977783, 0.5138900279998779, 0.15277999639511108, 0.05555599927902222, 0.36111000180244446, 0.6944400072097778, 0.5, 0.44444000720977783, 0.22222000360488892, 0.30555999279022217, 0.4722200036048889, 0.4583300054073334, 0.6388900279998779, 0.43055999279022217, 0.22222000360488892, 0.2777799963951111, 0.30555999279022217, 0.5277799963951111, 0.11111000180244446, 0.36111000180244446, 0.22222000360488892, 0.22222000360488892, 0.708329975605011, 0.3333300054073334, 0.43055999279022217, 0.6805599927902222, 0.2916699945926666, 0.43055999279022217, 0.375, 0.44444000720977783, 0.22222000360488892, 0.26388999819755554, 0.13888999819755554, 0.13888999819755554, 0.2777799963951111, 0.2777799963951111, 0.5277799963951111, 0.2916699945926666, 0.5694400072097778, 0.4166699945926666, 0.18055999279022217, 0.23611000180244446, 0.625, 0.09722200036048889, 0.5, 0.16666999459266663, 0.11111000180244446, 0.05555599927902222, 0.5, 0.11111000180244446, 0.38888999819755554, 0.19444000720977783, 0.4583300054073334, 0.38888999819755554, 0.23611000180244446, 0.7361099720001221, 0.375, 0.16666999459266663, 0.5277799963951111, 0.3333300054073334, 0.31944000720977783, 0.44444000720977783, 0.38888999819755554, 0.25, 0.30555999279022217, 0.6388900279998779, 0.18055999279022217, 0.5, 0.20833000540733337, 0.38888999819755554, 0.5694400072097778, 0.4027799963951111, 0.31944000720977783, 0.31944000720977783, 0.4583300054073334, 0.15277999639511108, 0.4583300054073334, 0.31944000720977783, 0.23611000180244446, 0.5694400072097778, 0.6388900279998779, 0.31944000720977783, 0.583329975605011, 0.22222000360488892, 0.16666999459266663, 0.31944000720977783, 0.375, 0.44444000720977783, 0.30555999279022217, 0.2777799963951111, 0.5, 0.22222000360488892, 0.36111000180244446, 0.09722200036048889, 0.19444000720977783, 0.5277799963951111, 0.5138900279998779, 0.11111000180244446, 0.05555599927902222, 0.20833000540733337, 0.6527799963951111, 0.22222000360488892, 0.3472200036048889, 0.5138900279998779, 0.6111099720001221, 0.20833000540733337, 0.16666999459266663, 0.125, 0.5277799963951111, 0.44444000720977783, 0.2916699945926666, 0.30555999279022217, 0.16666999459266663, 0.44444000720977783, 0.4583300054073334, 0.20833000540733337, 0.19444000720977783, 0.31944000720977783, 0.2777799963951111, 0.13888999819755554, 0.15277999639511108, 0.20833000540733337, 0.5138900279998779, 0.13888999819755554, 0.11111000180244446, 0.20833000540733337, 0.2777799963951111, 0.22222000360488892, 0.15277999639511108, 0.3472200036048889, 0.2916699945926666, 0.36111000180244446, 0.5972200036048889, 0.3472200036048889, 0.2777799963951111, 0.6388900279998779, 0.8888900279998779, 0.16666999459266663, 0.22222000360488892, 0.3333300054073334, 0.43055999279022217, 0.44444000720977783, 0.2777799963951111, 0.23611000180244446, 0.44444000720977783, 0.5555599927902222, 0.5972200036048889, 0.2916699945926666, 0.3333300054073334, 0.4027799963951111, 0.125, 0.2777799963951111, 0.375, 0.541670024394989, 0.2916699945926666, 0.25, 0.013888999819755554, 0.2777799963951111, 0.2916699945926666, 0.5277799963951111, 0.2777799963951111, 0.13888999819755554, 0.08333300054073334, 0.2916699945926666, 0.36111000180244446, 0.18055999279022217, 0.3472200036048889, 0.3333300054073334, 0.4027799963951111, 0.4027799963951111, 0.22222000360488892, 0.4722200036048889, 0.19444000720977783, 0.22222000360488892, 0.5972200036048889, 0.5, 0.5694400072097778, 0.013888999819755554, 0.4722200036048889, 0.4166699945926666, 0.4027799963951111, 0.20833000540733337, 0.22222000360488892, 0.31944000720977783, 0.11111000180244446, 0.3333300054073334, 0.11111000180244446, 0.25, 0.26388999819755554, 0.38888999819755554, 0.25, 0.6944400072097778, 0.541670024394989, 0.375, 0.13888999819755554, 0.30555999279022217, 0.11111000180244446, 0.3472200036048889, 0.25, 0.36111000180244446, 0.09722200036048889, 0.19444000720977783, 0.6527799963951111, 0.3333300054073334, 0.3333300054073334, 0.25, 0.4583300054073334, 0.43055999279022217, 0.375, 0.48611000180244446, 0.02777799963951111, 0.6388900279998779, 0.38888999819755554, 0.18055999279022217, 0.13888999819755554, 0.2916699945926666, 0.6111099720001221, 0.11111000180244446, 0.44444000720977783, 0.18055999279022217, 0.013888999819755554, 0.6805599927902222, 0.4583300054073334, 0.5555599927902222, 0.44444000720977783, 0.5, 0.36111000180244446, 0.3333300054073334, 0.06944400072097778, 0.38888999819755554, 0.31944000720977783, 0.6111099720001221, 0.5, 0.583329975605011, 0.08333300054073334, 0.375, 0.2916699945926666, 0.2916699945926666, 0.125, 0.18055999279022217, 0.44444000720977783, 0.625, 0.2777799963951111, 0.30555999279022217, 0.5277799963951111, 0.02777799963951111, 0.3333300054073334, 0.6111099720001221, 0.5555599927902222, 0.3472200036048889, 0.8055599927902222, 0.23611000180244446, 0.08333300054073334, 0.2777799963951111, 0.013888999819755554, 0.23611000180244446, 0.38888999819755554, 0.6388900279998779, 0.19444000720977783, 0.48611000180244446, 0.3333300054073334, 0.125, 0.25, 0.6527799963951111, 0.16666999459266663, 0.6805599927902222, 0.36111000180244446, 0.20833000540733337, 0.2777799963951111, 0.5277799963951111, 0.13888999819755554, 0.38888999819755554, 0.4722200036048889, 0.4583300054073334, 0.16666999459266663, 0.666670024394989, 0.0, 0.5, 1.0, 0.125, 0.75, 0.5972200036048889, 0.08333300054073334, 0.5555599927902222, 0.31944000720977783, 0.4722200036048889, 0.4583300054073334, 0.3333300054073334, 0.38888999819755554, 0.38888999819755554, 0.11111000180244446, 0.25, 0.6111099720001221, 0.2777799963951111, 0.18055999279022217, 0.5, 0.23611000180244446, 0.708329975605011, 0.6388900279998779, 0.6805599927902222, 0.25, 0.0, 0.3472200036048889, 0.2777799963951111, 0.36111000180244446, 0.4166699945926666, 0.06944400072097778, 0.6805599927902222, 0.13888999819755554, 0.6111099720001221, 0.5694400072097778, 0.38888999819755554, 0.48611000180244446, 0.5555599927902222, 0.625, 0.44444000720977783, 0.13888999819755554, 0.5277799963951111, 0.3472200036048889, 0.18055999279022217, 0.013888999819755554, 0.15277999639511108, 0.48611000180244446, 0.38888999819755554, 0.5277799963951111, 0.25, 0.31944000720977783, 0.2916699945926666, 0.4583300054073334, 0.43055999279022217, 0.16666999459266663, 0.2777799963951111, 0.5138900279998779, 0.2916699945926666, 0.09722200036048889, 0.625, 0.3472200036048889, 0.13888999819755554, 0.11111000180244446, 0.16666999459266663, 0.3472200036048889, 0.16666999459266663, 0.06944400072097778, 0.2916699945926666, 0.3333300054073334, 0.5277799963951111, 0.18055999279022217, 0.3333300054073334, 0.5, 0.04166699945926666, 0.375, 0.6944400072097778, 0.5, 0.3333300054073334, 0.7222200036048889, 0.16666999459266663, 0.3472200036048889, 0.44444000720977783, 0.16666999459266663, 0.25, 0.16666999459266663, 0.31944000720977783, 0.16666999459266663, 0.2777799963951111, 0.0, 0.05555599927902222, 0.36111000180244446, 0.5555599927902222, 0.15277999639511108, 0.3472200036048889, 0.4166699945926666, 0.26388999819755554, 0.26388999819755554, 0.43055999279022217, 0.875, 0.31944000720977783, 0.2777799963951111, 0.8055599927902222, 0.44444000720977783, 0.20833000540733337, 0.5555599927902222, 0.25, 0.31944000720977783, 0.44444000720977783, 0.25, 0.3472200036048889, 0.4583300054073334, 0.3333300054073334, 0.11111000180244446, 0.43055999279022217, 0.625, 0.30555999279022217, 0.125, 0.11111000180244446, 0.4722200036048889, 0.7222200036048889, 0.6527799963951111, 0.2777799963951111, 0.25, 0.5277799963951111, 0.22222000360488892, 0.5277799963951111, 0.3333300054073334, 0.38888999819755554, 0.05555599927902222, 0.26388999819755554, 0.08333300054073334, 0.20833000540733337, 0.4027799963951111, 0.26388999819755554, 0.2777799963951111, 0.5, 0.25, 0.05555599927902222, 0.23611000180244446, 0.4027799963951111, 0.6111099720001221, 0.6111099720001221, 0.5138900279998779, 0.2916699945926666, 0.125, 0.2777799963951111, 0.22222000360488892, 0.19444000720977783, 0.43055999279022217, 0.5972200036048889, 0.20833000540733337, 0.26388999819755554, 0.30555999279022217, 0.375, 0.5, 0.11111000180244446, 0.4583300054073334, 0.5555599927902222, 0.8055599927902222, 0.18055999279022217, 0.44444000720977783, 0.20833000540733337, 0.875, 0.375, 0.3333300054073334, 0.36111000180244446, 0.22222000360488892, 0.3472200036048889, 0.38888999819755554, 0.25, 0.26388999819755554, 0.75, 0.2916699945926666, 0.16666999459266663, 0.541670024394989, 0.11111000180244446, 0.4583300054073334, 0.125, 0.0, 0.2916699945926666, 0.20833000540733337, 0.04166699945926666, 0.22222000360488892, 0.4583300054073334, 0.20833000540733337, 0.7638900279998779, 0.05555599927902222, 0.708329975605011, 0.02777799963951111, 0.11111000180244446, 0.11111000180244446, 0.16666999459266663, 0.08333300054073334, 0.16666999459266663, 0.6388900279998779, 0.26388999819755554, 0.22222000360488892, 0.5138900279998779, 0.09722200036048889, 0.4583300054073334, 0.15277999639511108, 0.23611000180244446, 0.125, 0.22222000360488892, 0.25, 0.3333300054073334, 0.18055999279022217, 0.541670024394989, 0.20833000540733337, 0.125, 0.13888999819755554, 0.5, 0.13888999819755554, 0.15277999639511108, 0.31944000720977783, 0.26388999819755554, 0.11111000180244446, 0.125, 0.4722200036048889, 0.44444000720977783, 0.2777799963951111, 0.13888999819755554, 0.30555999279022217, 0.6388900279998779, 0.30555999279022217, 0.11111000180244446, 0.5555599927902222, 0.2777799963951111, 0.22222000360488892, 0.125, 0.05555599927902222, 0.16666999459266663, 0.38888999819755554, 0.20833000540733337, 0.2777799963951111, 0.541670024394989, 0.38888999819755554, 0.4166699945926666, 0.541670024394989, 0.125, 0.30555999279022217, 0.15277999639511108, 0.20833000540733337, 0.15277999639511108, 0.5, 0.5694400072097778, 0.3472200036048889, 0.38888999819755554, 0.3472200036048889, 0.38888999819755554, 0.5972200036048889, 0.2777799963951111, 0.3333300054073334, 0.5, 0.4166699945926666, 0.3333300054073334, 0.08333300054073334, 0.08333300054073334, 0.13888999819755554, 0.44444000720977783, 0.11111000180244446, 0.6111099720001221, 0.30555999279022217, 0.25, 0.20833000540733337, 0.3333300054073334, 0.25, 0.38888999819755554, 0.4027799963951111, 0.5277799963951111, 0.2916699945926666, 0.19444000720977783, 0.22222000360488892, 0.16666999459266663, 0.06944400072097778, 0.16666999459266663, 0.3333300054073334, 0.4583300054073334, 0.3472200036048889, 0.26388999819755554, 0.22222000360488892, 0.26388999819755554, 0.30555999279022217, 0.3333300054073334, 0.26388999819755554, 0.3472200036048889, 0.5, 0.23611000180244446, 0.48611000180244446, 0.44444000720977783, 0.22222000360488892, 0.3472200036048889, 0.19444000720977783, 0.3333300054073334, 0.2916699945926666, 0.6388900279998779, 0.18055999279022217, 0.708329975605011, 0.20833000540733337, 0.6111099720001221, 0.16666999459266663, 0.09722200036048889, 0.20833000540733337, 0.22222000360488892, 0.25, 0.31944000720977783, 0.20833000540733337, 0.25, 0.3333300054073334, 0.19444000720977783, 0.7777799963951111, 0.44444000720977783, 0.4583300054073334, 0.4027799963951111, 0.20833000540733337, 0.05555599927902222, 0.25, 0.26388999819755554, 0.18055999279022217, 0.38888999819755554, 0.08333300054073334, 0.16666999459266663, 0.19444000720977783, 0.3333300054073334, 0.22222000360488892, 0.30555999279022217, 0.3472200036048889, 0.25, 0.31944000720977783, 0.6388900279998779, 0.3472200036048889, 0.20833000540733337, 0.18055999279022217, 0.4722200036048889, 0.25, 0.6805599927902222, 0.541670024394989, 0.18055999279022217, 0.23611000180244446, 0.30555999279022217, 0.375, 0.3333300054073334, 0.5555599927902222, 0.2777799963951111, 0.44444000720977783, 0.2777799963951111, 0.5694400072097778, 0.11111000180244446, 0.11111000180244446, 0.3472200036048889, 0.44444000720977783, 0.30555999279022217, 0.375, 0.30555999279022217, 0.05555599927902222, 0.48611000180244446, 0.16666999459266663, 0.25, 0.125, 0.31944000720977783, 0.31944000720977783, 0.2916699945926666, 0.13888999819755554, 0.22222000360488892, 0.23611000180244446, 0.2916699945926666, 0.08333300054073334, 0.3472200036048889, 0.08333300054073334, 0.11111000180244446, 0.13888999819755554, 0.18055999279022217, 0.875, 0.2777799963951111, 0.22222000360488892, 0.4583300054073334, 0.5555599927902222, 0.11111000180244446, 0.25, 0.43055999279022217, 0.22222000360488892, 0.5972200036048889, 0.16666999459266663, 0.125, 0.3472200036048889, 0.6805599927902222, 0.4583300054073334, 0.15277999639511108, 0.18055999279022217, 0.5, 0.25, 0.16666999459266663, 0.15277999639511108, 0.2777799963951111, 0.36111000180244446, 0.2916699945926666, 0.31944000720977783, 0.4027799963951111, 0.25, 0.04166699945926666, 0.44444000720977783, 0.22222000360488892, 0.04166699945926666, 0.16666999459266663, 0.36111000180244446, 0.04166699945926666, 0.6527799963951111, 0.30555999279022217, 0.43055999279022217, 0.38888999819755554, 0.5138900279998779, 0.375, 0.30555999279022217, 0.013888999819755554, 0.05555599927902222, 0.4027799963951111, 0.44444000720977783, 0.43055999279022217, 0.125, 0.6944400072097778, 0.25, 0.25, 0.44444000720977783, 0.16666999459266663, 0.48611000180244446, 0.22222000360488892, 0.2916699945926666, 0.44444000720977783, 0.44444000720977783, 0.11111000180244446, 0.09722200036048889, 0.20833000540733337, 0.3472200036048889, 0.19444000720977783, 0.3333300054073334, 0.2777799963951111, 0.38888999819755554, 0.25, 0.3333300054073334, 0.05555599927902222, 0.2777799963951111, 0.30555999279022217, 0.5694400072097778, 0.4583300054073334, 0.4166699945926666, 0.2916699945926666, 0.11111000180244446, 0.5138900279998779, 0.18055999279022217, 0.4583300054073334, 0.08333300054073334, 0.2777799963951111, 0.48611000180244446, 0.48611000180244446, 0.16666999459266663, 0.6805599927902222, 0.36111000180244446, 0.23611000180244446, 0.20833000540733337, 0.541670024394989, 0.2916699945926666, 0.3333300054073334, 0.4027799963951111, 0.5138900279998779, 0.16666999459266663, 0.06944400072097778, 0.541670024394989, 0.2777799963951111, 0.6111099720001221, 0.08333300054073334, 0.11111000180244446, 0.05555599927902222, 0.2777799963951111, 0.06944400072097778, 0.3333300054073334, 0.3333300054073334, 0.11111000180244446, 0.31944000720977783, 0.26388999819755554, 0.2777799963951111, 0.2777799963951111, 0.4166699945926666, 0.4722200036048889, 0.5, 0.5, 0.22222000360488892, 0.31944000720977783, 0.02777799963951111, 0.22222000360488892, 0.375, 0.4027799963951111, 0.15277999639511108, 0.5138900279998779, 0.26388999819755554, 0.15277999639511108, 0.5138900279998779, 0.5277799963951111, 0.375, 0.4722200036048889, 0.2777799963951111, 0.5, 0.5, 0.20833000540733337, 0.4166699945926666, 0.3333300054073334, 0.31944000720977783, 0.5555599927902222, 0.19444000720977783, 0.5972200036048889, 0.5138900279998779, 0.09722200036048889, 0.25, 0.13888999819755554, 0.916670024394989, 0.15277999639511108, 0.6527799963951111, 0.2916699945926666, 0.38888999819755554, 0.31944000720977783, 0.6527799963951111, 0.2777799963951111, 0.3333300054073334, 0.13888999819755554, 0.5277799963951111, 0.13888999819755554, 0.6388900279998779, 0.5277799963951111, 0.3333300054073334, 0.36111000180244446, 0.08333300054073334, 0.3472200036048889, 0.666670024394989, 0.11111000180244446, 0.375, 0.38888999819755554, 0.2777799963951111, 0.3472200036048889, 0.13888999819755554, 0.3472200036048889, 0.26388999819755554, 0.7222200036048889, 0.13888999819755554, 0.44444000720977783, 0.4722200036048889, 0.11111000180244446, 0.2777799963951111, 0.19444000720977783, 0.4722200036048889, 0.11111000180244446, 0.375, 0.4027799963951111, 0.4027799963951111, 0.16666999459266663, 0.31944000720977783, 0.22222000360488892, 0.19444000720977783, 0.4027799963951111, 0.22222000360488892, 0.22222000360488892, 0.22222000360488892, 0.4166699945926666, 0.5, 0.20833000540733337, 0.708329975605011, 0.4166699945926666, 0.5138900279998779, 0.44444000720977783, 0.4583300054073334, 0.06944400072097778, 0.583329975605011, 0.11111000180244446, 0.11111000180244446, 0.18055999279022217, 0.43055999279022217, 0.3472200036048889, 0.44444000720977783, 0.15277999639511108, 0.48611000180244446, 0.31944000720977783, 0.2916699945926666, 0.36111000180244446, 0.5694400072097778, 0.36111000180244446, 0.13888999819755554, 0.2777799963951111, 0.3333300054073334, 0.3333300054073334, 0.2916699945926666, 0.75, 0.25, 0.16666999459266663, 0.6388900279998779, 0.4583300054073334, 0.38888999819755554, 0.38888999819755554, 0.6527799963951111, 0.23611000180244446, 0.625, 0.31944000720977783, 0.20833000540733337, 0.2777799963951111, 0.36111000180244446, 0.5555599927902222, 0.22222000360488892, 0.22222000360488892, 0.06944400072097778, 0.31944000720977783, 0.3333300054073334, 0.4583300054073334, 0.38888999819755554, 0.541670024394989, 0.5694400072097778, 0.26388999819755554, 0.3472200036048889, 0.31944000720977783, 0.31944000720977783, 0.3333300054073334, 0.2916699945926666, 0.44444000720977783, 0.4027799963951111, 0.5555599927902222, 0.36111000180244446, 0.5, 0.20833000540733337, 0.44444000720977783, 0.11111000180244446, 0.19444000720977783, 0.125, 0.2777799963951111, 0.44444000720977783, 0.3333300054073334, 0.4027799963951111, 0.5, 0.4583300054073334, 0.23611000180244446, 0.20833000540733337, 0.11111000180244446, 0.5277799963951111, 0.2777799963951111, 0.36111000180244446, 0.6388900279998779, 0.125, 0.05555599927902222, 0.23611000180244446, 0.18055999279022217, 0.3333300054073334, 0.541670024394989, 0.15277999639511108, 0.625, 0.23611000180244446, 0.2916699945926666, 0.15277999639511108, 0.36111000180244446, 0.38888999819755554, 0.44444000720977783, 0.30555999279022217, 0.15277999639511108, 0.38888999819755554, 0.3472200036048889, 0.2916699945926666, 0.26388999819755554, 0.4027799963951111, 0.38888999819755554, 0.4027799963951111, 0.44444000720977783, 0.22222000360488892, 0.2916699945926666, 0.26388999819755554, 0.11111000180244446, 0.5555599927902222, 0.23611000180244446, 0.20833000540733337, 0.3472200036048889, 0.4166699945926666, 0.16666999459266663, 0.08333300054073334, 0.05555599927902222, 0.2777799963951111, 0.3333300054073334, 0.22222000360488892, 0.2916699945926666, 0.2916699945926666, 0.44444000720977783, 0.20833000540733337, 0.4166699945926666, 0.5277799963951111, 0.5, 0.5, 0.09722200036048889, 0.375, 0.5138900279998779, 0.26388999819755554, 0.3472200036048889, 0.23611000180244446, 0.4722200036048889, 0.26388999819755554, 0.48611000180244446, 0.2916699945926666, 0.22222000360488892, 0.38888999819755554, 0.5972200036048889, 0.26388999819755554, 0.26388999819755554, 0.26388999819755554, 0.30555999279022217, 0.2777799963951111, 0.22222000360488892, 0.2777799963951111, 0.20833000540733337, 0.5, 0.26388999819755554, 0.31944000720977783, 0.36111000180244446, 0.583329975605011, 0.18055999279022217, 0.4722200036048889, 0.2777799963951111, 0.3333300054073334, 0.23611000180244446, 0.19444000720977783, 0.30555999279022217, 0.4166699945926666, 0.48611000180244446, 0.23611000180244446, 0.22222000360488892, 0.25, 0.36111000180244446, 0.08333300054073334, 0.36111000180244446, 0.16666999459266663, 0.02777799963951111, 0.38888999819755554, 0.18055999279022217, 0.26388999819755554, 0.31944000720977783, 0.4027799963951111, 0.44444000720977783, 0.22222000360488892, 0.44444000720977783, 0.2777799963951111, 0.26388999819755554, 0.38888999819755554, 0.375, 0.19444000720977783, 0.22222000360488892, 0.30555999279022217, 0.05555599927902222, 0.30555999279022217, 0.3333300054073334, 0.19444000720977783, 0.20833000540733337, 0.125, 0.22222000360488892, 0.08333300054073334, 0.3333300054073334, 0.3472200036048889, 0.3333300054073334, 0.36111000180244446, 0.20833000540733337, 0.4166699945926666, 0.26388999819755554, 0.3333300054073334, 0.16666999459266663, 0.25, 0.16666999459266663, 0.36111000180244446, 0.5, 0.5, 0.375, 0.583329975605011, 0.5, 0.6388900279998779, 0.5, 0.3333300054073334, 0.26388999819755554, 0.31944000720977783, 0.30555999279022217, 0.38888999819755554, 0.3333300054073334, 0.31944000720977783, 0.13888999819755554, 0.36111000180244446, 0.15277999639511108, 0.25, 0.25, 0.38888999819755554, 0.3472200036048889, 0.2916699945926666, 0.4722200036048889, 0.13888999819755554, 0.5138900279998779, 0.26388999819755554, 0.16666999459266663, 0.25, 0.18055999279022217, 0.2777799963951111, 0.38888999819755554, 0.25, 0.2777799963951111, 0.2777799963951111, 0.25, 0.31944000720977783, 0.16666999459266663, 0.2916699945926666, 0.6388900279998779, 0.06944400072097778, 0.583329975605011, 0.09722200036048889, 0.06944400072097778, 0.19444000720977783, 0.2777799963951111, 0.375, 0.013888999819755554, 0.3333300054073334, 0.6527799963951111, 0.22222000360488892, 0.43055999279022217, 0.25, 0.26388999819755554, 0.16666999459266663, 0.2777799963951111, 0.4027799963951111, 0.3333300054073334, 0.16666999459266663, 0.43055999279022217, 0.31944000720977783, 0.36111000180244446, 0.833329975605011, 0.23611000180244446, 0.4166699945926666, 0.16666999459266663, 0.541670024394989, 0.02777799963951111, 0.4166699945926666, 0.6388900279998779, 0.19444000720977783, 0.25, 0.22222000360488892, 0.4583300054073334, 0.5972200036048889, 0.125, 0.3472200036048889, 0.30555999279022217, 0.5972200036048889, 0.23611000180244446, 0.25, 0.15277999639511108, 0.26388999819755554, 0.2916699945926666, 0.4583300054073334, 0.583329975605011, 0.375, 0.2777799963951111, 0.08333300054073334, 0.5972200036048889, 0.5, 0.2777799963951111, 0.5694400072097778, 0.22222000360488892, 0.20833000540733337, 0.20833000540733337, 0.20833000540733337, 0.31944000720977783, 0.31944000720977783, 0.20833000540733337, 0.16666999459266663, 0.3472200036048889, 0.3333300054073334, 0.18055999279022217, 0.20833000540733337, 0.375, 0.48611000180244446, 0.6111099720001221, 0.2916699945926666, 0.23611000180244446, 0.3472200036048889, 0.09722200036048889, 0.6805599927902222, 0.20833000540733337, 0.19444000720977783, 0.15277999639511108, 0.18055999279022217, 0.05555599927902222, 0.26388999819755554, 0.013888999819755554, 0.125, 0.708329975605011, 0.25, 0.18055999279022217, 0.31944000720977783, 0.04166699945926666, 0.18055999279022217, 0.36111000180244446, 0.25, 0.31944000720977783, 0.38888999819755554, 0.3472200036048889, 0.08333300054073334, 0.22222000360488892, 0.23611000180244446, 0.08333300054073334, 0.30555999279022217, 0.13888999819755554, 0.5, 0.2777799963951111, 0.16666999459266663, 0.125, 0.48611000180244446, 0.22222000360488892, 0.19444000720977783, 0.3472200036048889, 0.5555599927902222, 0.13888999819755554, 0.2777799963951111, 0.4583300054073334, 0.19444000720977783, 0.7222200036048889, 0.2916699945926666, 0.09722200036048889, 0.38888999819755554, 0.22222000360488892, 0.23611000180244446, 0.3472200036048889, 0.38888999819755554, 0.8472200036048889, 0.25, 0.19444000720977783, 0.5138900279998779, 0.43055999279022217, 0.36111000180244446, 0.26388999819755554, 0.3333300054073334, 0.25, 0.3472200036048889, 0.36111000180244446, 0.31944000720977783, 0.583329975605011, 0.09722200036048889, 0.20833000540733337, 0.5, 0.22222000360488892, 0.6111099720001221, 0.38888999819755554, 0.11111000180244446, 0.3333300054073334, 0.16666999459266663, 0.30555999279022217, 0.26388999819755554, 0.375, 0.375, 0.4583300054073334, 0.22222000360488892, 0.30555999279022217, 0.18055999279022217, 0.25, 0.05555599927902222, 0.20833000540733337, 0.5138900279998779, 0.5, 0.2916699945926666, 0.22222000360488892, 0.2916699945926666, 0.11111000180244446, 0.541670024394989, 0.23611000180244446, 0.04166699945926666, 0.4027799963951111, 0.05555599927902222, 0.43055999279022217, 0.2916699945926666, 0.15277999639511108, 0.666670024394989, 0.2777799963951111, 0.125, 0.30555999279022217, 0.5694400072097778, 0.16666999459266663, 0.23611000180244446, 0.38888999819755554, 0.16666999459266663, 0.30555999279022217, 0.125, 0.22222000360488892, 0.31944000720977783, 0.22222000360488892, 0.05555599927902222, 0.26388999819755554, 0.3333300054073334, 0.16666999459266663, 0.5555599927902222, 0.20833000540733337, 0.3333300054073334, 0.26388999819755554, 0.30555999279022217, 0.23611000180244446, 0.15277999639511108, 0.48611000180244446, 0.2916699945926666, 0.3472200036048889, 0.38888999819755554, 0.2916699945926666, 0.5, 0.5, 0.09722200036048889, 0.43055999279022217, 0.6388900279998779, 0.4166699945926666, 0.20833000540733337, 0.26388999819755554, 0.2916699945926666, 0.4027799963951111, 0.2777799963951111, 0.375, 0.125, 0.20833000540733337, 0.11111000180244446, 0.30555999279022217, 0.3472200036048889, 0.4027799963951111, 0.5555599927902222, 0.375, 0.11111000180244446, 0.13888999819755554, 0.4722200036048889, 0.2777799963951111, 0.13888999819755554, 0.3472200036048889, 0.5555599927902222, 0.15277999639511108, 0.22222000360488892, 0.16666999459266663, 0.20833000540733337, 0.23611000180244446, 0.38888999819755554, 0.6111099720001221, 0.2916699945926666, 0.44444000720977783, 0.36111000180244446, 0.31944000720977783, 0.20833000540733337, 0.7222200036048889, 0.4722200036048889, 0.2777799963951111, 0.25, 0.44444000720977783, 0.2777799963951111, 0.583329975605011, 0.375, 0.22222000360488892, 0.23611000180244446, 0.05555599927902222, 0.18055999279022217, 0.18055999279022217, 0.8888900279998779, 0.4027799963951111, 0.5972200036048889, 0.23611000180244446, 0.26388999819755554, 0.30555999279022217, 0.5, 0.44444000720977783, 0.05555599927902222, 0.2777799963951111, 0.6388900279998779, 0.19444000720977783, 0.13888999819755554, 0.375, 0.25, 0.666670024394989, 0.2777799963951111, 0.44444000720977783, 0.4166699945926666, 0.375, 0.4166699945926666, 0.25, 0.11111000180244446, 0.16666999459266663, 0.18055999279022217, 0.22222000360488892, 0.36111000180244446, 0.31944000720977783, 0.36111000180244446, 0.5, 0.5694400072097778, 0.5555599927902222, 0.5555599927902222, 0.44444000720977783, 0.18055999279022217, 0.375, 0.44444000720977783, 0.5972200036048889, 0.2777799963951111, 0.18055999279022217, 0.08333300054073334, 0.4166699945926666, 0.13888999819755554, 0.15277999639511108, 0.30555999279022217, 0.3472200036048889, 0.20833000540733337, 0.20833000540733337, 0.23611000180244446, 0.30555999279022217, 0.04166699945926666, 0.75, 0.2777799963951111, 0.20833000540733337, 0.583329975605011, 0.125, 0.23611000180244446, 0.5277799963951111, 0.22222000360488892, 0.25, 0.3472200036048889, 0.5277799963951111, 0.5555599927902222, 0.125, 0.15277999639511108, 0.5, 0.5, 0.2916699945926666, 0.5, 0.6111099720001221, 0.5555599927902222, 0.375, 0.30555999279022217, 0.36111000180244446, 0.2916699945926666, 0.18055999279022217, 0.25, 0.38888999819755554, 0.2916699945926666, 0.375, 0.5555599927902222, 0.2777799963951111, 0.16666999459266663, 0.31944000720977783, 0.25, 0.375, 0.6111099720001221, 0.23611000180244446, 0.20833000540733337, 0.25, 0.666670024394989, 0.8055599927902222, 0.3333300054073334, 0.25, 0.44444000720977783, 0.09722200036048889, 0.11111000180244446, 0.31944000720977783, 0.22222000360488892, 0.4166699945926666, 0.5, 0.6111099720001221, 0.23611000180244446, 0.6111099720001221, 0.43055999279022217, 0.13888999819755554, 0.4166699945926666, 0.2777799963951111, 0.20833000540733337, 0.18055999279022217, 0.44444000720977783, 0.44444000720977783, 0.44444000720977783, 0.19444000720977783, 0.4166699945926666, 0.2777799963951111, 0.26388999819755554, 0.38888999819755554, 0.2777799963951111, 0.583329975605011, 0.2777799963951111, 0.43055999279022217, 0.4166699945926666, 0.3333300054073334, 0.7638900279998779, 0.26388999819755554, 0.2777799963951111, 0.19444000720977783, 0.31944000720977783, 0.19444000720977783, 0.3333300054073334, 0.6388900279998779, 0.44444000720977783, 0.25, 0.23611000180244446, 0.23611000180244446, 0.7361099720001221, 0.5, 0.20833000540733337, 0.2916699945926666, 0.26388999819755554, 0.125, 0.3333300054073334, 0.05555599927902222, 0.541670024394989, 0.25, 0.20833000540733337, 0.19444000720977783, 0.38888999819755554, 0.13888999819755554, 0.36111000180244446, 0.23611000180244446, 0.7777799963951111, 0.22222000360488892, 0.3333300054073334, 0.11111000180244446, 0.19444000720977783, 0.22222000360488892, 0.125, 0.30555999279022217, 0.11111000180244446, 0.7361099720001221, 0.36111000180244446, 0.22222000360488892, 0.125, 0.38888999819755554, 0.375, 0.30555999279022217, 0.11111000180244446, 0.20833000540733337, 0.15277999639511108, 0.3472200036048889, 0.375, 0.3333300054073334, 0.09722200036048889, 0.13888999819755554, 0.22222000360488892, 0.20833000540733337, 0.11111000180244446, 0.2916699945926666, 0.3472200036048889, 0.11111000180244446, 0.25, 0.5555599927902222, 0.22222000360488892, 0.3333300054073334, 0.44444000720977783, 0.11111000180244446, 0.38888999819755554, 0.36111000180244446, 0.3333300054073334, 0.15277999639511108, 0.5555599927902222, 0.36111000180244446, 0.31944000720977783, 0.11111000180244446, 0.22222000360488892, 0.05555599927902222, 0.11111000180244446, 0.541670024394989, 0.13888999819755554, 0.16666999459266663, 0.2916699945926666, 0.30555999279022217, 0.25, 0.05555599927902222, 0.15277999639511108, 0.23611000180244446, 0.708329975605011, 0.3472200036048889, 0.4027799963951111, 0.30555999279022217, 0.16666999459266663, 0.3472200036048889, 0.25, 0.09722200036048889, 0.30555999279022217, 0.48611000180244446, 0.6944400072097778, 0.125, 0.23611000180244446, 0.6388900279998779, 0.18055999279022217, 0.43055999279022217, 0.48611000180244446, 0.23611000180244446, 0.625, 0.22222000360488892, 0.31944000720977783, 0.04166699945926666, 0.6944400072097778, 0.3333300054073334, 0.375, 0.15277999639511108, 0.16666999459266663, 0.36111000180244446, 0.05555599927902222, 0.22222000360488892, 0.30555999279022217, 0.23611000180244446, 0.38888999819755554, 0.13888999819755554, 0.25, 0.16666999459266663, 0.5138900279998779, 0.16666999459266663, 0.08333300054073334, 0.16666999459266663, 0.11111000180244446, 0.2777799963951111, 0.30555999279022217, 0.3333300054073334, 0.38888999819755554, 0.02777799963951111, 0.22222000360488892, 0.43055999279022217, 0.5555599927902222, 0.26388999819755554, 0.5138900279998779, 0.22222000360488892, 0.2916699945926666, 0.26388999819755554, 0.23611000180244446, 0.36111000180244446, 0.13888999819755554, 0.11111000180244446, 0.4166699945926666, 0.5, 0.2777799963951111, 0.16666999459266663, 0.09722200036048889, 0.44444000720977783, 0.6805599927902222, 0.541670024394989, 0.11111000180244446, 0.5277799963951111, 0.20833000540733337, 0.18055999279022217, 0.5, 0.5, 0.19444000720977783, 0.11111000180244446, 0.26388999819755554, 0.20833000540733337, 0.31944000720977783, 0.08333300054073334, 0.25, 0.26388999819755554, 0.04166699945926666, 0.0, 0.30555999279022217, 0.666670024394989, 0.26388999819755554, 0.44444000720977783, 0.8472200036048889, 0.30555999279022217, 0.5277799963951111, 0.4027799963951111, 0.08333300054073334, 0.22222000360488892, 0.20833000540733337, 0.19444000720977783, 0.20833000540733337, 0.3472200036048889, 0.23611000180244446, 0.541670024394989, 0.5277799963951111, 0.09722200036048889, 0.25, 0.20833000540733337, 0.26388999819755554, 0.02777799963951111, 0.30555999279022217, 0.19444000720977783, 0.3333300054073334, 0.36111000180244446, 0.3333300054073334, 0.48611000180244446, 0.3333300054073334, 0.20833000540733337, 0.06944400072097778, 0.2916699945926666, 0.23611000180244446, 0.02777799963951111, 0.791670024394989, 0.4027799963951111, 0.4166699945926666, 0.2777799963951111, 0.6111099720001221, 0.833329975605011, 0.26388999819755554, 0.3333300054073334, 0.30555999279022217, 0.2777799963951111, 0.26388999819755554, 0.2777799963951111, 0.125, 0.583329975605011, 0.25, 0.375, 0.11111000180244446, 0.26388999819755554, 0.22222000360488892, 0.20833000540733337, 0.26388999819755554, 0.708329975605011, 0.3472200036048889, 0.22222000360488892, 0.31944000720977783, 0.4166699945926666, 0.375, 0.833329975605011, 0.2777799963951111, 0.30555999279022217, 0.3333300054073334, 0.4027799963951111, 0.22222000360488892, 0.2777799963951111, 0.5, 0.22222000360488892, 0.2916699945926666, 0.31944000720977783, 0.26388999819755554, 0.16666999459266663, 0.125, 0.31944000720977783, 0.23611000180244446, 0.19444000720977783, 0.38888999819755554, 0.26388999819755554, 0.2777799963951111, 0.19444000720977783, 0.18055999279022217, 0.25, 0.5555599927902222, 0.22222000360488892, 0.26388999819755554, 0.16666999459266663, 0.3333300054073334, 0.11111000180244446, 0.4583300054073334, 0.05555599927902222, 0.08333300054073334, 0.44444000720977783, 0.2777799963951111, 0.25, 0.22222000360488892, 0.4027799963951111, 0.2916699945926666, 0.875, 0.5, 0.23611000180244446, 0.6527799963951111, 0.5972200036048889, 0.18055999279022217, 0.5138900279998779, 0.541670024394989, 0.08333300054073334, 0.15277999639511108, 0.2777799963951111, 0.7222200036048889, 0.23611000180244446, 0.22222000360488892, 0.15277999639511108, 0.23611000180244446, 0.25, 0.5, 0.4027799963951111, 0.3333300054073334, 0.4027799963951111, 0.11111000180244446, 0.26388999819755554, 0.375, 0.5, 0.43055999279022217, 0.2916699945926666, 0.375, 0.20833000540733337, 0.125, 0.125, 0.4027799963951111, 0.25, 0.5, 0.36111000180244446, 0.5277799963951111, 0.43055999279022217, 0.44444000720977783, 0.15277999639511108, 0.2916699945926666, 0.2777799963951111, 0.2916699945926666, 0.5694400072097778, 0.2777799963951111, 0.26388999819755554, 0.19444000720977783, 0.20833000540733337, 0.20833000540733337, 0.5138900279998779, 0.11111000180244446, 0.31944000720977783, 0.11111000180244446, 0.16666999459266663, 0.3472200036048889, 0.3333300054073334, 0.4166699945926666, 0.48611000180244446, 0.23611000180244446, 0.22222000360488892, 0.08333300054073334, 0.3333300054073334, 0.48611000180244446, 0.125, 0.5, 0.44444000720977783, 0.26388999819755554, 0.09722200036048889, 0.22222000360488892, 0.18055999279022217, 0.4027799963951111, 0.30555999279022217, 0.16666999459266663, 0.7361099720001221, 0.3333300054073334, 0.3333300054073334, 0.5555599927902222, 0.43055999279022217, 0.11111000180244446, 0.20833000540733337, 0.44444000720977783, 0.43055999279022217, 0.25, 0.375, 0.11111000180244446, 0.16666999459266663, 0.19444000720977783, 0.30555999279022217, 0.5, 0.23611000180244446, 0.7777799963951111, 0.7222200036048889, 0.09722200036048889, 0.18055999279022217, 0.25, 0.19444000720977783, 0.4027799963951111, 0.5, 0.4027799963951111, 0.583329975605011, 0.30555999279022217, 0.5555599927902222, 0.26388999819755554, 0.4166699945926666, 0.3472200036048889, 0.15277999639511108, 0.11111000180244446, 0.22222000360488892, 0.31944000720977783, 0.11111000180244446, 0.11111000180244446, 0.38888999819755554, 0.26388999819755554, 0.20833000540733337, 0.7222200036048889, 0.25, 0.31944000720977783, 0.2916699945926666, 0.26388999819755554, 0.2916699945926666, 0.5, 0.22222000360488892, 0.16666999459266663, 0.6111099720001221, 0.3472200036048889, 0.30555999279022217, 0.375, 0.583329975605011, 0.5, 0.5, 0.38888999819755554, 0.375, 0.4027799963951111, 0.48611000180244446, 0.125, 0.7777799963951111, 0.2777799963951111, 0.16666999459266663, 0.375, 0.38888999819755554, 0.3333300054073334, 0.6527799963951111, 0.19444000720977783, 0.36111000180244446, 0.19444000720977783, 0.09722200036048889, 0.23611000180244446, 0.16666999459266663, 0.375, 0.31944000720977783, 0.125, 0.02777799963951111, 0.48611000180244446, 0.20833000540733337, 0.23611000180244446, 0.2777799963951111, 0.2777799963951111, 0.31944000720977783, 0.16666999459266663, 0.22222000360488892, 0.375, 0.26388999819755554, 0.20833000540733337, 0.18055999279022217, 0.44444000720977783, 0.3472200036048889, 0.09722200036048889, 0.31944000720977783, 0.36111000180244446, 0.18055999279022217, 0.23611000180244446, 0.2777799963951111, 0.5138900279998779, 0.2777799963951111, 0.7222200036048889, 0.36111000180244446, 0.11111000180244446, 0.25, 0.44444000720977783, 0.44444000720977783, 0.16666999459266663, 0.4027799963951111, 0.375, 0.15277999639511108, 0.0, 0.38888999819755554, 0.44444000720977783, 0.09722200036048889, 0.36111000180244446, 0.5694400072097778, 0.5694400072097778, 0.23611000180244446, 0.20833000540733337, 0.75, 0.2916699945926666, 0.23611000180244446, 0.5138900279998779, 0.22222000360488892, 0.16666999459266663, 0.4722200036048889, 0.4722200036048889, 0.5, 0.31944000720977783, 0.2916699945926666, 0.4166699945926666, 0.15277999639511108, 0.19444000720977783, 0.43055999279022217, 0.22222000360488892, 0.6527799963951111, 0.3333300054073334, 0.75, 0.5, 0.5277799963951111, 0.11111000180244446, 0.125, 0.75, 0.8055599927902222, 0.013888999819755554, 0.6527799963951111, 0.18055999279022217, 0.18055999279022217, 0.4027799963951111, 0.23611000180244446, 0.26388999819755554, 0.30555999279022217, 0.26388999819755554, 0.5972200036048889, 0.13888999819755554, 0.20833000540733337, 0.5, 0.43055999279022217, 0.5555599927902222, 0.4166699945926666, 0.4027799963951111, 0.2777799963951111, 0.4583300054073334, 0.18055999279022217, 0.44444000720977783, 0.26388999819755554, 0.2777799963951111, 0.20833000540733337, 0.18055999279022217, 0.15277999639511108, 0.48611000180244446, 0.48611000180244446, 0.5694400072097778, 0.2777799963951111, 0.16666999459266663, 0.30555999279022217, 0.44444000720977783, 0.22222000360488892, 0.25, 0.16666999459266663, 0.3472200036048889, 0.5138900279998779, 0.31944000720977783, 0.48611000180244446, 0.4166699945926666, 0.4027799963951111, 0.44444000720977783, 0.4583300054073334, 0.16666999459266663, 0.22222000360488892, 0.4166699945926666, 0.30555999279022217, 0.4027799963951111, 0.16666999459266663, 0.3333300054073334, 0.26388999819755554, 0.25, 0.5694400072097778, 0.25, 0.2777799963951111, 0.2777799963951111, 0.19444000720977783, 0.18055999279022217, 0.30555999279022217, 0.05555599927902222, 0.18055999279022217, 0.2916699945926666, 0.3472200036048889, 0.2777799963951111, 0.3333300054073334, 0.05555599927902222, 0.43055999279022217, 0.125, 0.4722200036048889, 0.375, 0.25, 0.5, 0.20833000540733337, 0.26388999819755554, 0.36111000180244446, 0.38888999819755554, 0.48611000180244446, 0.15277999639511108, 0.3333300054073334, 0.22222000360488892, 0.11111000180244446, 0.11111000180244446, 0.11111000180244446, 0.25, 0.5555599927902222, 0.5, 0.22222000360488892, 0.22222000360488892, 0.30555999279022217, 0.11111000180244446, 0.19444000720977783, 0.23611000180244446, 0.22222000360488892, 0.30555999279022217, 0.48611000180244446, 0.2777799963951111, 0.16666999459266663, 0.38888999819755554, 0.2916699945926666, 0.3333300054073334, 0.6111099720001221, 0.23611000180244446, 0.4583300054073334, 0.5694400072097778, 0.43055999279022217, 0.36111000180244446, 0.25, 0.5, 0.05555599927902222, 0.25, 0.3333300054073334, 0.30555999279022217, 0.375, 0.5555599927902222, 0.04166699945926666, 0.30555999279022217, 0.541670024394989, 0.15277999639511108, 0.48611000180244446, 0.30555999279022217, 0.5, 0.583329975605011, 0.30555999279022217, 0.19444000720977783, 0.583329975605011, 0.38888999819755554, 0.4583300054073334, 0.23611000180244446, 0.6388900279998779, 0.22222000360488892, 0.5694400072097778, 0.31944000720977783, 0.20833000540733337, 0.2777799963951111, 0.15277999639511108, 0.2916699945926666, 0.04166699945926666, 0.22222000360488892, 0.16666999459266663, 0.25, 0.4722200036048889, 0.38888999819755554, 0.2916699945926666, 0.09722200036048889, 0.25, 0.38888999819755554, 0.38888999819755554, 0.2916699945926666, 0.13888999819755554, 0.44444000720977783, 0.20833000540733337, 0.3472200036048889, 0.125, 0.9444400072097778, 0.6527799963951111, 0.11111000180244446, 0.31944000720977783, 0.6944400072097778, 0.4027799963951111, 0.16666999459266663, 0.013888999819755554, 0.20833000540733337, 0.16666999459266663, 0.31944000720977783, 0.25, 0.06944400072097778, 0.38888999819755554, 0.23611000180244446, 0.36111000180244446, 0.08333300054073334, 0.15277999639511108, 0.3333300054073334, 0.625, 0.2777799963951111, 0.22222000360488892, 0.22222000360488892, 0.43055999279022217, 0.30555999279022217, 0.4027799963951111, 0.20833000540733337, 0.11111000180244446, 0.18055999279022217, 0.44444000720977783, 0.13888999819755554, 0.43055999279022217, 0.22222000360488892, 0.43055999279022217, 0.38888999819755554, 0.31944000720977783, 0.375, 0.19444000720977783, 0.30555999279022217, 0.43055999279022217, 0.36111000180244446, 0.11111000180244446, 0.31944000720977783, 0.6111099720001221, 0.43055999279022217, 0.18055999279022217, 0.18055999279022217, 0.15277999639511108, 0.11111000180244446, 0.13888999819755554, 0.375, 0.5, 0.26388999819755554, 0.2777799963951111, 0.26388999819755554, 0.06944400072097778, 0.13888999819755554, 0.15277999639511108, 0.20833000540733337, 0.2777799963951111, 0.19444000720977783, 0.125, 0.5, 0.5555599927902222, 0.5, 0.4166699945926666, 0.26388999819755554, 0.09722200036048889, 0.06944400072097778, 0.541670024394989, 0.38888999819755554, 0.16666999459266663, 0.43055999279022217, 0.5, 0.3333300054073334, 0.3472200036048889, 0.4166699945926666, 0.4583300054073334, 0.4722200036048889, 0.2777799963951111, 0.09722200036048889, 0.583329975605011, 0.4722200036048889, 0.18055999279022217, 0.7222200036048889, 0.25, 0.3333300054073334, 0.6527799963951111, 0.375, 0.583329975605011, 0.8055599927902222, 0.5, 0.15277999639511108, 0.44444000720977783, 0.5, 0.5277799963951111, 0.13888999819755554, 0.25, 0.18055999279022217, 0.30555999279022217, 0.11111000180244446, 0.30555999279022217, 0.5138900279998779, 0.38888999819755554, 0.38888999819755554, 0.44444000720977783, 0.16666999459266663, 0.22222000360488892, 0.31944000720977783, 0.23611000180244446, 0.6527799963951111, 0.04166699945926666, 0.16666999459266663, 0.30555999279022217, 0.125, 0.3333300054073334, 0.19444000720977783, 0.3472200036048889, 0.833329975605011, 0.19444000720977783, 0.4027799963951111, 0.05555599927902222, 0.23611000180244446, 0.36111000180244446, 0.22222000360488892, 0.43055999279022217, 0.30555999279022217, 0.666670024394989, 0.4583300054073334, 0.44444000720977783, 0.26388999819755554, 0.22222000360488892, 0.22222000360488892, 0.4722200036048889, 0.0, 0.22222000360488892, 0.5555599927902222, 0.5694400072097778, 0.19444000720977783, 0.2916699945926666, 0.30555999279022217, 0.23611000180244446, 0.2777799963951111, 0.4027799963951111, 0.2916699945926666, 0.6388900279998779, 0.44444000720977783, 0.9444400072097778, 0.05555599927902222, 0.6805599927902222, 0.583329975605011, 0.25, 0.6111099720001221, 0.23611000180244446, 0.06944400072097778, 0.4722200036048889, 0.02777799963951111, 0.08333300054073334, 0.38888999819755554, 0.11111000180244446, 0.5694400072097778, 0.36111000180244446, 0.2916699945926666, 0.26388999819755554, 0.48611000180244446, 0.30555999279022217, 0.20833000540733337, 0.02777799963951111, 0.11111000180244446, 0.31944000720977783, 0.2916699945926666, 0.23611000180244446, 0.08333300054073334, 0.44444000720977783, 0.05555599927902222, 0.541670024394989, 0.06944400072097778, 0.22222000360488892, 0.3472200036048889, 0.38888999819755554, 0.22222000360488892, 0.375, 0.3333300054073334, 0.5, 0.4166699945926666, 0.5972200036048889, 0.25, 0.6527799963951111, 0.25, 0.5, 0.05555599927902222, 0.23611000180244446, 0.44444000720977783, 0.25, 0.3333300054073334, 0.5694400072097778, 0.6944400072097778, 0.2916699945926666, 0.02777799963951111, 0.05555599927902222, 0.2916699945926666, 0.26388999819755554, 0.7361099720001221, 0.125, 0.15277999639511108, 0.2916699945926666, 0.23611000180244446, 0.22222000360488892, 0.26388999819755554, 0.666670024394989, 0.19444000720977783, 0.31944000720977783, 0.43055999279022217, 0.3333300054073334, 0.26388999819755554, 0.2777799963951111, 0.2916699945926666, 0.125, 0.16666999459266663, 0.4722200036048889, 0.2916699945926666, 0.15277999639511108, 0.15277999639511108, 0.30555999279022217, 0.583329975605011, 0.22222000360488892, 0.26388999819755554, 0.4722200036048889, 0.5277799963951111, 0.31944000720977783, 0.2777799963951111, 0.36111000180244446, 0.20833000540733337, 0.5694400072097778, 0.2916699945926666, 0.44444000720977783, 0.6944400072097778, 0.48611000180244446, 0.5277799963951111, 0.23611000180244446, 0.38888999819755554, 0.5, 0.4166699945926666, 0.5138900279998779, 0.3333300054073334, 0.22222000360488892, 0.2777799963951111, 0.4583300054073334, 0.20833000540733337, 0.4583300054073334, 0.05555599927902222, 0.125, 0.25, 0.5694400072097778, 0.6805599927902222, 0.2777799963951111, 0.3472200036048889, 0.541670024394989, 0.5277799963951111, 0.06944400072097778, 0.43055999279022217, 0.36111000180244446, 0.375, 0.4027799963951111, 0.4583300054073334, 0.25, 0.18055999279022217, 0.18055999279022217, 0.5138900279998779, 0.20833000540733337, 0.08333300054073334, 0.3333300054073334, 0.16666999459266663, 0.43055999279022217, 0.20833000540733337, 0.125, 0.38888999819755554, 0.4722200036048889, 0.3333300054073334, 0.30555999279022217, 0.2916699945926666, 0.3333300054073334, 0.18055999279022217, 0.06944400072097778, 0.23611000180244446, 0.05555599927902222, 0.19444000720977783, 0.15277999639511108, 0.44444000720977783, 0.38888999819755554, 0.4166699945926666, 0.38888999819755554, 0.08333300054073334, 0.625, 0.25, 0.38888999819755554, 0.36111000180244446, 0.3472200036048889, 0.125, 0.31944000720977783, 0.36111000180244446, 0.5972200036048889, 0.23611000180244446, 0.19444000720977783, 0.16666999459266663, 0.13888999819755554, 0.3472200036048889, 0.4722200036048889, 0.31944000720977783, 0.26388999819755554, 0.20833000540733337, 0.2777799963951111, 0.25, 0.26388999819755554, 0.8194400072097778, 0.2777799963951111, 0.4166699945926666, 0.666670024394989, 0.375, 0.20833000540733337, 0.4027799963951111, 0.25, 0.708329975605011, 0.22222000360488892, 0.20833000540733337, 0.44444000720977783, 0.4166699945926666, 0.6111099720001221, 0.25, 0.31944000720977783, 0.08333300054073334, 0.625, 0.125, 0.541670024394989, 0.25, 0.375, 0.30555999279022217, 0.26388999819755554, 0.3472200036048889, 0.22222000360488892, 0.3333300054073334, 0.23611000180244446, 0.18055999279022217, 0.11111000180244446, 0.375, 0.125, 0.08333300054073334, 0.5138900279998779, 0.3472200036048889, 0.30555999279022217, 0.6388900279998779, 0.26388999819755554, 0.4027799963951111, 0.2916699945926666, 0.31944000720977783, 0.26388999819755554, 0.22222000360488892, 0.3333300054073334, 0.22222000360488892, 0.2777799963951111, 0.36111000180244446, 0.26388999819755554, 0.48611000180244446, 0.23611000180244446, 0.3333300054073334, 0.3472200036048889, 0.13888999819755554, 0.26388999819755554, 0.4583300054073334, 0.375, 0.2916699945926666, 0.22222000360488892, 0.11111000180244446, 0.38888999819755554, 0.2777799963951111, 0.16666999459266663, 0.09722200036048889, 0.05555599927902222, 0.3333300054073334, 0.30555999279022217, 0.3333300054073334, 0.36111000180244446, 0.4166699945926666, 0.44444000720977783, 0.4027799963951111, 0.375, 0.15277999639511108, 0.31944000720977783, 0.5555599927902222, 0.7777799963951111, 0.26388999819755554, 0.25, 0.48611000180244446, 0.23611000180244446, 0.20833000540733337, 0.19444000720977783, 0.5555599927902222, 0.44444000720977783, 0.13888999819755554, 0.6111099720001221, 0.9722200036048889, 0.31944000720977783, 0.09722200036048889, 0.16666999459266663, 0.30555999279022217, 0.3472200036048889, 0.19444000720977783, 0.16666999459266663, 0.15277999639511108, 0.48611000180244446, 0.15277999639511108, 0.38888999819755554, 0.16666999459266663, 0.19444000720977783, 0.6388900279998779, 0.38888999819755554, 0.7361099720001221, 0.36111000180244446, 0.125, 0.22222000360488892, 0.5, 0.5, 0.3333300054073334, 0.4583300054073334, 0.23611000180244446, 0.6527799963951111, 0.4027799963951111, 0.48611000180244446, 0.708329975605011, 0.4027799963951111, 0.5694400072097778, 0.2777799963951111, 0.23611000180244446, 0.2777799963951111, 0.125, 0.3472200036048889, 0.31944000720977783, 0.25, 0.43055999279022217, 0.2777799963951111, 0.2777799963951111, 0.20833000540733337, 0.22222000360488892, 0.2916699945926666, 0.3333300054073334, 0.2916699945926666, 0.09722200036048889, 0.23611000180244446, 0.2777799963951111, 0.26388999819755554, 0.3472200036048889, 0.375, 0.125, 0.2777799963951111, 0.4722200036048889, 0.2777799963951111, 0.125, 0.16666999459266663, 0.375, 0.31944000720977783, 0.23611000180244446, 0.625, 0.23611000180244446, 0.125, 0.11111000180244446, 0.25, 0.26388999819755554, 0.26388999819755554, 0.25, 0.22222000360488892, 0.16666999459266663, 0.5, 0.541670024394989, 0.4583300054073334, 0.2916699945926666, 0.19444000720977783, 0.11111000180244446, 0.48611000180244446, 0.375, 0.375, 0.30555999279022217, 0.666670024394989, 0.38888999819755554, 0.3333300054073334, 0.4027799963951111, 0.5138900279998779, 0.3333300054073334, 0.16666999459266663, 0.22222000360488892, 0.2777799963951111, 0.541670024394989, 0.3333300054073334, 0.18055999279022217, 0.26388999819755554, 0.4027799963951111, 0.375, 0.5138900279998779, 0.3472200036048889, 0.16666999459266663, 0.31944000720977783, 0.4027799963951111, 0.3472200036048889, 0.25, 0.19444000720977783, 0.375, 0.4027799963951111, 0.15277999639511108, 0.4583300054073334, 0.19444000720977783, 0.19444000720977783, 0.19444000720977783, 0.0, 0.4166699945926666, 0.20833000540733337, 0.4166699945926666, 0.48611000180244446, 0.19444000720977783, 0.22222000360488892, 0.3333300054073334, 0.04166699945926666, 0.6111099720001221, 0.666670024394989, 0.16666999459266663, 0.5138900279998779, 0.18055999279022217, 0.25, 0.5138900279998779, 0.20833000540733337, 0.26388999819755554, 0.2777799963951111, 0.3333300054073334, 0.708329975605011, 0.3333300054073334, 0.18055999279022217, 0.38888999819755554, 0.16666999459266663, 0.31944000720977783, 0.26388999819755554, 0.4583300054073334, 0.26388999819755554, 0.5, 0.11111000180244446, 0.5, 0.18055999279022217, 0.26388999819755554, 0.5694400072097778, 0.26388999819755554, 0.375, 0.25, 0.4166699945926666, 0.19444000720977783, 0.44444000720977783, 0.20833000540733337, 0.375, 0.2777799963951111, 0.16666999459266663, 0.20833000540733337, 0.36111000180244446, 0.7638900279998779, 0.125, 0.583329975605011, 0.18055999279022217, 0.2777799963951111, 0.36111000180244446, 0.3333300054073334, 0.3472200036048889, 0.18055999279022217, 0.30555999279022217, 0.5138900279998779, 0.26388999819755554, 0.38888999819755554, 0.36111000180244446, 0.23611000180244446, 0.11111000180244446, 0.4027799963951111, 0.26388999819755554, 0.5555599927902222, 0.16666999459266663, 0.4583300054073334, 0.20833000540733337, 0.18055999279022217, 0.23611000180244446, 0.5, 0.13888999819755554, 0.583329975605011, 0.06944400072097778, 0.15277999639511108, 0.5, 0.11111000180244446, 0.11111000180244446, 0.16666999459266663, 0.31944000720977783, 0.22222000360488892, 0.26388999819755554, 0.19444000720977783, 0.2916699945926666, 0.25, 0.2777799963951111, 0.16666999459266663, 0.23611000180244446, 0.6111099720001221, 0.18055999279022217, 0.05555599927902222, 0.23611000180244446, 0.5, 0.3472200036048889, 0.3333300054073334, 0.04166699945926666, 0.2916699945926666, 0.15277999639511108, 0.4722200036048889, 0.375, 0.43055999279022217, 0.23611000180244446, 0.2777799963951111, 0.18055999279022217, 0.3472200036048889, 0.31944000720977783, 0.3333300054073334, 0.16666999459266663, 0.22222000360488892, 0.18055999279022217, 0.22222000360488892, 0.43055999279022217, 0.4583300054073334, 0.30555999279022217, 0.23611000180244446, 0.08333300054073334, 0.11111000180244446, 0.2777799963951111, 0.43055999279022217, 0.36111000180244446, 0.19444000720977783, 0.26388999819755554, 0.5, 0.25, 0.23611000180244446, 0.3472200036048889, 0.3333300054073334, 0.38888999819755554, 0.13888999819755554, 0.08333300054073334, 0.20833000540733337, 0.36111000180244446, 0.5277799963951111, 0.38888999819755554, 0.38888999819755554, 0.5138900279998779, 0.18055999279022217, 0.11111000180244446, 0.30555999279022217, 0.26388999819755554, 0.44444000720977783, 0.48611000180244446, 0.6527799963951111, 0.5, 0.375, 0.541670024394989, 0.2777799963951111, 0.22222000360488892, 0.2777799963951111, 0.06944400072097778, 0.3333300054073334, 0.2777799963951111, 0.20833000540733337, 0.43055999279022217, 0.4166699945926666, 0.23611000180244446, 0.20833000540733337, 0.2916699945926666, 0.3333300054073334, 0.3333300054073334, 0.08333300054073334, 0.16666999459266663, 0.4583300054073334, 0.05555599927902222, 0.31944000720977783, 0.30555999279022217, 0.3472200036048889, 0.22222000360488892, 0.20833000540733337, 0.2777799963951111, 0.5, 0.375, 0.13888999819755554, 0.541670024394989, 0.2777799963951111, 0.7638900279998779, 0.23611000180244446, 0.5, 0.2777799963951111, 0.15277999639511108, 0.43055999279022217, 0.013888999819755554, 0.4166699945926666, 0.2916699945926666, 0.20833000540733337, 0.375, 0.125, 0.2916699945926666, 0.18055999279022217, 0.05555599927902222, 0.18055999279022217, 0.09722200036048889, 0.31944000720977783, 0.375, 0.375, 0.20833000540733337, 0.3333300054073334, 0.22222000360488892, 0.26388999819755554, 0.02777799963951111, 0.5138900279998779, 0.16666999459266663, 0.25, 0.25, 0.22222000360488892, 0.11111000180244446, 0.11111000180244446, 0.30555999279022217, 0.23611000180244446, 0.6388900279998779, 0.43055999279022217, 0.5555599927902222, 0.19444000720977783, 0.3472200036048889, 0.4027799963951111, 0.43055999279022217, 0.4027799963951111, 0.541670024394989, 0.666670024394989, 0.4166699945926666, 0.38888999819755554, 0.16666999459266663, 0.26388999819755554, 0.6111099720001221, 0.2916699945926666, 0.875, 0.7361099720001221, 0.3472200036048889, 0.18055999279022217, 0.5, 0.16666999459266663, 0.16666999459266663, 0.13888999819755554, 0.625, 0.43055999279022217, 0.09722200036048889, 0.5277799963951111, 0.15277999639511108, 0.16666999459266663, 0.4583300054073334, 0.3333300054073334, 0.09722200036048889, 0.20833000540733337, 0.23611000180244446, 0.26388999819755554, 0.44444000720977783, 0.3333300054073334, 0.06944400072097778, 0.30555999279022217, 0.5138900279998779, 0.2916699945926666, 0.15277999639511108, 0.04166699945926666, 0.26388999819755554, 0.16666999459266663, 0.5972200036048889, 0.583329975605011, 0.2777799963951111, 0.125, 0.0, 0.4583300054073334, 0.26388999819755554, 0.20833000540733337, 0.20833000540733337, 0.23611000180244446, 0.23611000180244446, 0.20833000540733337, 0.3333300054073334, 0.15277999639511108, 0.18055999279022217, 0.6527799963951111, 0.25, 0.30555999279022217, 0.30555999279022217, 0.31944000720977783, 0.3472200036048889, 0.4027799963951111, 0.11111000180244446, 0.38888999819755554, 0.125, 0.26388999819755554, 0.2777799963951111, 0.4027799963951111, 0.18055999279022217, 0.3472200036048889, 0.11111000180244446, 0.3333300054073334, 0.05555599927902222, 0.20833000540733337, 0.16666999459266663, 0.4583300054073334, 0.13888999819755554, 0.22222000360488892, 0.06944400072097778, 0.05555599927902222, 0.3333300054073334, 0.16666999459266663, 0.5, 0.541670024394989, 0.05555599927902222, 0.2916699945926666, 0.43055999279022217, 0.375, 0.583329975605011, 0.48611000180244446, 0.3333300054073334, 0.30555999279022217, 0.2916699945926666, 0.25, 0.125, 0.5555599927902222, 0.5277799963951111, 0.48611000180244446, 0.20833000540733337, 0.25, 0.22222000360488892, 0.5972200036048889, 0.25, 0.20833000540733337, 0.06944400072097778, 0.08333300054073334, 0.5555599927902222, 0.375, 0.15277999639511108, 0.18055999279022217, 0.2777799963951111, 0.06944400072097778, 0.15277999639511108, 0.25, 0.44444000720977783, 0.2916699945926666, 0.3333300054073334, 0.43055999279022217, 0.22222000360488892, 0.09722200036048889, 0.38888999819755554, 0.23611000180244446, 0.16666999459266663, 0.2777799963951111, 0.5138900279998779, 0.30555999279022217, 0.36111000180244446, 0.23611000180244446, 0.4583300054073334, 0.3472200036048889, 0.4166699945926666, 0.05555599927902222, 0.44444000720977783, 0.2777799963951111, 0.36111000180244446, 0.125, 0.20833000540733337, 0.4166699945926666, 0.5138900279998779, 0.3472200036048889, 0.583329975605011, 0.23611000180244446, 0.22222000360488892, 0.31944000720977783, 0.26388999819755554, 0.48611000180244446, 0.6527799963951111, 0.2777799963951111, 0.2777799963951111, 0.26388999819755554, 0.30555999279022217, 0.6527799963951111, 0.3333300054073334, 0.2916699945926666, 0.38888999819755554, 0.31944000720977783, 0.5277799963951111, 0.22222000360488892, 0.02777799963951111, 0.43055999279022217, 0.20833000540733337, 0.31944000720977783, 0.5, 0.43055999279022217, 0.13888999819755554, 0.30555999279022217, 0.4722200036048889, 0.3472200036048889, 0.5277799963951111, 0.15277999639511108, 0.09722200036048889, 0.2777799963951111, 0.38888999819755554, 0.16666999459266663, 0.22222000360488892, 0.2777799963951111, 0.25, 0.48611000180244446, 0.5, 0.666670024394989, 0.19444000720977783, 0.44444000720977783, 0.18055999279022217, 0.9305599927902222, 0.16666999459266663, 0.11111000180244446, 0.2777799963951111, 0.375, 0.5, 0.5, 0.7222200036048889, 0.05555599927902222, 0.625, 0.26388999819755554, 0.3472200036048889, 0.13888999819755554, 0.5555599927902222, 0.36111000180244446, 0.30555999279022217, 0.05555599927902222, 0.16666999459266663, 0.25, 0.48611000180244446, 0.05555599927902222, 0.38888999819755554, 0.11111000180244446, 0.30555999279022217, 0.23611000180244446, 0.38888999819755554, 0.08333300054073334, 0.48611000180244446, 0.4166699945926666, 0.2916699945926666, 0.2777799963951111, 0.3333300054073334, 0.22222000360488892, 0.3333300054073334, 0.6111099720001221, 0.11111000180244446, 0.5277799963951111, 0.06944400072097778, 0.18055999279022217, 0.30555999279022217, 0.3333300054073334, 0.16666999459266663, 0.625, 0.5555599927902222, 0.0, 0.2916699945926666, 0.6527799963951111, 0.38888999819755554, 0.2777799963951111, 0.16666999459266663, 0.4583300054073334, 0.6805599927902222, 0.31944000720977783, 0.09722200036048889, 0.43055999279022217, 0.05555599927902222, 0.22222000360488892, 0.4027799963951111, 0.30555999279022217, 0.15277999639511108, 0.26388999819755554, 0.06944400072097778, 0.833329975605011, 0.4583300054073334, 0.30555999279022217, 0.2777799963951111, 0.2777799963951111, 0.2777799963951111, 0.4166699945926666, 0.4722200036048889, 0.43055999279022217, 0.25, 0.26388999819755554, 0.05555599927902222, 0.3472200036048889, 0.11111000180244446, 0.31944000720977783, 0.31944000720977783, 0.2777799963951111, 0.18055999279022217, 0.23611000180244446, 0.2777799963951111, 0.3472200036048889, 0.4027799963951111, 0.4166699945926666, 0.13888999819755554, 0.15277999639511108, 0.4166699945926666, 0.3472200036048889, 0.3472200036048889, 0.6111099720001221, 0.3472200036048889, 0.013888999819755554, 0.18055999279022217, 0.26388999819755554, 0.6805599927902222, 0.19444000720977783, 0.06944400072097778, 0.2777799963951111, 0.19444000720977783, 0.26388999819755554, 0.4722200036048889, 0.5138900279998779, 0.36111000180244446, 0.30555999279022217, 0.2916699945926666, 0.375, 0.2777799963951111, 0.25, 0.25, 0.22222000360488892, 0.31944000720977783, 0.3472200036048889, 0.6527799963951111, 0.38888999819755554, 0.30555999279022217, 0.26388999819755554, 0.18055999279022217, 0.125, 0.25, 0.375, 0.43055999279022217, 0.15277999639511108, 0.11111000180244446, 0.05555599927902222, 0.30555999279022217, 0.2916699945926666, 0.2777799963951111, 0.125, 0.36111000180244446, 0.38888999819755554, 0.04166699945926666, 0.20833000540733337, 0.375, 0.44444000720977783, 0.11111000180244446, 0.38888999819755554, 0.18055999279022217, 0.3472200036048889, 0.19444000720977783, 0.36111000180244446, 0.4027799963951111, 0.375, 0.3333300054073334, 0.26388999819755554, 0.375, 0.30555999279022217, 0.4583300054073334, 0.13888999819755554, 0.31944000720977783, 0.125, 0.6805599927902222, 0.5972200036048889, 0.22222000360488892, 0.2777799963951111, 0.4583300054073334, 0.22222000360488892, 0.5, 0.2777799963951111, 0.5555599927902222, 0.19444000720977783, 0.22222000360488892, 0.30555999279022217, 0.26388999819755554, 0.6805599927902222, 0.20833000540733337, 0.19444000720977783, 0.25, 0.19444000720977783, 0.36111000180244446, 0.09722200036048889, 0.36111000180244446, 0.11111000180244446, 0.3333300054073334, 0.2777799963951111, 0.26388999819755554, 0.2916699945926666, 0.22222000360488892, 0.2777799963951111, 0.3472200036048889, 0.44444000720977783, 0.4027799963951111, 0.20833000540733337, 0.18055999279022217, 0.2916699945926666, 0.26388999819755554, 0.4027799963951111, 0.30555999279022217, 0.31944000720977783, 0.583329975605011, 0.20833000540733337, 0.25, 0.44444000720977783, 0.5138900279998779, 0.44444000720977783, 0.26388999819755554, 0.44444000720977783, 0.23611000180244446, 0.3333300054073334, 0.13888999819755554, 0.2916699945926666, 0.3333300054073334, 0.23611000180244446, 0.541670024394989, 0.4583300054073334, 0.08333300054073334, 0.18055999279022217, 0.6111099720001221, 0.25, 0.3333300054073334, 0.22222000360488892, 0.375, 0.23611000180244446, 0.13888999819755554, 0.20833000540733337, 0.2777799963951111, 0.2916699945926666, 0.31944000720977783, 0.5, 0.3472200036048889, 0.36111000180244446, 0.5277799963951111, 0.5138900279998779, 0.2777799963951111, 0.19444000720977783, 0.4583300054073334, 0.541670024394989, 0.19444000720977783, 0.30555999279022217, 0.13888999819755554, 0.16666999459266663, 0.4027799963951111, 0.375, 0.11111000180244446, 0.25, 0.22222000360488892, 0.20833000540733337, 0.05555599927902222, 0.23611000180244446, 0.06944400072097778, 0.5555599927902222, 0.38888999819755554, 0.25, 0.6388900279998779, 0.2916699945926666, 0.26388999819755554, 0.25, 0.11111000180244446, 0.7638900279998779, 0.11111000180244446, 0.3472200036048889, 0.5, 0.22222000360488892, 0.23611000180244446, 0.4722200036048889, 0.2777799963951111, 0.4027799963951111, 0.25, 0.25, 0.6111099720001221, 0.2777799963951111, 0.25, 0.18055999279022217, 0.15277999639511108, 0.2916699945926666, 0.22222000360488892, 0.44444000720977783, 0.3333300054073334, 0.23611000180244446, 0.31944000720977783, 0.125, 0.4722200036048889, 0.541670024394989, 0.20833000540733337, 0.4722200036048889, 0.38888999819755554, 0.30555999279022217, 0.3472200036048889, 0.09722200036048889, 0.3472200036048889, 0.22222000360488892, 0.18055999279022217, 0.38888999819755554, 0.2916699945926666, 0.23611000180244446, 0.2777799963951111, 0.25, 0.4027799963951111, 0.18055999279022217, 0.11111000180244446, 0.375, 0.30555999279022217, 0.583329975605011, 0.43055999279022217, 0.5138900279998779, 0.13888999819755554, 0.3333300054073334, 0.26388999819755554, 0.09722200036048889, 0.13888999819755554, 0.7777799963951111, 0.22222000360488892, 0.3333300054073334, 0.11111000180244446, 0.4166699945926666, 0.2777799963951111, 0.30555999279022217, 0.16666999459266663, 0.30555999279022217, 0.16666999459266663, 0.48611000180244446, 0.08333300054073334, 0.7361099720001221, 0.375, 0.15277999639511108, 0.26388999819755554, 0.4722200036048889, 0.22222000360488892, 0.20833000540733337, 0.541670024394989, 0.4166699945926666, 0.375, 0.36111000180244446, 0.20833000540733337, 0.6944400072097778, 0.2777799963951111, 0.20833000540733337, 0.09722200036048889, 0.791670024394989, 0.38888999819755554, 0.4583300054073334, 0.36111000180244446, 0.6805599927902222, 0.4027799963951111, 0.5, 0.2777799963951111, 0.44444000720977783, 0.44444000720977783, 0.22222000360488892, 0.5, 0.3333300054073334, 0.20833000540733337, 0.20833000540733337, 0.31944000720977783, 0.04166699945926666, 0.16666999459266663, 0.4166699945926666, 0.3333300054073334, 0.013888999819755554, 0.2916699945926666, 0.22222000360488892, 0.4722200036048889, 0.3472200036048889, 0.44444000720977783, 0.26388999819755554, 0.11111000180244446, 0.23611000180244446, 0.48611000180244446, 0.20833000540733337, 0.06944400072097778, 0.20833000540733337, 0.26388999819755554, 0.25, 0.18055999279022217, 0.5972200036048889, 0.0, 0.36111000180244446, 0.23611000180244446, 0.30555999279022217, 0.2777799963951111, 0.4722200036048889, 0.2777799963951111, 0.25, 0.5, 0.43055999279022217, 0.16666999459266663, 0.5972200036048889, 0.666670024394989, 0.15277999639511108, 0.22222000360488892, 0.20833000540733337, 0.4166699945926666, 0.43055999279022217, 0.23611000180244446, 0.3472200036048889, 0.26388999819755554, 0.43055999279022217, 0.5, 0.13888999819755554, 0.22222000360488892, 0.13888999819755554, 0.3333300054073334, 0.75, 0.30555999279022217, 0.791670024394989, 0.2916699945926666, 0.2916699945926666, 0.708329975605011, 0.916670024394989, 0.44444000720977783, 0.48611000180244446, 0.19444000720977783, 0.5138900279998779, 0.2916699945926666, 0.30555999279022217, 0.19444000720977783, 0.30555999279022217, 0.3333300054073334, 0.48611000180244446, 0.2916699945926666, 0.3472200036048889, 0.23611000180244446, 0.26388999819755554, 0.125, 0.23611000180244446, 0.26388999819755554, 0.375, 0.13888999819755554, 0.26388999819755554, 0.26388999819755554, 0.19444000720977783, 0.16666999459266663, 0.22222000360488892, 0.20833000540733337, 0.5, 0.23611000180244446, 0.3472200036048889, 0.6388900279998779, 0.2916699945926666, 0.4583300054073334, 0.19444000720977783, 0.5555599927902222, 0.6111099720001221, 0.4027799963951111, 0.25, 0.31944000720977783, 0.5277799963951111, 0.6388900279998779, 0.13888999819755554, 0.5, 0.19444000720977783, 0.15277999639511108, 0.48611000180244446, 0.31944000720977783, 0.13888999819755554, 0.375, 0.4027799963951111, 0.625, 0.26388999819755554, 0.22222000360488892, 0.4583300054073334, 0.5555599927902222, 0.541670024394989, 0.19444000720977783, 0.06944400072097778, 0.2777799963951111, 0.13888999819755554, 0.16666999459266663, 0.44444000720977783, 0.44444000720977783, 0.5972200036048889, 0.48611000180244446, 0.16666999459266663, 0.25, 0.20833000540733337, 0.05555599927902222, 0.7222200036048889, 0.30555999279022217, 0.375, 0.541670024394989, 0.5138900279998779, 0.833329975605011, 0.5694400072097778, 0.5, 0.30555999279022217, 0.6388900279998779, 0.4583300054073334, 0.2777799963951111, 0.18055999279022217, 0.5, 0.25, 0.11111000180244446, 0.31944000720977783, 0.4027799963951111, 0.25, 0.09722200036048889, 0.375, 0.3333300054073334, 0.5138900279998779, 0.23611000180244446, 0.20833000540733337, 0.5, 0.22222000360488892, 0.26388999819755554, 0.5138900279998779, 0.2777799963951111, 0.48611000180244446, 0.44444000720977783, 0.2777799963951111, 0.7361099720001221, 0.6805599927902222, 0.36111000180244446, 0.05555599927902222, 0.541670024394989, 0.30555999279022217, 0.36111000180244446, 0.22222000360488892, 0.36111000180244446, 0.38888999819755554, 0.22222000360488892, 0.05555599927902222, 0.125, 0.26388999819755554, 0.26388999819755554, 0.18055999279022217, 0.541670024394989, 0.08333300054073334, 0.19444000720977783, 0.4166699945926666, 0.23611000180244446, 0.05555599927902222, 0.22222000360488892, 0.5, 0.375, 0.4722200036048889, 0.26388999819755554, 0.2916699945926666, 0.2916699945926666, 0.3333300054073334, 0.23611000180244446, 0.36111000180244446, 0.43055999279022217, 0.02777799963951111, 0.05555599927902222, 0.3333300054073334, 0.22222000360488892, 0.5138900279998779, 0.36111000180244446, 0.6805599927902222, 0.30555999279022217, 0.31944000720977783, 0.11111000180244446, 0.20833000540733337, 0.125, 0.4722200036048889, 0.02777799963951111, 0.22222000360488892, 0.16666999459266663, 0.3472200036048889, 0.48611000180244446, 0.31944000720977783, 0.44444000720977783, 0.4583300054073334, 0.25, 0.2777799963951111, 0.4027799963951111, 0.4583300054073334, 0.18055999279022217, 0.5555599927902222, 0.5277799963951111, 0.20833000540733337, 0.2777799963951111, 0.22222000360488892, 0.25, 0.25, 0.2916699945926666, 0.16666999459266663, 0.25, 0.5138900279998779, 0.2777799963951111, 0.19444000720977783, 0.38888999819755554, 0.36111000180244446, 0.125, 0.36111000180244446, 0.09722200036048889, 0.31944000720977783, 0.19444000720977783, 0.05555599927902222, 0.375, 0.5, 0.05555599927902222, 0.09722200036048889, 0.4027799963951111, 0.20833000540733337, 0.25, 0.23611000180244446, 0.09722200036048889, 0.6111099720001221, 0.38888999819755554, 0.3333300054073334, 0.5277799963951111, 0.38888999819755554, 0.013888999819755554, 0.5, 0.18055999279022217, 0.15277999639511108, 0.3333300054073334, 0.38888999819755554, 0.125, 0.36111000180244446, 0.125, 0.43055999279022217, 0.25, 0.791670024394989, 0.5694400072097778, 0.38888999819755554, 0.2916699945926666, 0.3333300054073334, 0.4722200036048889, 0.3472200036048889, 0.7361099720001221, 0.5, 0.44444000720977783, 0.38888999819755554, 0.5138900279998779, 0.375, 0.5277799963951111, 0.5138900279998779, 0.5, 0.666670024394989, 0.16666999459266663, 0.23611000180244446, 0.666670024394989, 0.11111000180244446, 0.19444000720977783, 0.2777799963951111, 0.6111099720001221, 0.09722200036048889, 0.22222000360488892, 0.20833000540733337, 0.25, 0.44444000720977783, 0.19444000720977783, 0.125, 0.18055999279022217, 0.31944000720977783, 0.4722200036048889, 0.11111000180244446, 0.13888999819755554, 0.22222000360488892, 0.43055999279022217, 0.375, 0.20833000540733337, 0.0, 0.2777799963951111, 0.05555599927902222, 0.0, 0.25, 0.375, 0.2777799963951111, 0.3333300054073334, 0.19444000720977783, 0.13888999819755554, 0.5555599927902222, 0.625, 0.2777799963951111, 0.26388999819755554, 0.5277799963951111, 0.20833000540733337, 0.20833000540733337, 0.15277999639511108, 0.666670024394989, 0.04166699945926666, 0.08333300054073334, 0.36111000180244446, 0.375, 0.5, 0.2777799963951111, 0.23611000180244446, 0.6111099720001221, 0.05555599927902222, 0.3333300054073334, 0.30555999279022217, 0.08333300054073334, 0.09722200036048889, 0.26388999819755554, 0.16666999459266663, 0.31944000720977783, 0.16666999459266663, 0.3472200036048889, 0.3333300054073334, 0.18055999279022217, 0.2777799963951111, 0.16666999459266663, 0.3472200036048889, 0.23611000180244446, 0.23611000180244446, 0.4027799963951111, 0.38888999819755554, 0.25, 0.13888999819755554, 0.25, 0.4166699945926666, 0.5, 0.48611000180244446, 0.2777799963951111, 0.25, 0.08333300054073334, 0.16666999459266663, 0.08333300054073334, 0.31944000720977783, 0.22222000360488892, 0.38888999819755554, 0.2777799963951111, 0.22222000360488892, 0.30555999279022217, 0.4583300054073334, 0.19444000720977783, 0.5555599927902222, 0.11111000180244446, 0.5, 0.13888999819755554, 0.4166699945926666, 0.16666999459266663, 0.666670024394989, 0.30555999279022217, 0.31944000720977783, 0.25, 0.19444000720977783, 0.31944000720977783, 0.4166699945926666, 0.6805599927902222, 0.13888999819755554, 0.20833000540733337, 0.5138900279998779, 0.05555599927902222, 0.16666999459266663, 0.06944400072097778, 0.20833000540733337, 0.5, 0.08333300054073334, 0.22222000360488892, 0.2777799963951111, 0.375, 0.48611000180244446, 0.4722200036048889, 0.15277999639511108, 0.3333300054073334, 0.18055999279022217, 0.25, 0.708329975605011, 0.22222000360488892, 0.25, 0.30555999279022217, 0.19444000720977783, 0.08333300054073334, 0.125, 0.708329975605011, 0.16666999459266663, 0.3472200036048889, 0.6944400072097778, 0.18055999279022217, 0.19444000720977783, 0.18055999279022217, 0.38888999819755554, 0.18055999279022217, 0.43055999279022217, 0.26388999819755554, 0.5, 0.16666999459266663, 0.13888999819755554, 0.4166699945926666, 0.20833000540733337, 0.30555999279022217, 0.6805599927902222, 0.2777799963951111, 0.20833000540733337, 0.18055999279022217, 0.3472200036048889, 0.44444000720977783, 0.5138900279998779, 0.23611000180244446, 0.4583300054073334, 0.43055999279022217, 0.25, 0.08333300054073334, 0.31944000720977783, 0.2777799963951111, 0.7638900279998779, 0.3472200036048889, 0.375, 0.16666999459266663, 0.15277999639511108, 0.6111099720001221, 0.26388999819755554, 0.22222000360488892, 0.23611000180244446, 0.38888999819755554, 0.16666999459266663, 0.3472200036048889, 0.48611000180244446, 0.31944000720977783, 0.5694400072097778, 0.4583300054073334, 0.2777799963951111, 0.44444000720977783, 0.16666999459266663, 0.25, 0.375, 0.19444000720977783, 0.2777799963951111, 0.08333300054073334, 0.13888999819755554, 0.23611000180244446, 0.30555999279022217, 0.22222000360488892, 0.36111000180244446, 0.125, 0.4583300054073334, 0.4166699945926666, 0.3472200036048889, 0.541670024394989, 0.4583300054073334, 0.8888900279998779, 0.5972200036048889, 0.4027799963951111, 0.5, 0.583329975605011, 0.16666999459266663, 0.20833000540733337, 0.2916699945926666, 0.31944000720977783, 0.11111000180244446, 0.20833000540733337, 0.19444000720977783, 0.2777799963951111, 0.31944000720977783, 0.583329975605011, 0.5138900279998779, 0.4166699945926666, 0.44444000720977783, 0.05555599927902222, 0.3333300054073334, 0.013888999819755554, 0.22222000360488892, 0.3333300054073334, 0.6805599927902222, 0.36111000180244446, 0.2777799963951111, 0.13888999819755554, 0.19444000720977783, 0.31944000720977783, 0.15277999639511108, 0.2777799963951111, 0.125, 0.22222000360488892, 0.30555999279022217, 0.22222000360488892, 0.15277999639511108, 0.16666999459266663, 0.06944400072097778, 0.23611000180244446, 0.22222000360488892, 0.5277799963951111, 0.30555999279022217, 0.15277999639511108, 0.30555999279022217, 0.38888999819755554, 0.36111000180244446, 0.30555999279022217, 0.2916699945926666, 0.18055999279022217, 0.5, 0.708329975605011, 0.3333300054073334, 0.04166699945926666, 0.013888999819755554, 0.19444000720977783, 0.38888999819755554, 0.5, 0.36111000180244446, 0.4583300054073334, 0.22222000360488892, 0.16666999459266663, 0.22222000360488892, 0.31944000720977783, 0.4166699945926666, 0.18055999279022217, 0.23611000180244446, 0.15277999639511108, 0.2777799963951111, 0.23611000180244446, 0.6805599927902222, 0.4027799963951111, 0.15277999639511108, 0.3333300054073334, 0.5138900279998779, 0.4027799963951111, 0.26388999819755554, 0.2777799963951111, 0.19444000720977783, 0.22222000360488892, 0.4027799963951111, 0.5555599927902222, 0.43055999279022217, 0.13888999819755554, 0.15277999639511108, 0.18055999279022217, 0.20833000540733337, 0.48611000180244446, 0.05555599927902222, 0.15277999639511108, 0.43055999279022217, 0.4166699945926666, 0.13888999819755554, 0.4722200036048889, 0.22222000360488892, 0.2916699945926666, 0.44444000720977783, 0.08333300054073334, 0.44444000720977783, 0.36111000180244446, 0.5277799963951111, 0.3333300054073334, 0.666670024394989, 0.19444000720977783, 0.44444000720977783, 0.23611000180244446, 0.3333300054073334, 0.44444000720977783, 0.5277799963951111, 0.05555599927902222, 0.4722200036048889, 0.541670024394989, 0.09722200036048889, 0.22222000360488892, 0.43055999279022217, 0.3472200036048889, 0.38888999819755554, 0.4027799963951111, 0.04166699945926666, 0.2916699945926666, 0.625, 0.2916699945926666, 0.375, 0.36111000180244446, 0.09722200036048889, 0.2777799963951111, 0.5, 0.4583300054073334, 0.7222200036048889, 0.30555999279022217, 0.19444000720977783, 0.11111000180244446, 0.22222000360488892, 0.541670024394989, 0.22222000360488892, 0.25, 0.23611000180244446, 0.16666999459266663, 0.26388999819755554, 0.30555999279022217, 0.44444000720977783, 0.19444000720977783, 0.5694400072097778, 0.25, 0.26388999819755554, 0.19444000720977783, 0.4027799963951111, 0.31944000720977783, 0.25, 0.16666999459266663, 0.23611000180244446, 0.08333300054073334, 0.15277999639511108, 0.18055999279022217, 0.38888999819755554, 0.05555599927902222, 0.44444000720977783, 0.36111000180244446, 0.20833000540733337, 0.375, 0.20833000540733337, 0.30555999279022217, 0.3472200036048889, 0.16666999459266663, 0.31944000720977783, 0.15277999639511108, 0.31944000720977783, 0.16666999459266663, 0.4166699945926666, 0.23611000180244446, 0.375, 0.43055999279022217, 0.3333300054073334, 0.11111000180244446, 0.30555999279022217, 0.3333300054073334, 0.18055999279022217, 0.13888999819755554, 0.30555999279022217, 0.4027799963951111, 0.375, 0.7222200036048889, 0.9305599927902222, 0.6805599927902222, 0.916670024394989, 0.44444000720977783, 0.25, 0.708329975605011, 0.5694400072097778, 0.8055599927902222, 0.48611000180244446, 0.791670024394989, 0.6527799963951111, 0.6805599927902222, 0.791670024394989, 0.7777799963951111, 0.9027799963951111, 0.75, 0.541670024394989, 0.31944000720977783, 0.708329975605011, 0.8888900279998779, 0.6527799963951111, 0.75, 0.6944400072097778, 0.8055599927902222, 0.833329975605011, 0.6944400072097778, 0.666670024394989, 0.6805599927902222, 0.791670024394989, 0.6805599927902222, 0.75, 0.625, 0.5972200036048889, 0.6805599927902222, 0.8611099720001221, 0.791670024394989, 0.013888999819755554, 0.5555599927902222, 0.23611000180244446, 0.3472200036048889, 0.2916699945926666, 0.4027799963951111, 0.0, 0.30555999279022217, 0.25, 0.30555999279022217, 0.25, 0.38888999819755554, 0.2916699945926666, 0.2777799963951111, 0.11111000180244446, 0.7222200036048889, 0.19444000720977783, 0.6388900279998779, 0.6527799963951111, 0.43055999279022217, 0.3333300054073334, 0.5694400072097778, 0.4722200036048889, 0.26388999819755554, 0.013888999819755554, 0.5, 0.5, 0.541670024394989, 0.5972200036048889, 0.3333300054073334, 0.43055999279022217, 0.2777799963951111, 0.05555599927902222, 0.2916699945926666, 0.36111000180244446, 0.5, 0.13888999819755554, 0.06944400072097778, 0.375, 0.16666999459266663, 0.06944400072097778, 0.31944000720977783, 0.31944000720977783, 0.9722200036048889, 0.7222200036048889, 0.7777799963951111, 0.6388900279998779, 0.875, 0.9027799963951111, 0.833329975605011, 0.7222200036048889, 0.7777799963951111, 0.708329975605011, 0.6527799963951111, 0.9027799963951111, 0.7777799963951111, 0.916670024394989, 0.6944400072097778, 0.791670024394989, 0.8055599927902222, 0.7638900279998779, 0.916670024394989, 0.8194400072097778, 0.7222200036048889, 0.8611099720001221, 0.75, 0.8194400072097778, 0.9027799963951111, 0.6944400072097778, 0.8888900279998779, 0.2916699945926666, 0.8611099720001221, 0.9305599927902222, 0.8472200036048889, 0.833329975605011, 0.625, 0.75, 0.875, 0.5138900279998779, 0.7222200036048889, 0.9305599927902222, 0.8055599927902222, 0.833329975605011, 0.4722200036048889, 0.5, 0.8055599927902222, 0.75, 0.8055599927902222, 0.7222200036048889, 0.7777799963951111, 0.833329975605011, 0.5, 0.6111099720001221, 0.8055599927902222, 0.8888900279998779, 0.6527799963951111, 0.8611099720001221, 0.6805599927902222, 0.9027799963951111, 0.833329975605011, 0.7222200036048889, 0.5, 0.75, 0.75, 0.8472200036048889, 0.8472200036048889, 0.8472200036048889, 0.7777799963951111, 0.30555999279022217, 0.8888900279998779, 0.7361099720001221, 0.708329975605011, 0.7361099720001221, 0.7638900279998779, 0.541670024394989, 0.833329975605011, 0.708329975605011, 0.8888900279998779, 0.7361099720001221, 0.2777799963951111, 0.7777799963951111, 0.666670024394989, 0.9305599927902222, 0.8055599927902222, 0.8055599927902222, 0.20833000540733337, 0.833329975605011, 0.916670024394989, 0.8055599927902222, 0.8888900279998779, 0.06944400072097778, 0.7361099720001221, 0.625, 0.7638900279998779, 0.6388900279998779, 0.5972200036048889, 0.7222200036048889, 0.7361099720001221, 0.7638900279998779, 0.791670024394989, 0.916670024394989, 0.7777799963951111, 0.791670024394989, 0.8888900279998779, 0.916670024394989, 0.791670024394989, 0.2777799963951111, 0.5277799963951111, 0.20833000540733337, 0.16666999459266663, 0.43055999279022217, 0.08333300054073334, 0.04166699945926666, 0.23611000180244446, 0.3472200036048889, 0.20833000540733337, 0.36111000180244446, 0.20833000540733337, 0.09722200036048889, 0.08333300054073334, 0.08333300054073334, 0.22222000360488892, 0.11111000180244446, 0.6111099720001221, 0.125, 0.4583300054073334, 0.18055999279022217, 0.30555999279022217, 0.18055999279022217, 0.38888999819755554, 0.2916699945926666, 0.13888999819755554, 0.19444000720977783, 0.5694400072097778, 0.5694400072097778, 0.31944000720977783, 0.44444000720977783, 0.4722200036048889, 0.26388999819755554, 0.31944000720977783, 0.11111000180244446, 0.20833000540733337, 0.16666999459266663, 0.11111000180244446, 0.11111000180244446, 0.48611000180244446, 0.19444000720977783, 0.02777799963951111, 0.3333300054073334, 0.15277999639511108, 0.16666999459266663, 0.44444000720977783, 0.31944000720977783, 0.05555599927902222, 0.20833000540733337, 0.20833000540733337, 0.06944400072097778, 0.18055999279022217, 0.5, 0.48611000180244446, 0.20833000540733337, 0.16666999459266663, 0.31944000720977783, 0.16666999459266663, 0.16666999459266663, 0.31944000720977783, 0.22222000360488892, 0.11111000180244446, 0.4722200036048889, 0.20833000540733337, 0.44444000720977783, 0.2777799963951111, 0.18055999279022217, 0.3333300054073334, 0.375, 0.44444000720977783, 0.16666999459266663, 0.20833000540733337, 0.20833000540733337, 0.23611000180244446, 0.36111000180244446, 0.5694400072097778, 0.31944000720977783, 0.11111000180244446, 0.0, 0.4583300054073334, 0.13888999819755554, 0.125, 0.4722200036048889, 0.375, 0.11111000180244446, 0.08333300054073334, 0.09722200036048889, 0.2916699945926666, 0.43055999279022217, 0.11111000180244446, 0.5555599927902222, 0.16666999459266663, 0.2777799963951111, 0.16666999459266663, 0.22222000360488892, 0.36111000180244446, 0.125, 0.2777799963951111, 0.05555599927902222, 0.22222000360488892, 0.5972200036048889, 0.31944000720977783, 0.4166699945926666, 0.11111000180244446, 0.05555599927902222, 0.23611000180244446, 0.13888999819755554, 0.22222000360488892, 0.22222000360488892, 0.38888999819755554, 0.2777799963951111, 0.26388999819755554, 0.06944400072097778, 0.3333300054073334, 0.18055999279022217, 0.11111000180244446, 0.5, 0.31944000720977783, 0.2916699945926666, 0.18055999279022217, 0.43055999279022217, 0.4583300054073334, 0.13888999819755554, 0.6388900279998779, 0.11111000180244446, 0.22222000360488892, 0.75, 0.13888999819755554, 0.3472200036048889]\n",
      "tensor([1, 1, 1,  ..., 1, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average training loss: 0.0432\n",
      "====> Epoch: 1 Average training loss: 0.0426\n",
      "====> Epoch: 2 Average training loss: 0.0399\n",
      "====> Epoch: 3 Average training loss: 0.0365\n",
      "====> Epoch: 4 Average training loss: 0.0352\n",
      "====> Epoch: 5 Average training loss: 0.0345\n",
      "====> Epoch: 6 Average training loss: 0.0341\n",
      "====> Epoch: 7 Average training loss: 0.0336\n",
      "====> Epoch: 8 Average training loss: 0.0332\n",
      "====> Epoch: 9 Average training loss: 0.0328\n",
      "====> Epoch: 10 Average training loss: 0.0324\n",
      "====> Epoch: 11 Average training loss: 0.0321\n",
      "====> Epoch: 12 Average training loss: 0.0317\n",
      "====> Epoch: 13 Average training loss: 0.0312\n",
      "====> Epoch: 14 Average training loss: 0.0307\n",
      "Accuracy on the test data is: 0.7384615384615385\n"
     ]
    }
   ],
   "source": [
    "#dataloader\n",
    "train_loader = create_dataloader(training_data, sst_dataset['train']['label'], 0)\n",
    "\n",
    "#create model obejct\n",
    "d = 300\n",
    "rnn_model = Model(d).to(device)\n",
    "m = nn.Softmax(1)\n",
    "cel = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.SGD(rnn_model.parameters(), lr = 0.01)\n",
    "\n",
    "#train\n",
    "num_epoch = 15\n",
    "train(num_epoch,rnn_model,train_loader)\n",
    "\n",
    "#test\n",
    "test(rnn_model,testing_data, sst_dataset['test']['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyXx1Xm8j5Lr"
   },
   "source": [
    "## 실습 Part 4. LSTM\n",
    "In this section, you implement a LSTM and perform text classification with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rZNv5hzGmKbW"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.input_dim = d\n",
    "        self.hidden_dim = d\n",
    "        self.output_dim = 2\n",
    "\n",
    "        self.Wf = nn.Linear(self.input_dim, self.hidden_dim)\n",
    "        self.Uf = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "        self.Wi = nn.Linear(self.input_dim, self.hidden_dim)\n",
    "        self.Ui = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "        self.Wo = nn.Linear(self.input_dim, self.hidden_dim)\n",
    "        self.Uo = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "        self.Wc = nn.Linear(self.input_dim, self.hidden_dim)\n",
    "        self.Uc = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "        self.W = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        ht = torch.zeros(batch_size, self.hidden_dim).to(device)\n",
    "        ct = torch.zeros(batch_size, self.hidden_dim).to(device)\n",
    "        return ht, ct\n",
    "\n",
    "    def forward(self, x): \n",
    "        batch_size = x.size(0)\n",
    "        seq_length = x.size(1)\n",
    "        ht, ct = self.init_hidden(batch_size) \n",
    "\n",
    "        for t in range(0, seq_length):\n",
    "            xt = x[:, t, :]\n",
    "\n",
    "            ft = torch.sigmoid(self.Wf(xt) + self.Uf(ht))\n",
    "            it = torch.sigmoid(self.Wi(xt) + self.Ui(ht))\n",
    "            ot = torch.sigmoid(self.Wo(xt) + self.Uo(ht))\n",
    "            ct_tilda = torch.tanh(self.Wc(xt) + self.Uc(ht))\n",
    "\n",
    "            ct = ft * ct + it * ct_tilda\n",
    "            ht = ot * torch.tanh(ct)\n",
    "\n",
    "        return self.W(ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtxcDfwSqVSs"
   },
   "source": [
    "Now perform text classification using your LSTM model. You will see your model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nVX5TO2DqcGm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average training loss: 0.0433\n",
      "====> Epoch: 1 Average training loss: 0.0432\n",
      "====> Epoch: 2 Average training loss: 0.0431\n",
      "====> Epoch: 3 Average training loss: 0.0430\n",
      "====> Epoch: 4 Average training loss: 0.0428\n",
      "====> Epoch: 5 Average training loss: 0.0426\n",
      "====> Epoch: 6 Average training loss: 0.0424\n",
      "====> Epoch: 7 Average training loss: 0.0421\n",
      "====> Epoch: 8 Average training loss: 0.0417\n",
      "====> Epoch: 9 Average training loss: 0.0406\n",
      "====> Epoch: 10 Average training loss: 0.0377\n",
      "====> Epoch: 11 Average training loss: 0.0356\n",
      "====> Epoch: 12 Average training loss: 0.0348\n",
      "====> Epoch: 13 Average training loss: 0.0340\n",
      "====> Epoch: 14 Average training loss: 0.0335\n",
      "Accuracy on the test data is: 0.744343891402715\n"
     ]
    }
   ],
   "source": [
    "#create model obejct\n",
    "d = 300\n",
    "lstm_model = LSTM(d).to(device)\n",
    "m = nn.Softmax(1)\n",
    "cel = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.SGD(lstm_model.parameters(), lr = 0.01)\n",
    "\n",
    "\n",
    "#train\n",
    "num_epoch = 15\n",
    "train(num_epoch,lstm_model,train_loader)\n",
    "\n",
    "#test\n",
    "test(lstm_model,testing_data, sst_dataset['test']['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQjMunQq3evu"
   },
   "source": [
    "# 실습 Part 5. Transformer\n",
    "In this section, you will train BERT (transformer) for text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_ZbXRwZ5aSg"
   },
   "source": [
    "Download naver sentiment corpus for this transformer experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jrxFjPNW5ZiO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nsmc'...\n",
      "remote: Enumerating objects: 14763, done.\u001b[K\n",
      "remote: Counting objects: 100% (14762/14762), done.\u001b[K\n",
      "remote: Compressing objects: 100% (13012/13012), done.\u001b[K\n",
      "remote: Total 14763 (delta 1748), reused 14762 (delta 1748), pack-reused 1\u001b[K\n",
      "Receiving objects: 100% (14763/14763), 56.19 MiB | 19.65 MiB/s, done.\n",
      "Resolving deltas: 100% (1748/1748), done.\n"
     ]
    }
   ],
   "source": [
    "# naver sentiment corpus\n",
    "!git clone https://github.com/e9t/nsmc.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgjDAc2d5sWI"
   },
   "source": [
    "Once the download is finished, you can check the example of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CtK1yhOr5WXX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5403919</td>\n",
       "      <td>막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7797314</td>\n",
       "      <td>원작의 긴장감을 제대로 살려내지못했다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9443947</td>\n",
       "      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7156791</td>\n",
       "      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5912145</td>\n",
       "      <td>왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9008700</td>\n",
       "      <td>걍인피니트가짱이다.진짜짱이다♥</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10217543</td>\n",
       "      <td>볼때마다 눈물나서 죽겠다90년대의 향수자극!!허진호는 감성절제멜로의 달인이다~</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5957425</td>\n",
       "      <td>울면서 손들고 횡단보도 건널때 뛰쳐나올뻔 이범수 연기 드럽게못해</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8628627</td>\n",
       "      <td>담백하고 깔끔해서 좋다. 신문기사로만 보다 보면 자꾸 잊어버린다. 그들도 사람이었다...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9864035</td>\n",
       "      <td>취향은 존중한다지만 진짜 내생에 극장에서 본 영화중 가장 노잼 노감동임 스토리도 어...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           document  label\n",
       "0    9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1    3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2   10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3    9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4    6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "5    5403919      막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.      0\n",
       "6    7797314                              원작의 긴장감을 제대로 살려내지못했다.      0\n",
       "7    9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...      0\n",
       "8    7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1\n",
       "9    5912145      왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?      1\n",
       "10   9008700                                   걍인피니트가짱이다.진짜짱이다♥      1\n",
       "11  10217543        볼때마다 눈물나서 죽겠다90년대의 향수자극!!허진호는 감성절제멜로의 달인이다~      1\n",
       "12   5957425                울면서 손들고 횡단보도 건널때 뛰쳐나올뻔 이범수 연기 드럽게못해      0\n",
       "13   8628627  담백하고 깔끔해서 좋다. 신문기사로만 보다 보면 자꾸 잊어버린다. 그들도 사람이었다...      1\n",
       "14   9864035  취향은 존중한다지만 진짜 내생에 극장에서 본 영화중 가장 노잼 노감동임 스토리도 어...      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./nsmc/ratings_train.txt', sep='\\t')\n",
    "test_df = pd.read_csv('./nsmc/ratings_test.txt', sep='\\t')\n",
    "train_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzYcgUjx52Jk"
   },
   "source": [
    "For the fast experiment, we will use only small fraction of the dataset (40% of each dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pccD6OgL5ptN"
   },
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "train_df = train_df.sample(frac=0.2, random_state=999)\n",
    "test_df = test_df.sample(frac=0.2, random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OyEz7_W6mSz"
   },
   "source": [
    "Build the Dataset and DataLoader to train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kVDW00MW6Wmg"
   },
   "outputs": [],
   "source": [
    "class NsmcDataset(Dataset):\n",
    "    ''' Naver Sentiment Movie Corpus Dataset '''\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx, 1]\n",
    "        label = self.df.iloc[idx, 2]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5E1_MAhRIpVN"
   },
   "source": [
    "Generate Dataloader object for train and test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "VVmokbsdIeIH"
   },
   "outputs": [],
   "source": [
    "#dataloader\n",
    "nsmc_train_dataset = NsmcDataset(train_df)\n",
    "train_loader = DataLoader(nsmc_train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "nsmc_eval_dataset = NsmcDataset(test_df)\n",
    "eval_loader = DataLoader(nsmc_eval_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpLdE4NEJISD"
   },
   "source": [
    "Create the model object and tokenizer. In this experiment we will use AdamW optimzer with learning rate 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "H9bWeptKIzzL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/storage.py:315: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.\n",
      "  warnings.warn(message, UserWarning)\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create model obejct\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "transformer_model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n",
    "transformer_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "SGlBJ37Grr3l"
   },
   "outputs": [],
   "source": [
    "#optimizer\n",
    "optimizer = torch.optim.AdamW(transformer_model.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx8ZIXcuJJhJ"
   },
   "source": [
    "You can train the model and see the result with test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "wA97UwpS7PxZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3589/2900877290.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = torch.argmax(F.softmax(logits), dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1] Iteration 200 -> Train Loss: 0.6658, Accuracy: 0.596\n",
      "[Epoch 1/1] Iteration 400 -> Train Loss: 0.5645, Accuracy: 0.709\n",
      "[Epoch 1/1] Iteration 600 -> Train Loss: 0.5240, Accuracy: 0.738\n",
      "[Epoch 1/1] Iteration 800 -> Train Loss: 0.4934, Accuracy: 0.773\n",
      "[Epoch 1/1] Iteration 1000 -> Train Loss: 0.4973, Accuracy: 0.768\n",
      "[Epoch 1/1] Iteration 1200 -> Train Loss: 0.4693, Accuracy: 0.776\n",
      "[Epoch 1/1] Iteration 1400 -> Train Loss: 0.4652, Accuracy: 0.784\n",
      "[Epoch 1/1] Iteration 1600 -> Train Loss: 0.4325, Accuracy: 0.799\n",
      "[Epoch 1/1] Iteration 1800 -> Train Loss: 0.4642, Accuracy: 0.767\n",
      "[Epoch 1/1] Iteration 2000 -> Train Loss: 0.4324, Accuracy: 0.796\n",
      "[Epoch 1/1] Iteration 2200 -> Train Loss: 0.4467, Accuracy: 0.786\n",
      "[Epoch 1/1] Iteration 2400 -> Train Loss: 0.4226, Accuracy: 0.795\n",
      "[Epoch 1/1] Iteration 2600 -> Train Loss: 0.4039, Accuracy: 0.816\n",
      "[Epoch 1/1] Iteration 2800 -> Train Loss: 0.4267, Accuracy: 0.809\n",
      "[Epoch 1/1] Iteration 3000 -> Train Loss: 0.3999, Accuracy: 0.819\n",
      "[Epoch 1/1] Iteration 3200 -> Train Loss: 0.3940, Accuracy: 0.816\n",
      "[Epoch 1/1] Iteration 3400 -> Train Loss: 0.3851, Accuracy: 0.823\n",
      "[Epoch 1/1] Iteration 3600 -> Train Loss: 0.3959, Accuracy: 0.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3589/2900877290.py:57: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = torch.argmax(F.softmax(logits), dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8157815781578158\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "itr = 1\n",
    "p_itr = 200\n",
    "epochs = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "\n",
    "transformer_model.train()\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for text, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        encoded = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        encoded, label = encoded.to(device), label.to(device)\n",
    "        outputs = transformer_model(**encoded, labels=label)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "        correct = pred.eq(label)\n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(label)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if itr % p_itr == 0:\n",
    "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "            total_loss = 0\n",
    "            total_len = 0\n",
    "            total_correct = 0\n",
    "\n",
    "        itr+=1\n",
    "\n",
    "#test\n",
    "transformer_model.eval()\n",
    "\n",
    "nsmc_eval_dataset = NsmcDataset(test_df)\n",
    "eval_loader = DataLoader(nsmc_eval_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "for text, label in eval_loader:\n",
    "\n",
    "    encoded = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    encoded, label = encoded.to(device), label.to(device)\n",
    "    outputs = transformer_model(**encoded, labels=label)\n",
    "\n",
    "    logits = outputs.logits\n",
    "\n",
    "    pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "    correct = pred.eq(label)\n",
    "    total_correct += correct.sum().item()\n",
    "    total_len += len(label)\n",
    "\n",
    "print('Test accuracy: ', total_correct / total_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HseUfORhCohg"
   },
   "source": [
    "You can try trained model with your own input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "lRsFi6t9Clsk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: ㅋㅋ\n",
      "입력이 긍정적일 확률: 0.6901508\n",
      "입력이 부정적일 확률: 0.30984926\n"
     ]
    }
   ],
   "source": [
    "# You can try trained model with your own input\n",
    "text = 'ㅋㅋ'\n",
    "\n",
    "encoded = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "outputs = transformer_model(**encoded)\n",
    "\n",
    "logits = outputs.logits\n",
    "soft = F.softmax(logits, dim=1).cpu().detach().numpy()[0]\n",
    "\n",
    "print(\"입력:\", text)\n",
    "print(\"입력이 긍정적일 확률:\", soft[1])\n",
    "print(\"입력이 부정적일 확률:\", soft[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
